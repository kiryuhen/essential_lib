# Асинхронное программирование в Python

## Содержание
1. [Понимание синхронного vs асинхронного исполнения](#1-понимание-синхронного-vs-асинхронного-исполнения)
2. [Потоки и процессы (threading, multiprocessing)](#2-потоки-и-процессы-threading-multiprocessing)
3. [Асинхронный ввод-вывод](#3-асинхронный-ввод-вывод)
4. [Async/await синтаксис](#4-asyncawait-синтаксис)
5. [Asyncio и работа с ним](#5-asyncio-и-работа-с-ним)
6. [Конкурентное программирование](#6-конкурентное-программирование)
7. [Race conditions и их избежание](#7-race-conditions-и-их-избежание)
8. [Семафоры, блокировки, условные переменные](#8-семафоры-блокировки-условные-переменные)
9. [Практические задачи](#9-практические-задачи)

---

## 1. Понимание синхронного vs асинхронного исполнения

### Синхронное выполнение

При синхронном выполнении кода операции выполняются последовательно, одна за другой. Каждая следующая операция начинается только после завершения предыдущей. Это самая простая модель выполнения, привычная для большинства программистов.

```python
def sync_function():
    result1 = slow_operation1()  # Программа блокируется здесь, пока операция не завершится
    result2 = slow_operation2()  # Эта операция начнется только после завершения первой
    return result1 + result2
```

**Преимущества синхронного выполнения:**
- Простота понимания и отладки
- Предсказуемый поток выполнения
- Отсутствие накладных расходов на координацию выполнения

**Недостатки синхронного выполнения:**
- Неэффективное использование ресурсов при операциях ввода-вывода
- Блокировка всего процесса при долгих операциях
- Снижение отзывчивости пользовательского интерфейса

### Асинхронное выполнение

При асинхронном выполнении программа может продолжать работу, не дожидаясь завершения длительных операций. Когда выполняется асинхронная операция, программа может переключиться на другие задачи, а затем вернуться к обработке результата, когда операция завершится.

```python
async def async_function():
    task1 = asyncio.create_task(slow_operation1())  # Запускаем операцию и сразу идем дальше
    task2 = asyncio.create_task(slow_operation2())  # Запускаем вторую операцию, не дожидаясь первой
    
    result1 = await task1  # Ждем завершения первой операции
    result2 = await task2  # Ждем завершения второй операции
    
    return result1 + result2
```

**Преимущества асинхронного выполнения:**
- Более эффективное использование ресурсов
- Повышение пропускной способности приложения
- Улучшение отзывчивости интерфейса
- Возможность параллельного выполнения задач без использования многопоточности

**Недостатки асинхронного выполнения:**
- Сложность понимания и отладки
- Требуется специальный синтаксис и подходы
- Возможные проблемы с управлением памятью и утечками ресурсов
- Сложнее обрабатывать исключения

### Блокирующие vs неблокирующие операции

Важное различие, лежащее в основе синхронного и асинхронного программирования:

**Блокирующие операции** приостанавливают выполнение программы до завершения операции. Примеры:
- Чтение из файла с использованием `open().read()`
- Запрос к базе данных с использованием обычного соединения
- Получение ответа от HTTP-запроса с использованием `requests.get()`

**Неблокирующие операции** позволяют программе продолжать выполнение, предоставляя механизм для получения результата позже. Примеры:
- Чтение из файла с использованием `aiofiles.open()`
- Запрос к базе данных с использованием асинхронного соединения
- Получение ответа от HTTP-запроса с использованием `aiohttp.ClientSession.get()`

### Визуальное представление

```
Синхронное выполнение:
Задача 1: [==========]
Задача 2:            [==========]
Задача 3:                        [==========]
Время: |------------------------------------------->

Асинхронное выполнение:
Задача 1: [==========]
Задача 2: [==========]
Задача 3: [==========]
Время: |-------------->
```

### Пример: сравнение синхронного и асинхронного подходов

Синхронный код:

```python
import requests
import time

def fetch_url(url):
    response = requests.get(url)
    return response.text

def fetch_all_urls(urls):
    results = []
    for url in urls:
        results.append(fetch_url(url))
    return results

start_time = time.time()
urls = ["https://example.com", "https://example.org", "https://example.net"]
results = fetch_all_urls(urls)
print(f"Took {time.time() - start_time:.2f} seconds")
```

Асинхронный код:

```python
import aiohttp
import asyncio
import time

async def fetch_url(session, url):
    async with session.get(url) as response:
        return await response.text()

async def fetch_all_urls(urls):
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url(session, url) for url in urls]
        return await asyncio.gather(*tasks)

async def main():
    start_time = time.time()
    urls = ["https://example.com", "https://example.org", "https://example.net"]
    results = await fetch_all_urls(urls)
    print(f"Took {time.time() - start_time:.2f} seconds")

asyncio.run(main())
```

В этом примере асинхронный код будет значительно быстрее, так как все запросы будут выполняться параллельно, а не последовательно.

## 2. Потоки и процессы (threading, multiprocessing)

### Общий обзор

В Python существует несколько подходов к параллельному выполнению кода:

1. **Многопоточность (threading)** - создание нескольких потоков внутри одного процесса
2. **Многопроцессность (multiprocessing)** - создание нескольких процессов
3. **Асинхронное программирование (asyncio)** - использование корутин и событийного цикла

Каждый из этих подходов имеет свои преимущества и недостатки, а также наиболее подходящие сценарии использования.

### Глобальная блокировка интерпретатора (GIL)

Прежде чем углубляться в потоки и процессы, необходимо понять важное ограничение Python - Глобальную блокировку интерпретатора (Global Interpreter Lock, GIL).

GIL - это механизм, который гарантирует, что только один поток может выполнять байт-код Python в любой момент времени. GIL был введен для упрощения управления памятью и потоками в интерпретаторе CPython.

**Последствия GIL:**
- Потоки в Python не могут выполняться параллельно на многоядерных процессорах для CPU-bound задач
- Многопоточность полезна в основном для I/O-bound задач (сетевые операции, чтение/запись файлов)
- Для CPU-bound задач многопроцессорность может быть более эффективной

### Многопоточность (threading)

Многопоточность в Python реализуется через модуль `threading`. Потоки разделяют память процесса, что облегчает обмен данными между ними, но требует осторожности с синхронизацией.

**Когда использовать потоки:**
- Задачи с интенсивным вводом-выводом (I/O-bound)
- Когда важна быстрая коммуникация между параллельными задачами
- Когда необходимо выполнять много параллельных задач с малым потреблением памяти

**Пример использования потоков:**

```python
import threading
import time
import requests

def download_site(url):
    print(f"Загрузка {url}")
    response = requests.get(url)
    print(f"Завершена загрузка {url}")

def download_all_sites(sites):
    threads = []
    
    # Создаем и запускаем потоки
    for url in sites:
        thread = threading.Thread(target=download_site, args=(url,))
        threads.append(thread)
        thread.start()
    
    # Ждем завершения всех потоков
    for thread in threads:
        thread.join()

sites = ["https://example.com", "https://example.org", "https://example.net"] * 5
start_time = time.time()
download_all_sites(sites)
print(f"Загрузка {len(sites)} сайтов заняла {time.time() - start_time:.2f} секунд")
```

### Многопроцессность (multiprocessing)

Многопроцессность в Python реализуется через модуль `multiprocessing`. Каждый процесс имеет свою собственную память, что делает обмен данными более сложным, но позволяет обойти ограничения GIL.

**Когда использовать процессы:**
- Задачи с интенсивными вычислениями (CPU-bound)
- Когда необходимо задействовать все доступные ядра процессора
- Когда изоляция памяти между параллельными задачами является преимуществом

**Пример использования процессов:**

```python
import multiprocessing
import time

def cpu_bound_task(number):
    return sum(i * i for i in range(number))

def find_sums(numbers):
    with multiprocessing.Pool() as pool:
        return pool.map(cpu_bound_task, numbers)

numbers = [10_000_000 + x for x in range(12)]
start_time = time.time()
results = find_sums(numbers)
print(f"Вычисление заняло {time.time() - start_time:.2f} секунд")
```

### Коммуникация между потоками и процессами

**Для потоков:**
- Общие переменные (требуют синхронизации)
- Queue из модуля `queue`
- `threading.Event`, `threading.Condition` для сигнализации
- Локальное хранилище потоков (`threading.local()`)

**Для процессов:**
- `multiprocessing.Queue` и `multiprocessing.Pipe` для обмена данными
- `multiprocessing.Value` и `multiprocessing.Array` для общей памяти
- `multiprocessing.Manager` для более сложных структур данных
- `multiprocessing.Lock`, `multiprocessing.Event` для синхронизации

### Сравнение threading и multiprocessing

| Аспект | Threading | Multiprocessing |
|--------|-----------|-----------------|
| GIL | Ограничен GIL | Не ограничен GIL (каждый процесс имеет свой GIL) |
| Использование памяти | Низкое (общая память) | Высокое (копирование памяти для каждого процесса) |
| Обмен данными | Простой (общая память) | Сложнее (сериализация/десериализация) |
| Масштабирование по ядрам CPU | Ограниченное для CPU-задач | Хорошее |
| Накладные расходы на создание | Низкие | Высокие |
| Лучшее применение | I/O-bound задачи | CPU-bound задачи |

### Пример сравнения производительности

```python
import time
import threading
import multiprocessing
import requests

# Задача с интенсивным вводом-выводом (I/O-bound)
def io_bound_task(url):
    response = requests.get(url)
    return len(response.text)

# Задача с интенсивными вычислениями (CPU-bound)
def cpu_bound_task(n):
    count = 0
    for i in range(n):
        count += i * i
    return count

# Тестирование многопоточности для I/O-bound задачи
def test_threading_io():
    urls = ["https://example.com"] * 10
    threads = []
    
    for url in urls:
        thread = threading.Thread(target=io_bound_task, args=(url,))
        threads.append(thread)
        thread.start()
    
    for thread in threads:
        thread.join()

# Тестирование многопроцессности для I/O-bound задачи
def test_multiprocessing_io():
    urls = ["https://example.com"] * 10
    processes = []
    
    for url in urls:
        process = multiprocessing.Process(target=io_bound_task, args=(url,))
        processes.append(process)
        process.start()
    
    for process in processes:
        process.join()

# Тестирование многопоточности для CPU-bound задачи
def test_threading_cpu():
    numbers = [10_000_000] * 4
    threads = []
    
    for n in numbers:
        thread = threading.Thread(target=cpu_bound_task, args=(n,))
        threads.append(thread)
        thread.start()
    
    for thread in threads:
        thread.join()

# Тестирование многопроцессности для CPU-bound задачи
def test_multiprocessing_cpu():
    numbers = [10_000_000] * 4
    processes = []
    
    for n in numbers:
        process = multiprocessing.Process(target=cpu_bound_task, args=(n,))
        processes.append(process)
        process.start()
    
    for process in processes:
        process.join()

# Запуск тестов и вывод результатов
def run_tests():
    print("Тестирование I/O-bound задачи:")
    
    start = time.time()
    test_threading_io()
    print(f"Threading: {time.time() - start:.2f} секунд")
    
    start = time.time()
    test_multiprocessing_io()
    print(f"Multiprocessing: {time.time() - start:.2f} секунд")
    
    print("\nТестирование CPU-bound задачи:")
    
    start = time.time()
    test_threading_cpu()
    print(f"Threading: {time.time() - start:.2f} секунд")
    
    start = time.time()
    test_multiprocessing_cpu()
    print(f"Multiprocessing: {time.time() - start:.2f} секунд")

if __name__ == "__main__":
    run_tests()
```

Результаты будут примерно такими:
- Для I/O-bound задачи threading обычно быстрее multiprocessing из-за меньших накладных расходов
- Для CPU-bound задачи multiprocessing значительно быстрее threading, так как может использовать все ядра процессора

## 3. Асинхронный ввод-вывод

Асинхронный ввод-вывод (Async I/O) - это парадигма программирования, которая позволяет программе выполнять операции ввода-вывода параллельно, не блокируя основной поток выполнения.

### Основные концепции

#### Событийный цикл (Event Loop)

Событийный цикл - это центральный компонент асинхронного программирования. Он отвечает за:
- Регистрацию задач и колбэков
- Планирование их выполнения
- Выполнение задач в нужное время
- Обработку завершенных задач и исключений

```python
import asyncio

# Получение ссылки на текущий событийный цикл
loop = asyncio.get_event_loop()

# Создание и запуск нового событийного цикла
loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)

# В современном Python (3.7+) рекомендуется использовать:
asyncio.run(main())  # Создает новый цикл и запускает корутину main
```

#### Корутины и задачи

**Корутина (Coroutine)** - это специальная функция, которая может приостанавливать свое выполнение, позволяя событийному циклу выполнять другие задачи, и затем возобновлять выполнение с того места, где она была приостановлена.

**Задача (Task)** - это обертка вокруг корутины, которая отслеживает ее выполнение в событийном цикле.

```python
async def my_coroutine():
    await asyncio.sleep(1)
    return "Результат"

# Создание задачи из корутины
task = asyncio.create_task(my_coroutine())

# Ожидание завершения задачи
result = await task
```

#### Футуры (Futures)

Футуры представляют собой результат операции, которая еще не завершена. Они используются для уведомления о завершении асинхронных операций.

```python
# Создание футуры
future = asyncio.Future()

# Установка результата футуры
future.set_result("Результат")

# Ожидание завершения футуры
result = await future
```

### Неблокирующий ввод-вывод

Основное преимущество асинхронного программирования - возможность выполнять операции ввода-вывода без блокировки основного потока выполнения.

#### Операции с файлами

Стандартная библиотека Python не предоставляет асинхронное API для работы с файлами. Вместо этого используется библиотека `aiofiles`:

```python
import aiofiles

async def read_file(filename):
    async with aiofiles.open(filename, 'r') as file:
        return await file.read()

async def write_file(filename, content):
    async with aiofiles.open(filename, 'w') as file:
        await file.write(content)
```

#### Сетевые операции

Для сетевых операций в asyncio есть встроенные примитивы:

```python
import asyncio

async def tcp_echo_client():
    # Подключение к серверу
    reader, writer = await asyncio.open_connection('127.0.0.1', 8888)
    
    # Отправка данных
    writer.write(b'Hello, World!')
    await writer.drain()
    
    # Получение ответа
    data = await reader.read(100)
    print(f'Received: {data.decode()}')
    
    # Закрытие соединения
    writer.close()
    await writer.wait_closed()
```

### HTTP-запросы с aiohttp

Одно из самых распространенных применений асинхронного ввода-вывода - выполнение HTTP-запросов:

```python
import aiohttp
import asyncio

async def fetch(session, url):
    async with session.get(url) as response:
        return await response.text()

async def main():
    urls = [
        "https://example.com",
        "https://example.org",
        "https://example.net"
    ]
    
    async with aiohttp.ClientSession() as session:
        tasks = [fetch(session, url) for url in urls]
        results = await asyncio.gather(*tasks)
        
        for url, result in zip(urls, results):
            print(f"Размер содержимого {url}: {len(result)} байт")

asyncio.run(main())
```

### Асинхронные базы данных

Для работы с базами данных также существуют асинхронные драйверы:

```python
import asyncpg
import asyncio

async def get_users():
    # Установка соединения с PostgreSQL
    conn = await asyncpg.connect(
        user='postgres',
        password='password',
        database='database',
        host='127.0.0.1'
    )
    
    # Выполнение запроса
    users = await conn.fetch('SELECT * FROM users')
    
    # Закрытие соединения
    await conn.close()
    
    return users

asyncio.run(get_users())
```

### Асинхронные контекстные менеджеры

Асинхронный код может использовать специальные асинхронные контекстные менеджеры:

```python
class AsyncContextManager:
    async def __aenter__(self):
        print("Вход в контекстный менеджер")
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        print("Выход из контекстного менеджера")
        # Обработка исключений если нужно

async def main():
    async with AsyncContextManager() as manager:
        print("Внутри контекстного менеджера")

asyncio.run(main())
```

### Преимущества и недостатки асинхронного ввода-вывода

**Преимущества:**
- Высокая пропускная способность для I/O-bound приложений
- Эффективное использование ресурсов
- Масштабируемость без накладных расходов на потоки
- Детерминированное выполнение (в отличие от многопоточности)

**Недостатки:**
- Требуется переписывание кода для использования async/await
- Смешивание синхронного и асинхронного кода может быть сложным
- Отладка может быть затруднена
- Блокирование событийного цикла CPU-bound задачами

## 4. Async/await синтаксис

### Основы async/await

Ключевые слова `async` и `await` были введены в Python 3.5 для упрощения написания асинхронного кода. Они являются синтаксическим сахаром над генераторами и футурами, которые использовались для корутин в более ранних версиях.

#### Определение асинхронных функций

Асинхронная функция (корутина) определяется с помощью ключевого слова `async`:

```python
async def my_coroutine():
    # тело корутины
    return result
```

Асинхронные функции всегда возвращают объект-корутину, который должен быть запущен в событийном цикле.

#### Использование await

Ключевое слово `await` приостанавливает выполнение асинхронной функции до тех пор, пока awaitable-объект не завершится:

```python
async def fetch_data():
    # Приостанавливает корутину fetch_data, пока другая корутина не завершится
    result = await another_coroutine()
    return result
```

`await` можно использовать только внутри асинхронных функций.

### Awaitable объекты

В Python существует три типа объектов, которые можно использовать с `await`:

1. **Корутины** (созданные с помощью `async def` или `@asyncio.coroutine`)
2. **Задачи** (объекты `asyncio.Task`)
3. **Футуры** (объекты `asyncio.Future`)

Любой объект, реализующий метод `__await__`, который возвращает итератор, также может быть awaitable.

```python
async def main():
    # Ожидание корутины
    result1 = await async_function()
    
    # Ожидание задачи
    task = asyncio.create_task(async_function())
    result2 = await task
    
    # Ожидание футуры
    future = asyncio.Future()
    asyncio.create_task(set_future_result(future))
    result3 = await future

async def set_future_result(future):
    await asyncio.sleep(1)
    future.set_result("результат")
```

### Асинхронные генераторы и итераторы

#### Асинхронные генераторы

Асинхронные генераторы - это функции, определенные с помощью `async def`, которые используют `yield`:

```python
async def async_generator():
    for i in range(5):
        await asyncio.sleep(1)
        yield i

async def main():
    async for i in async_generator():
        print(i)
```

#### Асинхронные итераторы

Асинхронные итераторы - это объекты, реализующие методы `__aiter__` и `__anext__`:

```python
class AsyncIterator:
    def __init__(self, limit):
        self.limit = limit
        self.counter = 0
    
    def __aiter__(self):
        return self
    
    async def __anext__(self):
        if self.counter < self.limit:
            await asyncio.sleep(1)
            self.counter += 1
            return self.counter - 1
        else:
            raise StopAsyncIteration

async def main():
    async for i in AsyncIterator(5):
        print(i)
```

### Асинхронные контекстные менеджеры

Асинхронные контекстные менеджеры используются с `async with` и реализуют методы `__aenter__` и `__aexit__`:

```python
class AsyncContextManager:
    async def __aenter__(self):
        print("Вход в контекст")
        await asyncio.sleep(1)
        return "значение контекста"
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        print("Выход из контекста")
        await asyncio.sleep(1)
        # Возврат True подавит исключение, если оно возникло

async def main():
    async with AsyncContextManager() as value:
        print(f"Получено значение: {value}")
```

### Типичные ошибки при работе с async/await

#### 1. Забыли await

```python
async def fetch_data():
    return "данные"

async def main():
    # Неправильно: не используется await
    result = fetch_data()  # result будет корутиной, а не строкой "данные"
    
    # Правильно:
    result = await fetch_data()
```

#### 2. Использование await за пределами async функции

```python
# Неправильно: await используется в синхронной функции
def sync_function():
    result = await async_function()  # Вызовет SyntaxError
    
# Правильно:
async def async_function():
    result = await another_async_function()
```

#### 3. Блокирование событийного цикла

```python
import time

async def blocking_coroutine():
    # Неправильно: блокирует событийный цикл
    time.sleep(5)  # Используется блокирующий sleep
    
    # Правильно:
    await asyncio.sleep(5)  # Использует неблокирующий sleep
```

#### 4. Неправильная обработка исключений

```python
async def main():
    try:
        await risky_coroutine()
    except Exception as e:
        print(f"Перехвачено исключение: {e}")
        
    # Неправильно: исключения в создаваемых задачах не будут обработаны
    asyncio.create_task(risky_coroutine())
    
    # Правильно:
    task = asyncio.create_task(risky_coroutine())
    try:
        await task
    except Exception as e:
        print(f"Перехвачено исключение задачи: {e}")
```

### Примеры использования async/await

#### Web-скрапинг с aiohttp и BeautifulSoup

```python
import aiohttp
import asyncio
from bs4 import BeautifulSoup

async def fetch_page(session, url):
    async with session.get(url) as response:
        return await response.text()

async def parse_page(url):
    async with aiohttp.ClientSession() as session:
        html = await fetch_page(session, url)
        soup = BeautifulSoup(html, 'html.parser')
        title = soup.title.string if soup.title else "Без заголовка"
        return url, title

async def main():
    urls = [
        "https://python.org",
        "https://github.com",
        "https://stackoverflow.com"
    ]
    
    tasks = [parse_page(url) for url in urls]
    results = await asyncio.gather(*tasks)
    
    for url, title in results:
        print(f"{url}: {title}")

asyncio.run(main())
```

#### Асинхронная работа с файлами

```python
import aiofiles
import asyncio
import os

async def read_file(filename):
    async with aiofiles.open(filename, 'r') as file:
        return await file.read()

async def write_file(filename, content):
    async with aiofiles.open(filename, 'w') as file:
        await file.write(content)

async def process_files(directory):
    tasks = []
    
    # Чтение всех текстовых файлов в директории
    for filename in os.listdir(directory):
        if filename.endswith('.txt'):
            filepath = os.path.join(directory, filename)
            task = asyncio.create_task(read_and_process(filepath))
            tasks.append(task)
    
    return await asyncio.gather(*tasks)

async def read_and_process(filepath):
    content = await read_file(filepath)
    processed = content.upper()  # Простая обработка: преобразование в верхний регистр
    output_path = filepath + '.processed'
    await write_file(output_path, processed)
    return filepath, len(content)

asyncio.run(process_files('/path/to/directory'))
```

## 5. Asyncio и работа с ним

### Введение в Asyncio

`asyncio` - это стандартная библиотека Python для написания асинхронного кода с использованием синтаксиса `async`/`await`. Она предоставляет:

- Событийный цикл (event loop)
- Примитивы для работы с корутинами
- Транспорты и протоколы для сетевого программирования
- Инструменты синхронизации
- Абстракции для работы с процессами и подпроцессами

### Основные компоненты asyncio

#### Событийный цикл

Событийный цикл - ядро всего асинхронного приложения. Он отвечает за выполнение корутин, обработку колбэков и сетевых событий.

```python
import asyncio

# Получение текущего событийного цикла
loop = asyncio.get_event_loop()

# Создание нового событийного цикла
new_loop = asyncio.new_event_loop()
asyncio.set_event_loop(new_loop)

# Запуск корутины в событийном цикле (устаревший метод)
loop.run_until_complete(my_coroutine())

# Современный способ запуска корутины (Python 3.7+)
asyncio.run(my_coroutine())
```

#### Создание и управление задачами

Задачи (Tasks) - это способ запуска корутин в событийном цикле и отслеживания их выполнения:

```python
import asyncio

async def my_coroutine(seconds):
    print(f"Засыпаю на {seconds} секунд")
    await asyncio.sleep(seconds)
    print(f"Проснулся через {seconds} секунд")
    return seconds

async def main():
    # Создание задачи
    task1 = asyncio.create_task(my_coroutine(1))
    task2 = asyncio.create_task(my_coroutine(2))
    
    # Ожидание завершения задачи
    result1 = await task1
    result2 = await task2
    
    print(f"Результаты: {result1}, {result2}")
    
    # Создание и ожидание задачи в одном выражении (для Python 3.7+)
    result3 = await asyncio.create_task(my_coroutine(3))
    print(f"Результат задачи 3: {result3}")

asyncio.run(main())
```

#### Запуск корутин параллельно

Для запуска нескольких корутин параллельно используются функции `asyncio.gather()` и `asyncio.wait()`:

```python
import asyncio
import time

async def long_operation(name, seconds):
    print(f"Операция {name} началась")
    await asyncio.sleep(seconds)  # Имитация долгой операции
    print(f"Операция {name} завершена через {seconds} секунд")
    return f"Результат {name}"

async def main():
    start = time.time()
    
    # gather запускает корутины параллельно и собирает их результаты
    results = await asyncio.gather(
        long_operation("A", 3),
        long_operation("B", 1),
        long_operation("C", 4)
    )
    
    print(f"Все операции заняли {time.time() - start:.2f} секунд")
    print(f"Результаты: {results}")
    
    # wait предоставляет больше контроля над выполнением корутин
    start = time.time()
    tasks = [
        asyncio.create_task(long_operation("X", 3)),
        asyncio.create_task(long_operation("Y", 2)),
        asyncio.create_task(long_operation("Z", 1))
    ]
    
    # Ожидаем завершения первой задачи
    done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)
    
    print(f"Первая задача завершена через {time.time() - start:.2f} секунд")
    print(f"Завершенные задачи: {len(done)}")
    print(f"Ожидающие задачи: {len(pending)}")
    
    # Отменяем оставшиеся задачи
    for task in pending:
        task.cancel()
    
    # Ожидаем завершения всех задач (включая отмененные)
    await asyncio.wait(pending)

asyncio.run(main())
```

### Таймауты и отмена операций

#### Установка таймаута

Часто необходимо ограничить время выполнения асинхронной операции:

```python
import asyncio

async def long_operation():
    await asyncio.sleep(10)  # Операция, которая занимает 10 секунд
    return "Результат"

async def main():
    try:
        # Ожидаем long_operation() с таймаутом в 2 секунды
        result = await asyncio.wait_for(long_operation(), timeout=2)
        print(result)
    except asyncio.TimeoutError:
        print("Операция превысила таймаут")

asyncio.run(main())
```

#### Отмена задач

Задачи можно отменить до их завершения:

```python
import asyncio

async def long_operation():
    try:
        print("Операция началась")
        await asyncio.sleep(5)
        print("Операция завершена")
        return "Результат"
    except asyncio.CancelledError:
        print("Операция была отменена")
        raise  # Переброс исключения для правильной обработки отмены

async def main():
    # Создаем задачу
    task = asyncio.create_task(long_operation())
    
    # Ждем 2 секунды
    await asyncio.sleep(2)
    
    # Отменяем задачу
    task.cancel()
    
    try:
        # Пытаемся дождаться отмененной задачи
        await task
    except asyncio.CancelledError:
        print("Задача была успешно отменена")

asyncio.run(main())
```

#### Защита от отмены

Иногда необходимо защитить корутину от отмены, например, для выполнения критичных операций очистки:

```python
import asyncio

async def critical_operation():
    try:
        # Основная операция, которая может быть отменена
        await asyncio.sleep(5)
        return "Результат"
    finally:
        # Этот код выполнится даже при отмене корутины
        print("Выполняем критическую очистку")
        await asyncio.shield(cleanup())  # Защищаем cleanup() от отмены

async def cleanup():
    print("Начинаем очистку")
    await asyncio.sleep(1)  # Имитация операции очистки
    print("Очистка завершена")

async def main():
    task = asyncio.create_task(critical_operation())
    await asyncio.sleep(2)
    task.cancel()
    
    try:
        await task
    except asyncio.CancelledError:
        print("Основная задача отменена")

asyncio.run(main())
```

### Работа с сетью в asyncio

#### Низкоуровневые сокеты

asyncio предоставляет низкоуровневые примитивы для работы с сетью:

```python
import asyncio

async def tcp_echo_client():
    # Подключение к серверу
    reader, writer = await asyncio.open_connection('127.0.0.1', 8888)
    
    # Отправка данных
    message = "Hello, server!"
    print(f'Отправка: {message}')
    writer.write(message.encode())
    await writer.drain()
    
    # Получение ответа
    data = await reader.read(100)
    print(f'Получено: {data.decode()}')
    
    # Закрытие соединения
    writer.close()
    await writer.wait_closed()

async def echo_server(reader, writer):
    # Чтение данных
    data = await reader.read(100)
    message = data.decode()
    addr = writer.get_extra_info('peername')
    
    print(f"Получено {message} от {addr}")
    
    # Отправка ответа
    writer.write(data)
    await writer.drain()
    
    # Закрытие соединения
    writer.close()

async def start_server():
    server = await asyncio.start_server(
        echo_server, '127.0.0.1', 8888)
    
    addr = server.sockets[0].getsockname()
    print(f'Сервер запущен на {addr}')
    
    async with server:
        await server.serve_forever()

# Запуск сервера
# asyncio.run(start_server())

# Запуск клиента
# asyncio.run(tcp_echo_client())
```

#### Работа с протоколами

asyncio также предоставляет абстракции протоколов и транспортов для более высокоуровневой работы с сетью:

```python
import asyncio

class EchoClientProtocol(asyncio.Protocol):
    def __init__(self, message, on_con_lost):
        self.message = message
        self.on_con_lost = on_con_lost
        
    def connection_made(self, transport):
        transport.write(self.message.encode())
        print(f'Данные отправлены: {self.message}')
        
    def data_received(self, data):
        print(f'Данные получены: {data.decode()}')
        
    def connection_lost(self, exc):
        print('Соединение закрыто')
        self.on_con_lost.set_result(True)

async def main():
    # Получаем событийный цикл
    loop = asyncio.get_running_loop()
    
    # Создаем будущий объект для уведомления о завершении
    on_con_lost = loop.create_future()
    
    # Создаем и запускаем транспорт и протокол
    transport, protocol = await loop.create_connection(
        lambda: EchoClientProtocol('Hello, World!', on_con_lost),
        '127.0.0.1', 8888)
    
    # Ожидаем закрытия соединения
    try:
        await on_con_lost
    finally:
        transport.close()

# asyncio.run(main())
```

### Примитивы синхронизации

asyncio предоставляет примитивы синхронизации, аналогичные тем, что используются в многопоточном программировании, но адаптированные для работы с корутинами.

#### Lock (Блокировка)

```python
import asyncio

async def worker(lock, number):
    print(f"Воркер {number}: ожидает блокировку")
    async with lock:
        print(f"Воркер {number}: получил блокировку")
        await asyncio.sleep(1)  # Имитация работы с общим ресурсом
        print(f"Воркер {number}: освобождает блокировку")

async def main():
    lock = asyncio.Lock()
    
    # Запускаем несколько воркеров, которые конкурируют за блокировку
    await asyncio.gather(
        worker(lock, 1),
        worker(lock, 2),
        worker(lock, 3)
    )

asyncio.run(main())
```

#### Semaphore (Семафор)

```python
import asyncio

async def worker(semaphore, number):
    print(f"Воркер {number}: ожидает доступ")
    async with semaphore:
        print(f"Воркер {number}: получил доступ")
        await asyncio.sleep(1)  # Имитация работы с ограниченным ресурсом
        print(f"Воркер {number}: освобождает ресурс")

async def main():
    # Семафор, ограничивающий до 2 одновременных доступов
    semaphore = asyncio.Semaphore(2)
    
    # Запускаем несколько воркеров
    await asyncio.gather(
        worker(semaphore, 1),
        worker(semaphore, 2),
        worker(semaphore, 3),
        worker(semaphore, 4),
        worker(semaphore, 5)
    )

asyncio.run(main())
```

#### Event (Событие)

```python
import asyncio

async def waiter(event, number):
    print(f"Ожидатель {number}: ждет события")
    await event.wait()
    print(f"Ожидатель {number}: событие произошло!")

async def setter(event, delay):
    print(f"Установщик: ждет {delay} секунд перед установкой события")
    await asyncio.sleep(delay)
    print("Установщик: устанавливает событие")
    event.set()

async def main():
    event = asyncio.Event()
    
    # Запускаем несколько ожидателей и одного установщика
    await asyncio.gather(
        waiter(event, 1),
        waiter(event, 2),
        waiter(event, 3),
        setter(event, 3)
    )

asyncio.run(main())
```

#### Condition (Условие)

```python
import asyncio

async def consumer(condition, number, queue):
    async with condition:
        print(f"Потребитель {number}: ждет данные")
        await condition.wait()
        # Получение и обработка данных
        data = queue.pop(0)
        print(f"Потребитель {number}: получил данные {data}")

async def producer(condition, queue):
    await asyncio.sleep(1)  # Имитация подготовки данных
    
    async with condition:
        # Добавление данных в очередь
        queue.append("новые данные")
        print("Производитель: данные готовы")
        # Уведомление всех потребителей
        condition.notify_all()

async def main():
    condition = asyncio.Condition()
    queue = []  # Общая очередь данных
    
    # Запускаем нескольких потребителей и одного производителя
    await asyncio.gather(
        consumer(condition, 1, queue),
        consumer(condition, 2, queue),
        consumer(condition, 3, queue),
        producer(condition, queue)
    )

asyncio.run(main())
```

### Продвинутые возможности asyncio

#### Futures

Futures представляют собой низкоуровневый механизм для представления результата асинхронной операции:

```python
import asyncio

async def set_after_delay(future, delay, value):
    await asyncio.sleep(delay)
    future.set_result(value)

async def main():
    # Создаем Future
    future = asyncio.Future()
    
    # Запускаем задачу, которая установит результат Future через 2 секунды
    asyncio.create_task(set_after_delay(future, 2, "результат"))
    
    print("Ожидаем результат...")
    result = await future
    print(f"Получен результат: {result}")

asyncio.run(main())
```

#### Подпроцессы

asyncio может выполнять внешние команды асинхронно:

```python
import asyncio
import sys

async def run_command(*args):
    # Создание подпроцесса
    process = await asyncio.create_subprocess_exec(
        *args,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )
    
    # Ожидание завершения и чтение stdout/stderr
    stdout, stderr = await process.communicate()
    
    # Декодирование вывода
    stdout = stdout.decode() if stdout else ''
    stderr = stderr.decode() if stderr else ''
    
    return process.returncode, stdout, stderr

async def main():
    # Выполнение команды 'ls -la' (Unix) или 'dir' (Windows)
    command = ['dir'] if sys.platform == 'win32' else ['ls', '-la']
    
    print(f"Выполнение команды: {' '.join(command)}")
    returncode, stdout, stderr = await run_command(*command)
    
    print(f"Код возврата: {returncode}")
    print(f"Вывод:\n{stdout}")
    
    if stderr:
        print(f"Ошибка:\n{stderr}")

asyncio.run(main())
```

#### Очереди

Очереди в asyncio позволяют реализовать паттерн "производитель-потребитель":

```python
import asyncio
import random

async def producer(queue, name):
    for i in range(5):
        # Имитация производства данных
        await asyncio.sleep(random.uniform(0.1, 0.5))
        item = f"{name}-{i}"
        
        # Помещение данных в очередь
        await queue.put(item)
        print(f"Производитель {name} добавил: {item}")

async def consumer(queue, name):
    while True:
        # Ожидание данных из очереди
        item = await queue.get()
        
        # Имитация обработки данных
        await asyncio.sleep(random.uniform(0.5, 1.0))
        print(f"Потребитель {name} обработал: {item}")
        
        # Сообщаем очереди о завершении обработки элемента
        queue.task_done()

async def main():
    # Создаем очередь
    queue = asyncio.Queue()
    
    # Запускаем потребителей
    consumers = [asyncio.create_task(consumer(queue, f"потребитель-{i}"))
                for i in range(3)]
    
    # Запускаем производителей
    producers = [producer(queue, f"производитель-{i}") for i in range(2)]
    await asyncio.gather(*producers)
    
    # Ждем, пока очередь не будет полностью обработана
    await queue.join()
    
    # Отменяем потребителей
    for c in consumers:
        c.cancel()

asyncio.run(main())
```

### Лучшие практики работы с asyncio

1. **Избегайте блокирующих операций в событийном цикле**
   ```python
   async def bad_practice():
       # Блокирует событийный цикл!
       import time
       time.sleep(1)
       
   async def good_practice():
       # Не блокирует событийный цикл
       await asyncio.sleep(1)
   ```

2. **Используйте `asyncio.run()` как точку входа**
   ```python
   # Правильно (Python 3.7+):
   if __name__ == "__main__":
       asyncio.run(main())
       
   # Устаревший способ (избегайте):
   if __name__ == "__main__":
       loop = asyncio.get_event_loop()
       loop.run_until_complete(main())
       loop.close()
   ```

3. **Всегда обрабатывайте исключения в асинхронных задачах**
   ```python
   async def main():
       try:
           task = asyncio.create_task(risky_coroutine())
           await task
       except Exception as e:
           print(f"Ошибка: {e}")
   ```

4. **Используйте `asyncio.gather()` для параллельного выполнения корутин**
   ```python
   async def main():
       results = await asyncio.gather(
           coroutine1(),
           coroutine2(),
           coroutine3()
       )
   ```

5. **Закрывайте ресурсы правильно**
   ```python
   async def main():
       async with aiohttp.ClientSession() as session:
           # Используйте session здесь
           # После выхода из блока сессия будет автоматически закрыта
   ```

6. **Устанавливайте таймауты для предотвращения бесконечного ожидания**
   ```python
   async def main():
       try:
           result = await asyncio.wait_for(long_operation(), timeout=5)
       except asyncio.TimeoutError:
           print("Операция не завершилась в течение 5 секунд")
   ```

7. **Используйте `asyncio.shield()` для защиты критичных операций от отмены**
   ```python
   async def main():
       try:
           # Эта операция будет защищена от отмены
           await asyncio.shield(critical_operation())
       except asyncio.CancelledError:
           # Обработка отмены задачи
   ```

## 6. Конкурентное программирование

Конкурентное программирование в Python позволяет выполнять несколько задач параллельно, что может значительно повысить производительность приложений, особенно при операциях ввода-вывода.

### Что такое конкурентность

**Конкурентность** - это способность программы выполнять несколько задач, перекрывая их во времени. Это не обязательно означает параллельное выполнение на нескольких процессорах (параллелизм), а скорее эффективное переключение между задачами для создания иллюзии одновременного выполнения.

**Параллелизм** - это подмножество конкурентности, когда задачи действительно выполняются одновременно на разных процессорах или ядрах.

### Модели конкурентности в Python

В Python существует несколько моделей конкурентности:

1. **Многопоточность (Threading)** - использует потоки операционной системы для выполнения нескольких задач внутри одного процесса.
2. **Многопроцессность (Multiprocessing)** - использует несколько процессов для выполнения задач параллельно.
3. **Асинхронное программирование (Asyncio)** - использует корутины и событийный цикл для неблокирующего выполнения задач.
4. **Комбинированные подходы** - объединение вышеуказанных методов для оптимального использования ресурсов.

### Выбор подходящей модели конкурентности

| Модель | Когда использовать | Преимущества | Недостатки |
|--------|-------------------|-------------|------------|
| **Threading** | I/O-bound задачи с общими данными | Низкие накладные расходы, общая память | GIL, ограничения для CPU-bound задач |
| **Multiprocessing** | CPU-bound задачи | Обход GIL, использование всех ядер | Высокие накладные расходы, сложное межпроцессное взаимодействие |
| **Asyncio** | I/O-bound задачи с высокой конкурентностью | Низкие накладные расходы, легкое управление | Требует особого стиля программирования, неэффективно для CPU-bound задач |

### Конкурентность с использованием asyncio

Asyncio предоставляет простой способ организации конкурентного выполнения множества задач:

```python
import asyncio
import time

async def task(name, delay):
    print(f"Задача {name} начата")
    await asyncio.sleep(delay)  # Неблокирующая пауза
    print(f"Задача {name} завершена через {delay} секунд")
    return f"Результат {name}"

async def main():
    start = time.time()
    
    # Создаем список корутин
    tasks = [
        task("A", 3),
        task("B", 1),
        task("C", 2),
        task("D", 4),
        task("E", 2)
    ]
    
    # Запускаем все корутины конкурентно
    results = await asyncio.gather(*tasks)
    
    end = time.time()
    print(f"Все задачи выполнены за {end - start:.2f} секунд")
    print(f"Результаты: {results}")

asyncio.run(main())
```

### Комбинирование asyncio с threading/multiprocessing

Иногда необходимо комбинировать разные модели конкурентности для оптимальной производительности. Например, при работе с CPU-bound задачами в асинхронном приложении:

```python
import asyncio
import concurrent.futures
import time

# CPU-bound задача (выполняется в отдельном потоке/процессе)
def cpu_bound_task(n):
    result = 0
    for i in range(n):
        result += i * i
    return result

# I/O-bound задача (выполняется асинхронно)
async def io_bound_task(delay):
    await asyncio.sleep(delay)
    return f"Готово через {delay} секунд"

async def main():
    start = time.time()
    
    # Создаем пул процессов для CPU-bound задач
    with concurrent.futures.ProcessPoolExecutor() as pool:
        # Запускаем CPU-bound задачи в пуле процессов
        cpu_tasks = [
            pool.submit(cpu_bound_task, 10_000_000),
            pool.submit(cpu_bound_task, 20_000_000),
            pool.submit(cpu_bound_task, 30_000_000)
        ]
        
        # Запускаем I/O-bound задачи асинхронно
        io_tasks = [
            io_bound_task(1),
            io_bound_task(2),
            io_bound_task(3)
        ]
        
        # Ожидаем завершения CPU-bound задач (через executor)
        cpu_results = await asyncio.gather(
            *(asyncio.wrap_future(task) for task in cpu_tasks)
        )
        
        # Ожидаем завершения I/O-bound задач
        io_results = await asyncio.gather(*io_tasks)
    
    end = time.time()
    print(f"Все задачи выполнены за {end - start:.2f} секунд")
    print(f"CPU результаты: {cpu_results}")
    print(f"I/O результаты: {io_results}")

asyncio.run(main())
```

### Паттерны конкурентного программирования

#### 1. Модель "Производитель-Потребитель"

```python
import asyncio
import random

async def producer(queue, id):
    for i in range(5):
        await asyncio.sleep(random.random())
        item = f"Item-{id}-{i}"
        await queue.put(item)
        print(f"Производитель {id} произвел {item}")

async def consumer(queue, id):
    while True:
        item = await queue.get()
        if item is None:  # Сигнал о завершении
            queue.task_done()
            break
            
        await asyncio.sleep(random.random() * 2)  # Имитация обработки
        print(f"Потребитель {id} обработал {item}")
        queue.task_done()

async def main():
    queue = asyncio.Queue()
    
    # Создаем производителей
    producers = [producer(queue, i) for i in range(3)]
    
    # Создаем потребителей
    consumers = [asyncio.create_task(consumer(queue, i)) for i in range(2)]
    
    # Запускаем производителей
    await asyncio.gather(*producers)
    
    # Ждем, пока все задачи будут завершены
    await queue.join()
    
    # Отправляем сигнал завершения потребителям
    for _ in range(len(consumers)):
        await queue.put(None)
    
    # Ждем завершения потребителей
    await asyncio.gather(*consumers)

asyncio.run(main())
```

#### 2. Модель "Рабочий пул"

```python
import asyncio
import random
import time

# Имитация задачи
async def worker_task(task_id):
    # Случайное время выполнения от 0.5 до 2 секунд
    execution_time = random.uniform(0.5, 2)
    await asyncio.sleep(execution_time)
    return f"Задача {task_id} выполнена за {execution_time:.2f} сек"

# Рабочий процесс
async def worker(name, queue, results):
    while True:
        # Получаем задачу из очереди
        task_id = await queue.get()
        
        if task_id is None:  # Сигнал о завершении
            queue.task_done()
            break
            
        print(f"Рабочий {name} начал задачу {task_id}")
        
        # Выполняем задачу
        result = await worker_task(task_id)
        
        # Сохраняем результат
        results[task_id] = result
        
        print(f"Рабочий {name} завершил задачу {task_id}")
        
        # Помечаем задачу как выполненную
        queue.task_done()

async def main():
    # Количество рабочих
    num_workers = 3
    
    # Количество задач
    num_tasks = 15
    
    # Очередь задач
    task_queue = asyncio.Queue()
    
    # Словарь для хранения результатов
    results = {}
    
    # Создаем и запускаем рабочих
    workers = []
    for i in range(num_workers):
        task = asyncio.create_task(worker(f"worker-{i}", task_queue, results))
        workers.append(task)
    
    # Добавляем задачи в очередь
    for i in range(num_tasks):
        await task_queue.put(i)
    
    # Ждем завершения всех задач
    start = time.time()
    await task_queue.join()
    end = time.time()
    
    # Отправляем сигнал о завершении рабочим
    for _ in range(num_workers):
        await task_queue.put(None)
    
    # Ждем завершения всех рабочих
    await asyncio.gather(*workers)
    
    print(f"Все задачи выполнены за {end - start:.2f} секунд")
    
    # Выводим результаты
    for task_id in sorted(results.keys()):
        print(results[task_id])

asyncio.run(main())
```

#### 3. Модель "Фан-аут/Фан-ин"

```python
import asyncio
import random

# Фаза 1 - один источник данных
async def data_source():
    data = []
    for i in range(10):
        await asyncio.sleep(0.1)
        data.append(i)
    return data

# Фаза 2 - параллельная обработка (фан-аут)
async def process_item(item):
    await asyncio.sleep(random.uniform(0.5, 1.0))  # Имитация обработки
    return item * item

# Фаза 3 - агрегация результатов (фан-ин)
async def aggregate_results(results):
    await asyncio.sleep(0.2)  # Имитация агрегации
    return sum(results)

async def main():
    # Фаза 1: получение данных
    data = await data_source()
    print(f"Исходные данные: {data}")
    
    # Фаза 2: параллельная обработка каждого элемента (фан-аут)
    process_tasks = [process_item(item) for item in data]
    processed_data = await asyncio.gather(*process_tasks)
    print(f"Обработанные данные: {processed_data}")
    
    # Фаза 3: агрегация результатов (фан-ин)
    final_result = await aggregate_results(processed_data)
    print(f"Итоговый результат: {final_result}")

asyncio.run(main())
```

#### 4. Модель "Конвейер"

```python
import asyncio
import random

# Стадия 1: генерация данных
async def stage1(output_queue):
    for i in range(10):
        await asyncio.sleep(random.uniform(0.1, 0.3))
        item = f"item-{i}"
        await output_queue.put(item)
        print(f"Стадия 1: сгенерирован {item}")
    
    # Сигнал о завершении
    await output_queue.put(None)

# Стадия 2: обработка данных
async def stage2(input_queue, output_queue):
    while True:
        item = await input_queue.get()
        
        if item is None:
            # Передаем сигнал о завершении
            await output_queue.put(None)
            break
        
        await asyncio.sleep(random.uniform(0.2, 0.5))
        processed_item = f"processed-{item}"
        await output_queue.put(processed_item)
        print(f"Стадия 2: обработан {item} -> {processed_item}")
        
        input_queue.task_done()

# Стадия 3: финальная обработка
async def stage3(input_queue, results):
    while True:
        item = await input_queue.get()
        
        if item is None:
            break
        
        await asyncio.sleep(random.uniform(0.1, 0.4))
        final_item = f"final-{item}"
        results.append(final_item)
        print(f"Стадия 3: завершен {item} -> {final_item}")
        
        input_queue.task_done()

async def pipeline():
    # Очереди между стадиями
    queue1_to_2 = asyncio.Queue()
    queue2_to_3 = asyncio.Queue()
    
    # Список результатов
    results = []
    
    # Запуск всех стадий конвейера
    stage1_task = asyncio.create_task(stage1(queue1_to_2))
    stage2_task = asyncio.create_task(stage2(queue1_to_2, queue2_to_3))
    stage3_task = asyncio.create_task(stage3(queue2_to_3, results))
    
    # Ожидание завершения всех стадий
    await stage1_task
    await queue1_to_2.join()
    await stage2_task
    await queue2_to_3.join()
    await stage3_task
    
    return results

async def main():
    print("Запуск конвейера...")
    results = await pipeline()
    print(f"Конвейер завершен с результатами: {results}")

asyncio.run(main())
```

### Управление конкурентностью

#### Ограничение количества одновременных задач

Иногда необходимо ограничить количество одновременно выполняемых задач, чтобы избежать перегрузки системы. Для этого можно использовать семафоры:

```python
import asyncio
import random

async def worker(semaphore, name, delay):
    async with semaphore:
        print(f"Рабочий {name} начал выполнение")
        await asyncio.sleep(delay)  # Имитация работы
        print(f"Рабочий {name} завершил выполнение через {delay:.2f} секунд")
        return f"Результат от {name}"

async def main():
    # Ограничиваем до 3 одновременных задач
    semaphore = asyncio.Semaphore(3)
    
    # Создаем список из 10 задач
    tasks = [
        worker(semaphore, f"task-{i}", random.uniform(1, 3))
        for i in range(10)
    ]
    
    # Запускаем все задачи
    results = await asyncio.gather(*tasks)
    
    print(f"Все задачи завершены с результатами: {results}")

asyncio.run(main())
```

#### Отмена задач при ошибке

Иногда необходимо отменить все выполняющиеся задачи, если одна из них завершается с ошибкой:

```python
import asyncio
import random

async def risky_task(name, fail_probability=0.3):
    print(f"Задача {name} начата")
    await asyncio.sleep(random.uniform(0.5, 2))
    
    # С некоторой вероятностью завершаемся с ошибкой
    if random.random() < fail_probability:
        print(f"Задача {name} завершилась с ошибкой")
        raise Exception(f"Ошибка в задаче {name}")
    
    print(f"Задача {name} успешно завершена")
    return f"Результат от {name}"

async def main():
    # Создаем и запускаем задачи
    tasks = [
        asyncio.create_task(risky_task(f"task-{i}"))
        for i in range(5)
    ]
    
    # Ждем завершения первой задачи (успешно или с ошибкой)
    done, pending = await asyncio.wait(
        tasks,
        return_when=asyncio.FIRST_EXCEPTION
    )
    
    # Проверяем, есть ли задачи с ошибками
    for task in done:
        if task.exception():
            print(f"Обнаружена ошибка: {task.exception()}")
            
            # Отменяем все оставшиеся задачи
            for pending_task in pending:
                print(f"Отмена задачи {pending_task}")
                pending_task.cancel()
            
            break
    
    # Ждем завершения всех задач (включая отмененные)
    await asyncio.wait(pending)
    
    print("Все задачи завершены или отменены")

asyncio.run(main())
```

#### Таймауты для группы задач

Для ограничения общего времени выполнения группы задач можно использовать `asyncio.wait_for()`:

```python
import asyncio
import random

async def long_task(name):
    delay = random.uniform(1, 5)
    print(f"Задача {name} запущена (планируемое время: {delay:.2f}с)")
    try:
        await asyncio.sleep(delay)
        print(f"Задача {name} завершена")
        return f"Результат от {name}"
    except asyncio.CancelledError:
        print(f"Задача {name} была отменена")
        raise

async def main():
    # Создаем список задач
    tasks = [
        asyncio.create_task(long_task(f"task-{i}"))
        for i in range(5)
    ]
    
    try:
        # Устанавливаем таймаут в 3 секунды для всей группы задач
        results = await asyncio.wait_for(asyncio.gather(*tasks), timeout=3)
        print(f"Все задачи завершены с результатами: {results}")
    except asyncio.TimeoutError:
        print("Превышен таймаут для группы задач")
        
        # Отменяем все незавершенные задачи
        for task in tasks:
            if not task.done():
                task.cancel()
        
        # Ждем завершения отмененных задач
        await asyncio.gather(*tasks, return_exceptions=True)
    
    print("Завершение программы")

asyncio.run(main())
```

### Мониторинг и отладка конкурентного кода

#### Использование логирования

Логирование помогает отслеживать выполнение конкурентных задач:

```python
import asyncio
import logging
import random
import time

# Настройка логирования
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("concurrency_demo")

async def task_with_logging(name):
    logger.info(f"Задача {name} начата")
    
    try:
        delay = random.uniform(0.5, 2)
        logger.debug(f"Задача {name} будет выполняться {delay:.2f} секунд")
        await asyncio.sleep(delay)
        
        # Иногда генерируем ошибку
        if random.random() < 0.3:
            raise ValueError(f"Случайная ошибка в задаче {name}")
        
        logger.info(f"Задача {name} успешно завершена")
        return f"Результат от {name}"
    except Exception as e:
        logger.error(f"Ошибка в задаче {name}: {e}", exc_info=True)
        raise
    finally:
        logger.debug(f"Завершение обработки задачи {name}")

async def main():
    start_time = time.time()
    logger.info("Запуск программы")
    
    # Создаем список задач
    tasks = [
        task_with_logging(f"task-{i}")
        for i in range(5)
    ]
    
    # Запускаем все задачи и обрабатываем исключения
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # Анализируем результаты
    successful = 0
    failed = 0
    
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.warning(f"Задача task-{i} завершилась с ошибкой: {result}")
            failed += 1
        else:
            logger.info(f"Задача task-{i} вернула: {result}")
            successful += 1
    
    end_time = time.time()
    logger.info(f"Программа завершена за {end_time - start_time:.2f} секунд")
    logger.info(f"Успешно выполнено задач: {successful}, с ошибками: {failed}")

asyncio.run(main())
```

#### Отладка с помощью событийного цикла отладки

Для более подробной отладки можно включить отладочный режим для событийного цикла:

```python
import asyncio
import logging
import sys

# Включение отладки asyncio
logging.basicConfig(level=logging.DEBUG)
asyncio.get_event_loop().set_debug(True)

# Настройка подробного логирования исключений
sys.set_asyncio_debug_callback(lambda *args, **kwargs: print(f"DEBUG: {args}, {kwargs}"))

# Далее идет обычный код...
```

#### Профилирование конкурентного кода

Для профилирования можно добавить метрики:

```python
import asyncio
import time
import statistics

class Profiler:
    def __init__(self, name):
        self.name = name
        self.start_times = {}
        self.durations = {}
    
    async def run_with_profiling(self, coro, task_id):
        # Запоминаем время начала
        start = time.time()
        self.start_times[task_id] = start
        
        try:
            # Выполняем корутину
            result = await coro
            
            # Запоминаем длительность
            end = time.time()
            duration = end - start
            self.durations[task_id] = duration
            
            return result
        except Exception as e:
            # В случае ошибки также запоминаем длительность
            end = time.time()
            duration = end - start
            self.durations[task_id] = duration
            raise e
    
    def print_stats(self):
        durations = list(self.durations.values())
        
        if not durations:
            print(f"Профайлер {self.name}: нет данных")
            return
        
        print(f"Профайлер {self.name} - статистика выполнения:")
        print(f"  Всего задач: {len(durations)}")
        print(f"  Минимальное время: {min(durations):.6f}с")
        print(f"  Максимальное время: {max(durations):.6f}с")
        print(f"  Среднее время: {sum(durations) / len(durations):.6f}с")
        print(f"  Медиана: {statistics.median(durations):.6f}с")
        if len(durations) > 1:
            print(f"  Стандартное отклонение: {statistics.stdev(durations):.6f}с")

async def demo_task(id, delay):
    await asyncio.sleep(delay)
    return f"Результат задачи {id}"

async def main():
    profiler = Profiler("DemoTasks")
    
    # Создаем задачи с разными задержками
    tasks = [
        profiler.run_with_profiling(demo_task(i, i * 0.2), f"task-{i}")
        for i in range(1, 6)
    ]
    
    # Запускаем все задачи
    results = await asyncio.gather(*tasks)
    
    # Выводим результаты профилирования
    profiler.print_stats()

asyncio.run(main())
```

#### Использование asyncio.current_task() для отслеживания

```python
import asyncio
import random
import time

async def monitored_task(name):
    # Получаем текущую задачу
    task = asyncio.current_task()
    
    print(f"Задача {name} (ID: {id(task)}) начата")
    
    # Добавляем метаданные к задаче
    task.name = name
    task.start_time = time.time()
    
    # Выполняем работу
    await asyncio.sleep(random.uniform(0.5, 2))
    
    # Завершаем и обновляем метаданные
    task.end_time = time.time()
    task.duration = task.end_time - task.start_time
    
    print(f"Задача {name} завершена за {task.duration:.2f} секунд")
    return f"Результат от {name}"

async def task_monitor():
    while True:
        # Получаем все задачи из текущего цикла событий
        all_tasks = asyncio.all_tasks()
        
        # Отфильтровываем монитор и главную задачу
        monitored_tasks = [
            t for t in all_tasks 
            if hasattr(t, 'name') and t != asyncio.current_task()
        ]
        
        if not monitored_tasks:
            # Если нет задач для мониторинга, завершаем монитор
            print("Монитор: все задачи завершены")
            break
        
        # Выводим информацию о задачах
        print("\n--- Статус задач ---")
        for t in monitored_tasks:
            runtime = time.time() - t.start_time
            status = "выполняется" if not t.done() else "завершена"
            print(f"  Задача {t.name}: {status}, время выполнения: {runtime:.2f}с")
        
        # Проверяем каждую секунду
        await asyncio.sleep(1)

async def main():
    # Создаем задачи
    tasks = [
        asyncio.create_task(monitored_task(f"task-{i}"))
        for i in range(5)
    ]
    
    # Запускаем монитор
    monitor = asyncio.create_task(task_monitor())
    
    # Ждем завершения всех задач
    await asyncio.gather(*tasks)
    
    # Ждем завершения монитора
    await monitor
    
    print("Все задачи завершены")

asyncio.run(main())
```

## 7. Race conditions и их избежание

Race conditions (состояния гонки) возникают, когда несколько потоков или процессов одновременно обращаются к общим данным, и результат зависит от точного порядка выполнения операций.

### Что такое Race Condition

Race condition происходит, когда:
1. Несколько потоков или процессов имеют доступ к общим данным
2. Они пытаются изменять эти данные одновременно
3. Конечный результат зависит от точного порядка выполнения операций

Классический пример race condition:

```python
import threading

counter = 0

def increment():
    global counter
    for _ in range(100000):
        # Эти три строки не атомарны!
        current = counter  # Чтение
        current += 1       # Модификация
        counter = current  # Запись

threads = []
for _ in range(5):
    thread = threading.Thread(target=increment)
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()

print(f"Ожидается: {5 * 100000}")
print(f"Фактически: {counter}")
```

Результат будет меньше ожидаемого из-за race condition: потоки "наступают друг другу на ноги", переписывая значения друг друга.

### Типы Race Conditions

1. **Условия гонки при чтении-записи** (Read-Write Race Conditions)
   - Один поток читает данные, в то время как другой их изменяет

2. **Условия гонки при проверке-использовании** (Check-Then-Act Race Conditions)
   - Проверка условия и последующее действие не являются атомарными

3. **Условия гонки инкремента/декремента** (Increment/Decrement Race Conditions)
   - Операция изменения счетчика не является атомарной

### Выявление Race Conditions

Race conditions могут быть трудно обнаружимыми, так как они проявляются непредсказуемо. Для их выявления можно использовать:

1. **Инструменты статического анализа кода**
   - pylint, mypy с плагинами для обнаружения потенциальных race conditions

2. **Stress-тестирование**
   - Многократное выполнение программы для выявления непредсказуемого поведения

3. **Логирование и анализ**
   - Подробное логирование операций для последующего анализа

4. **Инструменты динамического анализа**
   - Инструменты типа ThreadSanitizer (хотя для Python их меньше, чем для C++)

### Стратегии предотвращения Race Conditions

#### 1. Использование блокировок (Locks)

Блокировки гарантируют, что только один поток может выполнять критическую секцию кода одновременно:

```python
import threading

counter = 0
lock = threading.Lock()

def increment():
    global counter
    for _ in range(100000):
        with lock:  # Приобретаем блокировку
            counter += 1  # Критическая секция защищена

threads = []
for _ in range(5):
    thread = threading.Thread(target=increment)
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()

print(f"Ожидается: {5 * 100000}")
print(f"Фактически: {counter}")
```

#### 2. Использование RLock (реентерабельная блокировка)

Когда один и тот же поток может несколько раз приобретать блокировку:

```python
import threading

counter = 0
lock = threading.RLock()  # Вместо обычного Lock

def increment_and_double():
    global counter
    
    with lock:  # Первое приобретение блокировки
        counter += 1
        
        with lock:  # Второе приобретение той же блокировки тем же потоком
            counter *= 2
```

#### 3. Использование семафоров (Semaphores)

Семафоры ограничивают количество потоков, которые могут одновременно выполнять критическую секцию:

```python
import threading
import time
import random

# Семафор с лимитом в 3 потока
semaphore = threading.Semaphore(3)

def worker(id):
    print(f"Поток {id} ожидает доступа")
    
    with semaphore:
        print(f"Поток {id} получил доступ")
        time.sleep(random.uniform(0.5, 2))  # Имитация работы
        print(f"Поток {id} освободил ресурс")

# Запускаем 10 потоков, но только 3 могут работать одновременно
threads = []
for i in range(10):
    thread = threading.Thread(target=worker, args=(i,))
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()
```

#### 4. Использование событий (Events)

События позволяют одному потоку сигнализировать другим о наступлении определенного условия:

```python
import threading
import time

event = threading.Event()
data = None

def producer():
    global data
    time.sleep(1)  # Имитация подготовки данных
    
    data = {"key": "value"}  # Устанавливаем данные
    
    print("Производитель: данные готовы")
    event.set()  # Сигнализируем о готовности данных

def consumer():
    print("Потребитель: ожидание данных")
    event.wait()  # Блокируется до установки события
    
    print(f"Потребитель: получены данные {data}")

# Запускаем потребителя и производителя
consumer_thread = threading.Thread(target=consumer)
producer_thread = threading.Thread(target=producer)

consumer_thread.start()
producer_thread.start()

consumer_thread.join()
producer_thread.join()
```

#### 5. Использование Condition (условных переменных)

Условные переменные позволяют потокам ждать определенного условия и быть уведомленными, когда оно наступает:

```python
import threading
import time
import random
from collections import deque

# Общая очередь и условная переменная
queue = deque()
condition = threading.Condition()
MAX_SIZE = 5

def producer(id):
    for i in range(10):
        time.sleep(random.uniform(0.1, 0.5))  # Имитация работы
        
        with condition:
            # Ждем, пока очередь не освободится
            while len(queue) >= MAX_SIZE:
                print(f"Производитель {id}: очередь заполнена, ожидание...")
                condition.wait()
            
            # Добавляем элемент в очередь
            item = f"item-{id}-{i}"
            queue.append(item)
            print(f"Производитель {id}: добавлен {item}, размер очереди {len(queue)}")
            
            # Уведомляем потребителей о новых данных
            condition.notify()

def consumer(id):
    while True:
        with condition:
            # Ждем, пока в очереди не появятся элементы
            while not queue:
                print(f"Потребитель {id}: очередь пуста, ожидание...")
                condition.wait()
                
            # Извлекаем элемент из очереди
            item = queue.popleft()
            print(f"Потребитель {id}: получен {item}, размер очереди {len(queue)}")
            
            # Уведомляем производителей о свободном месте
            condition.notify()
            
            # Для демонстрации: завершаем, если получили последний элемент
            if item.endswith("-9"):  # Последний элемент от любого производителя
                return
        
        # Имитация обработки
        time.sleep(random.uniform(0.2, 0.7))

# Запускаем производителей и потребителей
producers = [threading.Thread(target=producer, args=(i,)) for i in range(2)]
consumers = [threading.Thread(target=consumer, args=(i,)) for i in range(3)]

for t in producers + consumers:
    t.start()

for t in producers:
    t.join()

for t in consumers:
    t.join()
```

#### 6. Использование очередей (Queues)

Потокобезопасные очереди из модуля `queue` предоставляют простой способ обмена данными между потоками:

```python
import threading
import queue
import time
import random

# Создаем потокобезопасную очередь
task_queue = queue.Queue(maxsize=10)
done = threading.Event()

def producer():
    for i in range(20):
        task = f"Task-{i}"
        task_queue.put(task)  # Блокируется, если очередь заполнена
        print(f"Производитель: добавлена задача {task}")
        time.sleep(random.uniform(0.1, 0.3))
    
    # Добавляем маркер завершения
    task_queue.put(None)
    print("Производитель: работа завершена")

def consumer():
    while True:
        task = task_queue.get()  # Блокируется, если очередь пуста
        
        if task is None:
            # Передаем маркер завершения дальше
            task_queue.put(None)
            print("Потребитель: получен сигнал завершения")
            break
        
        print(f"Потребитель: обработка задачи {task}")
        time.sleep(random.uniform(0.2, 0.5))
        task_queue.task_done()  # Сообщаем о завершении задачи

# Запускаем потоки
producer_thread = threading.Thread(target=producer)
consumer_threads = [threading.Thread(target=consumer) for _ in range(2)]

producer_thread.start()
for t in consumer_threads:
    t.start()

producer_thread.join()
for t in consumer_threads:
    t.join()

print("Все потоки завершили работу")
```

#### 7. Атомарные операции

Некоторые операции в Python атомарны по своей природе, например, присваивание и чтение ссылки на объект. Для более сложных атомарных операций можно использовать модуль `threading.atomic`:

```python
import threading
import time

# threading.atomic не существует в стандартной библиотеке,
# но мы можем использовать другие примитивы синхронизации для атомарных операций

class AtomicCounter:
    def __init__(self):
        self._value = 0
        self._lock = threading.Lock()
    
    def increment(self):
        with self._lock:
            self._value += 1
    
    def decrement(self):
        with self._lock:
            self._value -= 1
    
    def value(self):
        with self._lock:
            return self._value

# Использование атомарного счетчика
counter = AtomicCounter()

def increment_task():
    for _ in range(100000):
        counter.increment()

threads = [threading.Thread(target=increment_task) for _ in range(5)]

for t in threads:
    t.start()

for t in threads:
    t.join()

print(f"Итоговое значение счетчика: {counter.value()}")
```

#### 8. Использование ThreadLocal для изоляции данных

Объекты `threading.local()` позволяют каждому потоку иметь свою собственную копию данных:

```python
import threading
import random

# Создаем объект для хранения данных потока
thread_local = threading.local()

def process_request(request_id):
    # Каждый поток имеет свое собственное значение thread_local.request_id
    thread_local.request_id = request_id
    thread_local.results = []
    
    print(f"Поток обрабатывает запрос {thread_local.request_id}")
    
    # Имитация этапов обработки запроса
    process_step_1()
    process_step_2()
    
    print(f"Результаты для запроса {thread_local.request_id}: {thread_local.results}")

def process_step_1():
    # У каждого потока есть доступ к его собственному request_id
    print(f"Шаг 1 для запроса {thread_local.request_id}")
    thread_local.results.append(f"результат шага 1 (запрос {thread_local.request_id})")

def process_step_2():
    print(f"Шаг 2 для запроса {thread_local.request_id}")
    thread_local.results.append(f"результат шага 2 (запрос {thread_local.request_id})")

# Запускаем обработку нескольких запросов
threads = [
    threading.Thread(target=process_request, args=(i,))
    for i in range(5)
]

for t in threads:
    t.start()

for t in threads:
    t.join()
```

### Лучшие практики избегания Race Conditions

1. **Минимизация общих состояний**
   - Чем меньше общих данных, тем меньше вероятность race conditions
   - Предпочитайте передачу данных через аргументы или очереди

2. **Неизменяемые объекты (Immutable objects)**
   - Используйте неизменяемые объекты, где это возможно
   - Например, tuple вместо list для общих коллекций

3. **Принцип наименьших привилегий**
   - Ограничивайте доступ к общим данным
   - Разделяйте доступы на чтение и запись

4. **Использование правильного уровня изоляции**
   - Для CPU-bound задач: многопроцессорность
   - Для I/O-bound задач с общими данными: многопоточность
   - Для I/O-bound задач без общих данных: asyncio

5. **Синхронизация с минимальной областью**
   - Держите критические секции как можно короче
   - Избегайте вложенных блокировок, если возможно

6. **Документирование потокобезопасности**
   - Явно указывайте, какие функции и классы потокобезопасны
   - Документируйте предполагаемый режим использования

7. **Тестирование на гонки условий**
   - Пишите стресс-тесты, воспроизводящие условия гонки
   - Используйте таймеры и задержки для поиска проблем

### Практический пример решения race condition

Рассмотрим пример кеша с проблемой race condition и его решение:

```python
import threading
import time
import random

# Имитация медленного вычисления
def compute_value(key):
    print(f"Вычисление значения для ключа {key}")
    time.sleep(1)  # Имитация сложных расчетов
    return f"значение-{key}"

# Версия 1: Наивная реализация с race condition
class UnsafeCache:
    def __init__(self):
        self.cache = {}
    
    def get(self, key):
        if key not in self.cache:
            # Race condition: два потока могут одновременно проверить,
            # что ключа нет в кеше, и оба начнут вычисление
            value = compute_value(key)
            self.cache[key] = value
        return self.cache[key]

# Версия 2: Исправление с использованием блокировки
class ThreadSafeCache:
    def __init__(self):
        self.cache = {}
        self.lock = threading.Lock()
    
    def get(self, key):
        with self.lock:
            if key not in self.cache:
                value = compute_value(key)
                self.cache[key] = value
            return self.cache[key]

# Версия 3: Более эффективная реализация с детальной блокировкой
class FineGrainedCache:
    def __init__(self):
        self.cache = {}
        self.locks = {}
        self.global_lock = threading.Lock()
    
    def get(self, key):
        # Сначала проверяем без блокировки (оптимистично)
        if key in self.cache:
            return self.cache[key]
        
        # Если ключа нет, получаем или создаем блокировку для этого ключа
        with self.global_lock:
            if key not in self.locks:
                self.locks[key] = threading.Lock()
        
        # Используем блокировку только для этого ключа
        with self.locks[key]:
            # Проверяем еще раз, другой поток мог уже вычислить значение
            if key not in self.cache:
                value = compute_value(key)
                self.cache[key] = value
            return self.cache[key]

# Тестирование различных реализаций кеша
def test_cache(cache_class, num_threads=10):
    cache = cache_class()
    
    def worker():
        # Каждый поток запрашивает случайные ключи
        for _ in range(5):
            key = random.randint(1, 3)  # Небольшой диапазон для создания коллизий
            value = cache.get(key)
            print(f"Поток получил {key} -> {value}")
            time.sleep(random.uniform(0.1, 0.3))
    
    start = time.time()
    
    threads = [threading.Thread(target=worker) for _ in range(num_threads)]
    for t in threads:
        t.start()
    
    for t in threads:
        t.join()
    
    end = time.time()
    print(f"{cache_class.__name__}: завершено за {end - start:.2f} секунд")

# Запуск тестов
print("Тестирование UnsafeCache:")
test_cache(UnsafeCache)

print("\nТестирование ThreadSafeCache:")
test_cache(ThreadSafeCache)

print("\nТестирование FineGrainedCache:")
test_cache(FineGrainedCache)
```

## 8. Семафоры, блокировки, условные переменные

### Введение в примитивы синхронизации

Примитивы синхронизации - это низкоуровневые механизмы, которые позволяют координировать работу параллельных потоков и процессов. Они помогают избежать race conditions и обеспечивают правильное взаимодействие между потоками.

Python предоставляет различные примитивы синхронизации в модуле `threading`:

1. **Lock** - простейший примитив блокировки
2. **RLock** - реентерабельная блокировка (может быть получена тем же потоком несколько раз)
3. **Semaphore** - семафор, ограничивающий доступ к ресурсу
4. **BoundedSemaphore** - семафор с проверкой превышения лимита
5. **Event** - механизм сигнализации между потоками
6. **Condition** - условная переменная, комбинирующая блокировку и механизм уведомления
7. **Barrier** - барьер, синхронизирующий группу потоков в определенной точке

### Блокировки (Locks)

Блокировки (Locks) предоставляют базовый механизм для предотвращения одновременного доступа к общему ресурсу.

#### Основные операции с блокировками

- `lock.acquire()` - получение блокировки (блокирует выполнение, если блокировка уже получена другим потоком)
- `lock.release()` - освобождение блокировки
- `lock.locked()` - проверка, получена ли блокировка

#### Использование блокировок с контекстным менеджером

```python
import threading
import time

# Общие данные
counter = 0
lock = threading.Lock()

def increment(name, count):
    global counter
    for _ in range(count):
        # Вход в критическую секцию
        with lock:  # Эквивалентно try: lock.acquire(); ... finally: lock.release()
            current = counter
            time.sleep(0.0001)  # Имитация "тяжелой" операции
            counter = current + 1
        # Выход из критической секции

# Запускаем несколько потоков, которые обновляют счетчик
threads = []
for i in range(5):
    thread = threading.Thread(target=increment, args=(f"Thread-{i}", 10))
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()

print(f"Итоговое значение счетчика: {counter}")
```

#### Реентерабельные блокировки (RLock)

RLock позволяет одному и тому же потоку получить блокировку несколько раз без блокировки:

```python
import threading

class Counter:
    def __init__(self):
        self._value = 0
        self._lock = threading.RLock()
    
    def increment(self):
        with self._lock:
            self._value += 1
    
    def decrement(self):
        with self._lock:
            self._value -= 1
    
    def value(self):
        with self._lock:
            # Хотя мы уже владеем блокировкой, мы можем получить её ещё раз
            return self._get_value()
    
    def _get_value(self):
        # Эта функция также требует блокировки
        with self._lock:
            return self._value

counter = Counter()
counter.increment()  # Работает нормально, так как RLock поддерживает повторные блокировки
```

#### Deadlock (взаимная блокировка)

Deadlock происходит, когда два или более потока ожидают ресурсов, занятых друг другом. Пример:

```python
import threading
import time

# Две блокировки
lock1 = threading.Lock()
lock2 = threading.Lock()

def thread1_function():
    print("Поток 1: Попытка получить lock1...")
    with lock1:
        print("Поток 1: lock1 получен")
        time.sleep(0.5)  # Имитация работы
        
        print("Поток 1: Попытка получить lock2...")
        with lock2:
            print("Поток 1: lock2 получен")
            # Эта точка никогда не будет достигнута в случае deadlock

def thread2_function():
    print("Поток 2: Попытка получить lock2...")
    with lock2:
        print("Поток 2: lock2 получен")
        time.sleep(0.5)  # Имитация работы
        
        print("Поток 2: Попытка получить lock1...")
        with lock1:
            print("Поток 2: lock1 получен")
            # Эта точка никогда не будет достигнута в случае deadlock

# Запускаем оба потока
thread1 = threading.Thread(target=thread1_function)
thread2 = threading.Thread(target=thread2_function)

thread1.start()
thread2.start()

thread1.join()
thread2.join()

print("Программа завершена (это сообщение может не появиться из-за deadlock)")
```

**Способы избежать deadlock:**
1. Всегда получать блокировки в одном и том же порядке
2. Использовать блокировки с таймаутом
3. Использовать контекстные менеджеры для гарантированного освобождения
4. Минимизировать вложенность блокировок

### Семафоры (Semaphores)

Семафоры ограничивают количество потоков, которые могут одновременно выполнять критическую секцию кода.

#### Основные операции с семафорами

- `semaphore.acquire()` - получение доступа (уменьшение счетчика)
- `semaphore.release()` - освобождение доступа (увеличение счетчика)
- `semaphore._value` - текущее значение счетчика (не рекомендуется использовать напрямую)

#### Использование семафоров для ограничения доступа

```python
import threading
import time
import random

# Семафор, ограничивающий 3 одновременных доступа
pool_semaphore = threading.Semaphore(3)
print_lock = threading.Lock()

def worker(id):
    print(f"Рабочий {id}: ожидает доступа к пулу ресурсов")
    
    with pool_semaphore:
        # Критическая секция - максимум 3 потока могут быть здесь одновременно
        with print_lock:
            print(f"Рабочий {id}: получил доступ к пулу ресурсов")
        
        # Имитация работы с ресурсом
        time.sleep(random.uniform(1, 3))
        
        with print_lock:
            print(f"Рабочий {id}: освободил ресурс")

# Запускаем 10 рабочих потоков
threads = []
for i in range(10):
    thread = threading.Thread(target=worker, args=(i,))
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()

print("Все рабочие завершили работу")
```

#### BoundedSemaphore

`BoundedSemaphore` - это семафор, который проверяет, что значение счетчика не превышает начальное значение:

```python
import threading
import time

# Создаем ограниченный семафор
semaphore = threading.BoundedSemaphore(2)

def worker(id):
    print(f"Рабочий {id}: получаю доступ")
    
    semaphore.acquire()
    try:
        print(f"Рабочий {id}: внутри критической секции")
        time.sleep(1)
    finally:
        print(f"Рабочий {id}: освобождаю доступ")
        semaphore.release()
        
        # Если раскомментировать следующую строку, будет вызвано исключение
        # ValueError: Semaphore released too many times
        # semaphore.release()

# Запускаем несколько потоков
threads = []
for i in range(5):
    thread = threading.Thread(target=worker, args=(i,))
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()
```

#### Использование семафоров для реализации пула ресурсов

```python
import threading
import queue
import time
import random

class ResourcePool:
    def __init__(self, resources):
        # Инициализация пула ресурсов
        self.resources = resources
        self.semaphore = threading.Semaphore(len(resources))
        self.available = queue.Queue()
        
        # Помещаем все ресурсы в очередь доступных
        for resource in resources:
            self.available.put(resource)
    
    def acquire(self):
        # Получение ресурса из пула
        self.semaphore.acquire()
        return self.available.get()
    
    def release(self, resource):
        # Возврат ресурса в пул
        self.available.put(resource)
        self.semaphore.release()

# Пример использования
def worker(pool, id):
    print(f"Рабочий {id}: запрашивает ресурс")
    
    # Получаем ресурс
    resource = pool.acquire()
    print(f"Рабочий {id}: получил ресурс {resource}")
    
    # Используем ресурс
    time.sleep(random.uniform(1, 3))
    
    # Возвращаем ресурс в пул
    print(f"Рабочий {id}: возвращает ресурс {resource}")
    pool.release(resource)

# Создаем пул с ограниченным количеством соединений к БД
db_connections = ["connection-1", "connection-2", "connection-3"]
pool = ResourcePool(db_connections)

# Запускаем потоки, использующие соединения
threads = []
for i in range(10):
    thread = threading.Thread(target=worker, args=(pool, i))
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()
```

### События (Events)

События позволяют одному потоку сигнализировать о наступлении определенного условия другим потокам.

#### Основные операции с событиями

- `event.set()` - устанавливает флаг события
- `event.clear()` - сбрасывает флаг события
- `event.is_set()` - проверяет, установлен ли флаг
- `event.wait(timeout=None)` - блокируется до установки флага или истечения таймаута

#### Использование событий для синхронизации

```python
import threading
import time

# Событие для сигнализации о готовности данных
data_ready = threading.Event()
data = None

def producer():
    global data
    print("Производитель: начало работы")
    
    # Имитация подготовки данных
    time.sleep(3)
    
    # Установка данных
    data = {"key": "value", "timestamp": time.time()}
    
    print("Производитель: данные готовы")
    
    # Уведомление всех ожидающих потоков
    data_ready.set()

def consumer(id):
    print(f"Потребитель {id}: ожидание данных")
    
    # Ожидание сигнала о готовности данных
    data_ready.wait()
    
    print(f"Потребитель {id}: получены данные {data}")

# Запускаем производителя и нескольких потребителей
producer_thread = threading.Thread(target=producer)
consumer_threads = [threading.Thread(target=consumer, args=(i,)) for i in range(3)]

# Запускаем сначала потребителей, они будут ждать
for thread in consumer_threads:
    thread.start()

# Затем запускаем производителя
producer_thread.start()

# Ждем завершения всех потоков
producer_thread.join()
for thread in consumer_threads:
    thread.join()
```

#### Использование событий для таймера

```python
import threading
import time

class Timer:
    def __init__(self, interval):
        self.interval = interval
        self.flag = threading.Event()
        self.thread = None
    
    def start(self):
        # Запуск таймера
        if self.thread and self.thread.is_alive():
            return False
        
        self.flag.clear()
        self.thread = threading.Thread(target=self._timer_thread)
        self.thread.daemon = True
        self.thread.start()
        return True
    
    def _timer_thread(self):
        # Поток таймера
        print(f"Таймер запущен на {self.interval} секунд")
        self.flag.wait(self.interval)
        
        if not self.flag.is_set():
            print("Время истекло!")
            self.on_timeout()
    
    def stop(self):
        # Остановка таймера
        self.flag.set()
        if self.thread:
            self.thread.join()
            return True
        return False
    
    def on_timeout(self):
        # Переопределяемый метод, вызываемый по истечении времени
        pass

# Пример использования таймера
class MyTimer(Timer):
    def on_timeout(self):
        print("Действие по таймауту выполнено!")

# Создаем и запускаем таймер
timer = MyTimer(3)
timer.start()

# Ждем некоторое время
time.sleep(1)
print("Прошла 1 секунда")

# Решаем остановить таймер или дать ему закончиться
choice = input("Остановить таймер? (y/n): ")
if choice.lower() == 'y':
    timer.stop()
    print("Таймер остановлен")
else:
    # Ждем завершения таймера
    timer.thread.join()
```

### Условные переменные (Conditions)

Условные переменные объединяют блокировку (Lock или RLock) с механизмом уведомления потоков о наступлении определенного условия.

#### Основные операции с условными переменными

- `condition.acquire()` - получение базовой блокировки
- `condition.release()` - освобождение базовой блокировки
- `condition.wait(timeout=None)` - освобождение блокировки и ожидание уведомления
- `condition.notify(n=1)` - уведомление n ожидающих потоков
- `condition.notify_all()` - уведомление всех ожидающих потоков

#### Использование условных переменных для очереди

```python
import threading
import time
import random
import collections

class BoundedQueue:
    def __init__(self, capacity):
        self.queue = collections.deque()
        self.capacity = capacity
        self.condition = threading.Condition()
    
    def put(self, item):
        with self.condition:
            # Ждем, пока очередь не освободится
            while len(self.queue) >= self.capacity:
                self.condition.wait()
            
            # Добавляем элемент
            self.queue.append(item)
            print(f"Добавлен элемент {item}, размер очереди: {len(self.queue)}")
            
            # Уведомляем потребителей
            self.condition.notify()
    
    def get(self):
        with self.condition:
            # Ждем, пока в очереди не появятся элементы
            while not self.queue:
                self.condition.wait()
            
            # Извлекаем элемент
            item = self.queue.popleft()
            print(f"Извлечен элемент {item}, размер очереди: {len(self.queue)}")
            
            # Уведомляем производителей
            self.condition.notify()
            
            return item

# Пример использования
queue = BoundedQueue(5)

def producer():
    for i in range(10):
        time.sleep(random.uniform(0.1, 0.5))  # Имитация работы
        queue.put(f"Элемент-{i}")

def consumer():
    while True:
        item = queue.get()
        time.sleep(random.uniform(0.2, 0.7))  # Имитация обработки
        
        # Завершаем поток после обработки последнего элемента
        if item == "Элемент-9":
            break

# Запускаем потоки
threads = [
    threading.Thread(target=producer),
    threading.Thread(target=consumer)
]

for thread in threads:
    thread.start()

for thread in threads:
    thread.join()
```

#### Использование условных переменных для управления потоками

```python
import threading
import time
import random

class Worker:
    def __init__(self, name):
        self.name = name
        self.condition = threading.Condition()
        self.working = False
        self.task = None
        self.thread = threading.Thread(target=self._worker_thread)
        self.thread.daemon = True
        self.running = True
    
    def start(self):
        self.thread.start()
    
    def stop(self):
        with self.condition:
            self.running = False
            self.condition.notify()
        self.thread.join()
    
    def assign_task(self, task):
        with self.condition:
            if self.working:
                return False
            
            self.task = task
            self.working = True
            self.condition.notify()
            return True
    
    def _worker_thread(self):
        while self.running:
            with self.condition:
                # Ждем задачу или сигнал остановки
                while not self.working and self.running:
                    self.condition.wait()
                
                if not self.running:
                    break
                
                task = self.task
            
            # Выполняем задачу
            print(f"Рабочий {self.name}: выполняет задачу {task}")
            time.sleep(random.uniform(1, 3))  # Имитация работы
            print(f"Рабочий {self.name}: задача {task} завершена")
            
            # Помечаем как свободный
            with self.condition:
                self.working = False
                self.task = None

class WorkerPool:
    def __init__(self, num_workers):
        self.workers = [Worker(f"Worker-{i}") for i in range(num_workers)]
        self.condition = threading.Condition()
        self.task_counter = 0
    
    def start(self):
        for worker in self.workers:
            worker.start()
    
    def stop(self):
        for worker in self.workers:
            worker.stop()
    
    def process_task(self, task):
        with self.condition:
            while True:
                # Ищем свободного рабочего
                for worker in self.workers:
                    if worker.assign_task(task):
                        print(f"Задача {task} назначена рабочему {worker.name}")
                        return
                
                # Если все рабочие заняты, ждем
                print(f"Задача {task} ожидает свободного рабочего")
                self.condition.wait()

    def notify_worker_available(self):
        with self.condition:
            self.condition.notify()

# Пример использования
pool = WorkerPool(3)
pool.start()

try:
    for i in range(10):
        pool.process_task(f"Task-{i}")
        time.sleep(random.uniform(0.1, 0.5))
finally:
    # Ждем некоторое время, чтобы рабочие успели закончить
    time.sleep(5)
    pool.stop()
```

### Барьеры (Barriers)

Барьеры синхронизируют группу потоков в определенной точке выполнения. Все потоки блокируются до тех пор, пока все участники не достигнут барьера.

#### Основные операции с барьерами

- `barrier = threading.Barrier(parties, action=None, timeout=None)` - создание барьера
- `barrier.wait(timeout=None)` - ожидание на барьере
- `barrier.reset()` - сброс барьера
- `barrier.abort()` - принудительное разблокирование всех потоков с ошибкой
- `barrier.parties` - общее количество участников
- `barrier.n_waiting` - количество потоков, ожидающих на барьере
- `barrier.broken` - флаг, указывающий, что барьер был сломан

#### Использование барьеров для синхронизации фаз

```python
import threading
import time
import random

def worker(barrier, id):
    print(f"Рабочий {id}: начало фазы 1")
    time.sleep(random.uniform(0.1, 1))  # Имитация работы
    print(f"Рабочий {id}: фаза 1 завершена, ожидание других потоков")
    
    # Ожидание на барьере, пока все потоки не завершат фазу 1
    barrier.wait()
    
    print(f"Рабочий {id}: начало фазы 2")
    time.sleep(random.uniform(0.1, 1))  # Имитация работы
    print(f"Рабочий {id}: фаза 2 завершена, ожидание других потоков")
    
    # Ожидание на барьере, пока все потоки не завершат фазу 2
    barrier.wait()
    
    print(f"Рабочий {id}: начало фазы 3")
    time.sleep(random.uniform(0.1, 1))  # Имитация работы
    print(f"Рабочий {id}: фаза 3 завершена")

def phase_action():
    print("\n*** Все потоки завершили фазу, переход к следующей фазе ***\n")

# Создаем барьер для 5 потоков с действием при преодолении барьера
barrier = threading.Barrier(5, action=phase_action)

# Запускаем рабочие потоки
threads = []
for i in range(5):
    thread = threading.Thread(target=worker, args=(barrier, i))
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()

print("Все потоки завершили работу")
```

#### Обработка ошибок при использовании барьеров

```python
import threading
import time
import random

def worker(barrier, id, should_fail=False):
    try:
        print(f"Рабочий {id}: начало работы")
        time.sleep(random.uniform(0.5, 1.5))
        
        if should_fail and id == 2:  # Имитация ошибки в одном из потоков
            print(f"Рабочий {id}: возникла ошибка!")
            raise RuntimeError("Симуляция ошибки")
        
        print(f"Рабочий {id}: ожидание на барьере")
        barrier.wait()  # Может вызвать BrokenBarrierError, если барьер сломан
        
        print(f"Рабочий {id}: прошел барьер")
        
    except threading.BrokenBarrierError:
        print(f"Рабочий {id}: барьер был сломан!")
    except Exception as e:
        print(f"Рабочий {id}: исключение {type(e).__name__}: {e}")
        barrier.abort()  # Ломаем барьер при ошибке

# Создаем барьер для 4 потоков
barrier = threading.Barrier(4)

# Запускаем рабочие потоки
threads = []
for i in range(4):
    # Поток 2 сгенерирует ошибку в режиме should_fail=True
    thread = threading.Thread(target=worker, args=(barrier, i, True))
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()

print(f"Состояние барьера: broken={barrier.broken}")
```

### Таймауты в примитивах синхронизации

Большинство примитивов синхронизации в Python поддерживают таймауты, которые позволяют избежать бесконечного ожидания:

```python
import threading
import time

# Блокировка с таймаутом
lock = threading.Lock()

def try_lock_with_timeout():
    print("Попытка получить блокировку с таймаутом 2 секунды")
    acquired = lock.acquire(timeout=2)
    
    if acquired:
        print("Блокировка получена")
        time.sleep(1)
        lock.release()
        return True
    else:
        print("Не удалось получить блокировку в течение таймаута")
        return False

# Семафор с таймаутом
semaphore = threading.Semaphore(0)  # Начальное значение 0

def try_semaphore_with_timeout():
    print("Попытка получить семафор с таймаутом 2 секунды")
    acquired = semaphore.acquire(timeout=2)
    
    if acquired:
        print("Семафор получен")
        return True
    else:
        print("Не удалось получить семафор в течение таймаута")
        return False

# Условная переменная с таймаутом
condition = threading.Condition()

def try_condition_with_timeout():
    with condition:
        print("Ожидание на условной переменной с таймаутом 2 секунды")
        waited = condition.wait(timeout=2)
        
        if not waited:
            print("Таймаут истек, условие не наступило")
        else:
            print("Условие наступило до истечения таймаута")

# Событие с таймаутом
event = threading.Event()

def try_event_with_timeout():
    print("Ожидание события с таймаутом 2 секунды")
    occurred = event.wait(timeout=2)
    
    if occurred:
        print("Событие наступило до истечения таймаута")
    else:
        print("Таймаут истек, событие не наступило")

# Барьер с таймаутом
barrier = threading.Barrier(2)

def try_barrier_with_timeout():
    try:
        print("Ожидание на барьере с таймаутом 2 секунды")
        barrier.wait(timeout=2)
        print("Барьер преодолен")
    except threading.BrokenBarrierError:
        print("Барьер был сломан")

# Примеры использования таймаутов
threads = [
    threading.Thread(target=try_lock_with_timeout),
    threading.Thread(target=try_semaphore_with_timeout),
    threading.Thread(target=try_condition_with_timeout),
    threading.Thread(target=try_event_with_timeout),
    threading.Thread(target=try_barrier_with_timeout)
]

for thread in threads:
    thread.start()

for thread in threads:
    thread.join()
```

### Асинхронные примитивы синхронизации в asyncio

Библиотека asyncio предоставляет аналоги примитивов синхронизации для асинхронного кода:

1. `asyncio.Lock` - асинхронная блокировка
2. `asyncio.Event` - асинхронное событие
3. `asyncio.Condition` - асинхронное условие
4. `asyncio.Semaphore` - асинхронный семафор
5. `asyncio.BoundedSemaphore` - асинхронный ограниченный семафор

#### Пример использования асинхронных примитивов

```python
import asyncio
import random

async def worker_with_lock(lock, id):
    print(f"Рабочий {id}: ожидает блокировку")
    async with lock:
        print(f"Рабочий {id}: получил блокировку")
        await asyncio.sleep(random.uniform(0.1, 0.5))
        print(f"Рабочий {id}: освобождает блокировку")

async def worker_with_semaphore(semaphore, id):
    print(f"Рабочий {id}: ожидает семафор")
    async with semaphore:
        print(f"Рабочий {id}: получил доступ")
        await asyncio.sleep(random.uniform(0.5, 1))
        print(f"Рабочий {id}: освобождает доступ")

async def producer_consumer_with_condition():
    condition = asyncio.Condition()
    queue = []
    
    async def producer():
        for i in range(5):
            await asyncio.sleep(random.uniform(0.1, 0.3))
            
            async with condition:
                queue.append(f"Элемент-{i}")
                print(f"Производитель: добавил Элемент-{i}")
                condition.notify()
    
    async def consumer():
        for _ in range(5):
            async with condition:
                while not queue:
                    await condition.wait()
                
                item = queue.pop(0)
                print(f"Потребитель: получил {item}")
    
    await asyncio.gather(producer(), consumer())

async def workers_with_event():
    event = asyncio.Event()
    
    async def waiter(id):
        print(f"Ожидатель {id}: ждет события")
        await event.wait()
        print(f"Ожидатель {id}: событие произошло!")
    
    async def setter():
        await asyncio.sleep(1)
        print("Установщик: устанавливает событие")
        event.set()
    
    await asyncio.gather(waiter(1), waiter(2), waiter(3), setter())

async def main():
    # Пример с блокировкой
    print("\n--- Пример с блокировкой ---")
    lock = asyncio.Lock()
    await asyncio.gather(
        worker_with_lock(lock, 1),
        worker_with_lock(lock, 2),
        worker_with_lock(lock, 3)
    )
    
    # Пример с семафором
    print("\n--- Пример с семафором ---")
    semaphore = asyncio.Semaphore(2)  # Максимум 2 одновременных доступа
    await asyncio.gather(
        worker_with_semaphore(semaphore, 1),
        worker_with_semaphore(semaphore, 2),
        worker_with_semaphore(semaphore, 3),
        worker_with_semaphore(semaphore, 4)
    )
    
    # Пример с условной переменной
    print("\n--- Пример с условной переменной ---")
    await producer_consumer_with_condition()
    
    # Пример с событием
    print("\n--- Пример с событием ---")
    await workers_with_event()

asyncio.run(main())
```

## 9. Практические задачи

В этом разделе представлены задачи различной сложности для практики асинхронного программирования. Для каждой задачи предоставлены описание, начальный код и подсказки.

### Задача 1: Асинхронная загрузка данных с веб-сайтов

**Описание:** Реализуйте асинхронную функцию для загрузки содержимого нескольких URL-адресов. Функция должна возвращать словарь, где ключ - URL, а значение - длина полученного HTML-контента.

**Начальный код:**

```python
import asyncio
import aiohttp
import time

async def fetch_url(session, url):
    # TODO: Реализуйте функцию загрузки URL
    pass

async def fetch_all(urls):
    # TODO: Реализуйте функцию для параллельной загрузки всех URL
    pass

def main():
    urls = [
        "https://example.com",
        "https://python.org",
        "https://docs.python.org",
        "https://github.com",
        "https://stackoverflow.com"
    ]
    
    start = time.time()
    result = asyncio.run(fetch_all(urls))
    end = time.time()
    
    for url, length in result.items():
        print(f"{url}: {length} символов")
    
    print(f"Загрузка заняла {end - start:.2f} секунд")

if __name__ == "__main__":
    main()
```

**Подсказки:**
1. Используйте `aiohttp.ClientSession` для выполнения HTTP-запросов.
2. Для параллельного выполнения используйте `asyncio.gather()`.
3. Обработайте возможные исключения, такие как недоступность сайта.
4. Корректно закрывайте сессию с помощью контекстного менеджера.

### Задача 2: Асинхронный генератор данных и их обработка

**Описание:** Реализуйте асинхронную систему "производитель-потребитель" с использованием asyncio.Queue. Производитель должен генерировать случайные числа, а потребители – обрабатывать их (например, вычислять квадратный корень).

**Начальный код:**

```python
import asyncio
import random
import math
import time

async def producer(queue, num_items):
    # TODO: Реализуйте генератор случайных чисел
    pass

async def consumer(queue, id):
    # TODO: Реализуйте обработчик чисел
    pass

async def main():
    # Создаем очередь
    queue = asyncio.Queue(maxsize=10)
    
    # Количество элементов для генерации
    num_items = 50
    
    # Количество потребителей
    num_consumers = 3
    
    # TODO: Запустите производителя и потребителей
    
    # TODO: Дождитесь завершения всех задач
    
    print("Все задачи завершены")

if __name__ == "__main__":
    start = time.time()
    asyncio.run(main())
    print(f"Время выполнения: {time.time() - start:.2f} секунд")
```

**Подсказки:**
1. Производитель должен генерировать числа и помещать их в очередь.
2. Потребители должны извлекать числа из очереди и обрабатывать их.
3. Используйте `asyncio.Queue.put()` и `asyncio.Queue.get()` для работы с очередью.
4. Для завершения работы потребителей можно использовать специальный маркер в очереди или `asyncio.CancelledError`.
5. Используйте асинхронные задержки (`await asyncio.sleep()`) для имитации "тяжелых" операций.

### Задача 3: Ограничение количества одновременных запросов

**Описание:** Реализуйте функцию для асинхронной загрузки множества URL-адресов с ограничением максимального количества одновременных запросов. Используйте семафоры для контроля числа параллельных задач.

**Начальный код:**

```python
import asyncio
import aiohttp
import random
import time

async def fetch_with_semaphore(semaphore, session, url):
    # TODO: Реализуйте функцию загрузки URL с использованием семафора
    pass

async def fetch_all_with_limit(urls, limit):
    # TODO: Реализуйте функцию для ограниченной параллельной загрузки
    pass

def main():
    # Генерируем много URL для тестирования
    base_urls = [
        "https://example.com",
        "https://python.org",
        "https://docs.python.org",
        "https://github.com",
        "https://stackoverflow.com"
    ]
    
    # Создаем больше URL, добавляя параметры к базовым
    urls = []
    for base_url in base_urls:
        for i in range(10):
            urls.append(f"{base_url}?param={i}")
    
    # Перемешиваем список URL
    random.shuffle(urls)
    
    # Ограничение одновременных запросов
    limit = 5
    
    start = time.time()
    results = asyncio.run(fetch_all_with_limit(urls, limit))
    end = time.time()
    
    print(f"Загружено {len(results)} URL")
    print(f"Время выполнения: {end - start:.2f} секунд")

if __name__ == "__main__":
    main()
```

**Подсказки:**
1. Создайте семафор с помощью `asyncio.Semaphore(limit)`.
2. Используйте семафор как контекстный менеджер для контроля количества одновременных запросов.
3. Для конкурентного выполнения задач с семафором, создайте список задач и используйте `asyncio.gather()`.
4. Добавьте задержки между запросами, чтобы избежать проблем с сервером (например, с помощью jitter).
5. Обрабатывайте возможные ошибки, чтобы одна неудачная загрузка не приводила к падению всей программы.

### Задача 4: Реализация асинхронного TCP-сервера и клиента

**Описание:** Создайте простой асинхронный TCP echo-сервер, который принимает соединения от клиентов, принимает данные и отправляет их обратно. Затем реализуйте клиент, который подключается к серверу, отправляет сообщения и выводит ответы.

**Начальный код:**

```python
import asyncio
import random
import string

# Серверная часть
async def handle_client(reader, writer):
    # TODO: Реализуйте обработку клиентского соединения
    pass

async def run_server():
    # TODO: Запустите сервер на localhost:8888
    pass

# Клиентская часть
async def client_session(client_id):
    # TODO: Реализуйте клиентскую сессию
    pass

async def run_clients(num_clients):
    # TODO: Запустите несколько клиентов
    pass

# Основная функция
async def main():
    # Запускаем сервер в отдельной задаче
    server_task = asyncio.create_task(run_server())
    
    # Даем серверу время на запуск
    await asyncio.sleep(0.5)
    
    # Запускаем клиентов
    await run_clients(5)
    
    # Отменяем задачу сервера при завершении
    server_task.cancel()
    try:
        await server_task
    except asyncio.CancelledError:
        print("Сервер остановлен")

if __name__ == "__main__":
    asyncio.run(main())
```

**Подсказки:**
1. Используйте `asyncio.start_server()` для создания сервера.
2. Используйте `asyncio.open_connection()` для подключения клиента к серверу.
3. Для чтения данных от клиента используйте `reader.read(n)` или `reader.readline()`.
4. Для отправки данных клиенту используйте `writer.write(data)` и `await writer.drain()`.
5. Не забудьте закрывать соединения с помощью `writer.close()` и `await writer.wait_closed()`.
6. Обрабатывайте исключения, чтобы сервер не падал при ошибках клиента.

### Задача 5: Асинхронное кеширование с истечением срока действия

**Описание:** Реализуйте асинхронный кеш с истечением срока действия элементов. Кеш должен поддерживать асинхронные операции добавления, получения и удаления элементов. Элементы должны автоматически удаляться из кеша по истечении указанного времени.

**Начальный код:**

```python
import asyncio
import time
import random

class AsyncExpiringCache:
    def __init__(self, default_ttl=60):
        # TODO: Инициализируйте структуры данных для кеша
        pass
    
    async def get(self, key):
        # TODO: Получение элемента из кеша, если он существует и не истек
        pass
    
    async def put(self, key, value, ttl=None):
        # TODO: Добавление элемента в кеш с указанным временем жизни
        pass
    
    async def delete(self, key):
        # TODO: Удаление элемента из кеша
        pass
    
    async def cleanup(self):
        # TODO: Фоновая задача для очистки истекших элементов
        pass
    
    async def start_cleanup_task(self):
        # TODO: Запуск фоновой задачи очистки
        pass
    
    async def stop_cleanup_task(self):
        # TODO: Остановка фоновой задачи очистки
        pass

async def expensive_operation(key):
    # Имитация дорогостоящей операции (например, запрос к БД или API)
    await asyncio.sleep(random.uniform(0.5, 2.0))
    return f"Результат для {key}: {random.randint(1, 100)}"

async def main():
    # Создаем кеш с временем жизни элементов 5 секунд
    cache = AsyncExpiringCache(default_ttl=5)
    
    # Запускаем задачу очистки
    await cache.start_cleanup_task()
    
    try:
        # Тестирование кеша
        keys = ["key1", "key2", "key3", "key4", "key5"]
        
        # TODO: Реализуйте тестирование кеша
        
    finally:
        # Останавливаем задачу очистки
        await cache.stop_cleanup_task()

if __name__ == "__main__":
    asyncio.run(main())
```

**Подсказки:**
1. Используйте словарь для хранения элементов кеша и их времени истечения.
2. Реализуйте фоновую задачу очистки, которая периодически проверяет и удаляет истекшие элементы.
3. Используйте блокировку (`asyncio.Lock`) для защиты состояния кеша при конкурентном доступе.
4. Для хранения времени истечения можно использовать `time.time() + ttl`.
5. Метод `get()` должен проверять, не истек ли срок жизни элемента.
6. Фоновая задача очистки должна быть остановлена корректно при завершении программы.
7. Тестирование должно включать различные сценарии: попадания и промахи кеша, истечения времени жизни, повторные запросы одного и того же ключа.

### Задача 6: Реализация асинхронного планировщика задач

**Описание:** Создайте асинхронный планировщик задач, который позволяет запускать задачи по расписанию (однократно или с периодическим повторением). Планировщик должен поддерживать добавление, удаление и изменение задач.

**Начальный код:**

```python
import asyncio
import time
import heapq
from datetime import datetime, timedelta

class AsyncScheduler:
    def __init__(self):
        # TODO: Инициализируйте структуры данных для планировщика
        pass
    
    async def start(self):
        # TODO: Запуск планировщика
        pass
    
    async def stop(self):
        # TODO: Остановка планировщика
        pass
    
    async def schedule_once(self, coroutine, delay):
        # TODO: Планирование однократного выполнения корутины
        pass
    
    async def schedule_periodic(self, coroutine, interval):
        # TODO: Планирование периодического выполнения корутины
        pass
    
    async def cancel_task(self, task_id):
        # TODO: Отмена запланированной задачи
        pass
    
    async def _run_scheduler_loop(self):
        # TODO: Основной цикл планировщика
        pass

# Пример задач для тестирования
async def task_hello(name):
    print(f"[{datetime.now()}] Привет, {name}!")

async def task_time():
    print(f"[{datetime.now()}] Текущее время: {datetime.now().strftime('%H:%M:%S')}")

async def task_countdown(n):
    for i in range(n, 0, -1):
        print(f"[{datetime.now()}] Обратный отсчет: {i}")
        await asyncio.sleep(1)
    print(f"[{datetime.now()}] Обратный отсчет завершен!")

async def main():
    scheduler = AsyncScheduler()
    await scheduler.start()
    
    try:
        # TODO: Запланируйте различные задачи для тестирования
        
        # Ждем некоторое время для выполнения задач
        await asyncio.sleep(30)
        
    finally:
        await scheduler.stop()

if __name__ == "__main__":
    asyncio.run(main())
```

**Подсказки:**
1. Используйте приоритетную очередь (heap) для хранения запланированных задач, отсортированных по времени выполнения.
2. Для периодических задач после выполнения добавляйте их обратно в очередь с обновленным временем.
3. Используйте `asyncio.create_task()` для запуска задач в нужное время.
4. Обрабатывайте отмену задач путем хранения ссылок на задачи и использования `task.cancel()`.
5. Основной цикл планировщика должен эффективно ожидать следующую задачу, не потребляя CPU.
6. Используйте событие (`asyncio.Event`) для пробуждения цикла планировщика при добавлении новых задач.
7. Создайте уникальные идентификаторы для задач, чтобы можно было их отменять.

### Задача 7: Реализация асинхронного паттерна "Circuit Breaker"

**Описание:** Реализуйте паттерн "Circuit Breaker" (Прерыватель цепи) для защиты от каскадных сбоев в асинхронных вызовах. Паттерн должен отслеживать ошибки и временно блокировать вызовы, если количество ошибок превышает пороговое значение.

**Начальный код:**

```python
import asyncio
import random
import time
from enum import Enum

class CircuitState(Enum):
    CLOSED = "CLOSED"         # Нормальная работа, запросы проходят
    OPEN = "OPEN"             # Цепь разомкнута, запросы блокируются
    HALF_OPEN = "HALF_OPEN"   # Пробное состояние после таймаута

class AsyncCircuitBreaker:
    def __init__(self, failure_threshold=5, recovery_timeout=10, timeout=5):
        # TODO: Инициализируйте состояние прерывателя цепи
        pass
    
    async def execute(self, func, *args, **kwargs):
        # TODO: Реализуйте логику выполнения функции с учетом состояния цепи
        pass
    
    def _record_success(self):
        # TODO: Регистрация успешного вызова
        pass
    
    def _record_failure(self):
        # TODO: Регистрация неудачного вызова
        pass
    
    def _trip_open(self):
        # TODO: Переход в состояние OPEN
        pass
    
    def _try_half_open(self):
        # TODO: Проверка возможности перехода в HALF_OPEN
        pass
    
    def reset(self):
        # TODO: Сброс прерывателя в исходное состояние
        pass

# Тестовые функции
async def stable_operation():
    await asyncio.sleep(0.1)
    return "Операция выполнена успешно"

async def unstable_operation(failure_rate=0.7):
    await asyncio.sleep(0.1)
    if random.random() < failure_rate:
        raise Exception("Симуляция ошибки")
    return "Операция выполнена успешно"

async def slow_operation(delay=6):
    await asyncio.sleep(delay)
    return "Медленная операция завершена"

async def main():
    # Создаем прерыватель цепи
    circuit_breaker = AsyncCircuitBreaker(
        failure_threshold=3,   # После 3 ошибок размыкаем цепь
        recovery_timeout=5,    # Через 5 секунд пробуем полуоткрытое состояние
        timeout=2              # Таймаут операции - 2 секунды
    )
    
    # TODO: Протестируйте прерыватель цепи с различными сценариями
    
    print("Тестирование завершено")

if __name__ == "__main__":
    asyncio.run(main())
```

**Подсказки:**
1. Прерыватель должен отслеживать количество последовательных ошибок и успешных вызовов.
2. В состоянии OPEN все запросы должны немедленно отклоняться без выполнения.
3. После истечения `recovery_timeout` в состоянии OPEN, прерыватель должен перейти в состояние HALF_OPEN и попробовать выполнить один запрос.
4. В случае успеха в состоянии HALF_OPEN, прерыватель должен вернуться в состояние CLOSED.
5. В случае ошибки в состоянии HALF_OPEN, прерыватель должен вернуться в состояние OPEN с обновленным таймером.
6. Используйте `asyncio.wait_for()` для реализации таймаута операций.
7. Обрабатывайте исключения и передавайте информативные сообщения об ошибках.
8. Реализуйте логирование переходов между состояниями и причин этих переходов.

### Задача 8: Асинхронная обработка файлов

**Описание:** Реализуйте систему для асинхронного чтения, обработки и записи файлов. Система должна эффективно обрабатывать большие файлы, разбивая их на части и обрабатывая конкурентно.

**Начальный код:**

```python
import asyncio
import aiofiles
import os
import time
from pathlib import Path

async def read_chunk(filename, start, size):
    # TODO: Реализуйте асинхронное чтение части файла
    pass

async def process_chunk(chunk, processor_func):
    # TODO: Реализуйте асинхронную обработку части файла
    pass

async def write_chunk(filename, chunk, position):
    # TODO: Реализуйте асинхронную запись части файла
    pass

async def process_file_concurrently(input_file, output_file, processor_func, chunk_size=1024*1024):
    # TODO: Реализуйте конкурентную обработку файла
    pass

# Пример функции обработки (преобразует текст в верхний регистр)
async def uppercase_processor(chunk):
    await asyncio.sleep(0.01)  # Имитация "тяжелой" обработки
    return chunk.upper()

# Пример функции обработки (заменяет все вхождения подстроки)
async def replace_processor(chunk):
    await asyncio.sleep(0.01)  # Имитация "тяжелой" обработки
    return chunk.replace(b'example', b'REPLACED')

async def main():
    # Создаем тестовый файл, если его нет
    input_file = "large_test_file.txt"
    output_file = "processed_file.txt"
    
    if not os.path.exists(input_file) or os.path.getsize(input_file) < 10*1024*1024:
        print(f"Создание тестового файла {input_file}...")
        
        # TODO: Создайте большой тестовый файл
    
    print(f"Асинхронная обработка файла {input_file}...")
    start_time = time.time()
    
    await process_file_concurrently(input_file, output_file, uppercase_processor)
    
    end_time = time.time()
    print(f"Обработка завершена за {end_time - start_time:.2f} секунд")
    
    input_size = os.path.getsize(input_file)
    output_size = os.path.getsize(output_file)
    print(f"Размер входного файла: {input_size/1024/1024:.2f} MB")
    print(f"Размер выходного файла: {output_size/1024/1024:.2f} MB")

if __name__ == "__main__":
    asyncio.run(main())
```

**Подсказки:**
1. Используйте библиотеку `aiofiles` для асинхронной работы с файлами.
2. Определите размер входного файла с помощью `os.path.getsize()`.
3. Разбейте файл на части (чанки) и обрабатывайте их параллельно.
4. Используйте `asyncio.gather()` для параллельной обработки чанков.
5. Для чтения части файла можно использовать `file.seek()` и `file.read()`.
6. Корректно обрабатывайте границы чанков, чтобы избежать потери или дублирования данных.
7. Ограничивайте количество одновременно обрабатываемых чанков, чтобы не перегрузить систему.
8. Для создания тестового файла можно использовать генерацию случайных данных или повторение одного и того же текста.

### Задача 9: Асинхронная обработка событий с топологическими зависимостями

**Описание:** Реализуйте асинхронную систему обработки событий, где события могут иметь зависимости друг от друга. Система должна обрабатывать события в правильном порядке, учитывая их зависимости, и максимально параллельно, когда это возможно.

**Начальный код:**

```python
import asyncio
import random
import time
from typing import Dict, List, Set, Optional

class Event:
    def __init__(self, event_id: str, dependencies: Optional[List[str]] = None):
        self.event_id = event_id
        self.dependencies = set(dependencies or [])
        self.completed = False
    
    async def process(self):
        # Имитация обработки события
        process_time = random.uniform(0.5, 2.0)
        print(f"Начало обработки события {self.event_id} (займет {process_time:.2f}с)...")
        await asyncio.sleep(process_time)
        print(f"Событие {self.event_id} обработано")
        self.completed = True
        return self.event_id

class AsyncEventProcessor:
    def __init__(self):
        self.events: Dict[str, Event] = {}
        self.processing: Set[str] = set()
    
    def add_event(self, event: Event) -> None:
        # TODO: Добавить событие в систему
        pass
    
    def get_ready_events(self) -> List[Event]:
        # TODO: Получить список событий, готовых к обработке 
        # (все зависимости которых уже обработаны и которые сами еще не обрабатываются)
        pass
    
    async def process_all_events(self) -> None:
        # TODO: Обработать все события в правильном порядке с максимальным параллелизмом
        pass
    
    def reset(self) -> None:
        # Сброс состояния процессора
        self.events = {}
        self.processing = set()

async def main():
    processor = AsyncEventProcessor()
    
    # Создаем тестовый граф событий
    # A -> B -> D -> F
    #  \         /
    #   -> C -> E
    
    processor.add_event(Event("A"))
    processor.add_event(Event("B", ["A"]))
    processor.add_event(Event("C", ["A"]))
    processor.add_event(Event("D", ["B"]))
    processor.add_event(Event("E", ["C"]))
    processor.add_event(Event("F", ["D", "E"]))
    
    print("Начало обработки событий...")
    start_time = time.time()
    
    await processor.process_all_events()
    
    end_time = time.time()
    print(f"Все события обработаны за {end_time - start_time:.2f} секунд")
    
    # Тестирование с циклической зависимостью
    print("\nТест на циклические зависимости:")
    processor.reset()
    
    processor.add_event(Event("X"))
    processor.add_event(Event("Y", ["Z"]))
    processor.add_event(Event("Z", ["X"]))
    processor.add_event(Event("W", ["Y"]))
    
    try:
        await processor.process_all_events()
    except Exception as e:
        print(f"Произошла ошибка (ожидаемо): {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

**Подсказки:**
1. Используйте топологическую сортировку для определения правильного порядка обработки событий.
2. Обнаруживайте циклические зависимости и выбрасывайте исключение в таких случаях.
3. Для максимального параллелизма запускайте обработку всех событий, зависимости которых уже выполнены.
4. Используйте `asyncio.gather()` для параллельной обработки независимых событий.
5. Поддерживайте множество обрабатываемых в данный момент событий для избежания повторной обработки.
6. После обработки события обновляйте состояние системы и проверяйте, какие новые события стали готовы к обработке.
7. Для визуализации хода обработки добавьте информативные сообщения с временем начала и завершения обработки каждого события.

### Задача 10: Асинхронное распределенное выполнение задач с отказоустойчивостью

**Описание:** Реализуйте асинхронную систему распределенного выполнения задач с поддержкой отказоустойчивости. Система должна распределять задачи между "рабочими узлами", отслеживать их выполнение, перезапускать в случае ошибок и собирать результаты.

**Начальный код:**

```python
import asyncio
import random
import time
import uuid
from enum import Enum
from typing import Dict, List, Callable, Awaitable, Any, Optional, Tuple

class TaskStatus(Enum):
    PENDING = "PENDING"
    RUNNING = "RUNNING"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"

class Task:
    def __init__(self, func: Callable[..., Awaitable[Any]], *args, **kwargs):
        self.id = str(uuid.uuid4())
        self.func = func
        self.args = args
        self.kwargs = kwargs
        self.status = TaskStatus.PENDING
        self.result = None
        self.error = None
        self.retry_count = 0
        self.worker_id = None
    
    async def execute(self):
        try:
            self.result = await self.func(*self.args, **self.kwargs)
            self.status = TaskStatus.COMPLETED
            return self.result
        except Exception as e:
            self.error = str(e)
            self.status = TaskStatus.FAILED
            raise

class Worker:
    def __init__(self, worker_id: str, failure_rate: float = 0.2):
        self.id = worker_id
        self.failure_rate = failure_rate  # Вероятность сбоя при выполнении задачи
        self.busy = False
    
    async def execute_task(self, task: Task) -> Any:
        if self.busy:
            raise RuntimeError(f"Рабочий узел {self.id} уже занят")
        
        self.busy = True
        task.worker_id = self.id
        task.status = TaskStatus.RUNNING
        
        try:
            # Имитация случайных сбоев
            if random.random() < self.failure_rate:
                await asyncio.sleep(random.uniform(0.1, 0.5))
                raise RuntimeError(f"Симуляция сбоя рабочего узла {self.id}")
            
            result = await task.execute()
            return result
        finally:
            self.busy = False

class AsyncTaskScheduler:
    def __init__(self, max_retries: int = 3):
        self.tasks: Dict[str, Task] = {}
        self.workers: Dict[str, Worker] = {}
        self.max_retries = max_retries
        self.results: Dict[str, Any] = {}
    
    def add_worker(self, worker_id: Optional[str] = None, failure_rate: float = 0.2) -> str:
        # TODO: Добавление нового рабочего узла
        pass
    
    def add_task(self, func: Callable[..., Awaitable[Any]], *args, **kwargs) -> str:
        # TODO: Добавление новой задачи
        pass
    
    def get_available_worker(self) -> Optional[Worker]:
        # TODO: Получение свободного рабочего узла
        pass
    
    async def execute_task(self, task_id: str) -> Any:
        # TODO: Выполнение задачи с учетом отказоустойчивости
        pass
    
    async def execute_all(self) -> Dict[str, Any]:
        # TODO: Выполнение всех задач
        pass

# Примеры асинхронных функций для тестирования
async def task_success(task_id: str, duration: float = 1.0) -> str:
    await asyncio.sleep(duration)
    return f"Задача {task_id} выполнена успешно"

async def task_sometimes_fails(task_id: str, fail_rate: float = 0.5) -> str:
    await asyncio.sleep(random.uniform(0.5, 1.5))
    if random.random() < fail_rate:
        raise ValueError(f"Симуляция ошибки в задаче {task_id}")
    return f"Задача {task_id} выполнена успешно"

async def main():
    scheduler = AsyncTaskScheduler(max_retries=2)
    
    # Добавляем рабочие узлы с разной вероятностью сбоя
    for i in range(5):
        scheduler.add_worker(failure_rate=0.3)
    
    # Добавляем задачи
    for i in range(10):
        if i % 3 == 0:
            # Задачи, которые могут завершиться с ошибкой
            scheduler.add_task(task_sometimes_fails, f"задача-{i}", fail_rate=0.7)
        else:
            # Задачи, которые всегда успешны
            scheduler.add_task(task_success, f"задача-{i}", duration=random.uniform(0.5, 2.0))
    
    print("Запуск выполнения всех задач...")
    start_time = time.time()
    
    results = await scheduler.execute_all()
    
    end_time = time.time()
    print(f"Все задачи выполнены за {end_time - start_time:.2f} секунд")
    
    # Анализ результатов
    success_count = sum(1 for task_id, result in scheduler.results.items() 
                     if scheduler.tasks[task_id].status == TaskStatus.COMPLETED)
    failure_count = sum(1 for task_id in scheduler.tasks 
                     if scheduler.tasks[task_id].status == TaskStatus.FAILED)
    
    print(f"Успешно выполнено задач: {success_count}")
    print(f"Не удалось выполнить задач: {failure_count}")
    
    # Подробная информация о задачах
    for task_id, task in scheduler.tasks.items():
        status = task.status.value
        retries = task.retry_count
        if task.status == TaskStatus.COMPLETED:
            print(f"Задача {task_id}: {status}, попыток: {retries}, результат: {task.result}")
        else:
            print(f"Задача {task_id}: {status}, попыток: {retries}, ошибка: {task.error}")

if __name__ == "__main__":
    asyncio.run(main())
```

**Подсказки:**
1. Реализуйте механизм повторных попыток для неудачных задач с учетом `max_retries`.
2. Отслеживайте состояние рабочих узлов и распределяйте задачи только на свободные узлы.
3. Используйте семафоры для ограничения количества параллельно выполняемых задач.
4. Реализуйте механизм отмены и освобождения ресурсов в случае отмены задачи.
5. Поддерживайте очередь задач и очередь доступных рабочих узлов.
6. Используйте `asyncio.gather()` с `return_exceptions=True` для параллельного выполнения задач и обработки ошибок.
7. Добавьте подробное логирование выполнения задач, включая информацию о перезапусках и причинах ошибок.
8. Реализуйте возможность добавления новых задач во время выполнения уже существующих.
