# Параллельные вычисления

Параллельные вычисления — это вычислительная парадигма, при которой множество вычислений выполняются одновременно, основываясь на принципе разделения большой задачи на более мелкие, которые затем решаются параллельно. Эта концепция фундаментально важна для современной разработки программного обеспечения, особенно в эпоху многоядерных процессоров, распределенных систем и больших данных.

## Зачем нужны параллельные вычисления?

Существует несколько важных причин для применения параллельных вычислений:

1. **Повышение производительности** — параллельная обработка позволяет решать задачи быстрее
2. **Обработка больших объемов данных** — некоторые задачи слишком велики для последовательной обработки за разумное время
3. **Эффективное использование ресурсов** — современные компьютеры имеют несколько процессоров/ядер, которые простаивают при однопоточных вычислениях
4. **Преодоление физических ограничений** — частота процессоров перестала расти, и параллелизм стал основным источником повышения производительности
5. **Повышение отказоустойчивости** — распределенные параллельные системы могут продолжать работу при отказе отдельных компонентов

## Уровни параллелизма

Параллельные вычисления можно рассматривать на разных уровнях:

### 1. Параллелизм на уровне бит и инструкций

Этот низкоуровневый параллелизм обычно реализуется на уровне процессора и компилятора:
- **Битовый параллелизм** — обработка нескольких бит одновременно (например, 64-битная операция vs 32-битная)
- **Параллелизм на уровне инструкций** — одновременное выполнение нескольких инструкций процессора (конвейерная обработка, суперскалярное выполнение)

### 2. Параллелизм на уровне данных (SIMD)

**Single Instruction, Multiple Data (SIMD)** — модель, при которой одна и та же операция применяется одновременно к нескольким элементам данных:
- Векторные и матричные операции
- Обработка изображений и мультимедиа
- GPU-вычисления

### 3. Параллелизм на уровне задач

Разделение программы на независимые задачи, которые могут выполняться параллельно:
- Многопоточность в рамках одного процесса
- Асинхронные вызовы и неблокирующий ввод/вывод
- Параллельные циклы и разделение работы

### 4. Параллелизм на уровне процессов

Запуск нескольких отдельных процессов, которые взаимодействуют друг с другом:
- Многопроцессорная обработка
- Распределенные вычисления

## Таксономия Флинна

Классификация компьютерных архитектур, предложенная Майклом Флинном в 1966 году, определяет четыре категории в зависимости от потоков инструкций и данных:

1. **SISD (Single Instruction, Single Data)** — традиционная последовательная модель (один процессор выполняет одну инструкцию над одним элементом данных)
2. **SIMD (Single Instruction, Multiple Data)** — векторные и матричные процессоры, GPU (одна инструкция применяется к множеству данных)
3. **MISD (Multiple Instruction, Single Data)** — редкая конфигурация (несколько инструкций применяются к одному элементу данных)
4. **MIMD (Multiple Instruction, Multiple Data)** — наиболее распространенная современная модель, включающая многоядерные процессоры и кластеры (разные процессоры выполняют разные инструкции над разными данными)

## Закон Амдала и масштабируемость

Закон Амдала описывает теоретический предел ускорения программы при использовании параллельной обработки:

$$ S(n) = \frac{1}{(1 - p) + \frac{p}{n}} $$

где:
- $S(n)$ — ускорение при использовании $n$ процессоров
- $p$ — доля программы, которая может быть распараллелена
- $(1 - p)$ — доля последовательной части программы

Ключевые выводы из закона Амдала:
- Максимальное ускорение ограничено последовательной частью программы
- Даже если 95% программы можно распараллелить, максимальное ускорение ограничено фактором 20x, независимо от количества процессоров
- Для достижения хорошей масштабируемости необходимо минимизировать последовательную часть программы

## Модели параллельного программирования

### 1. Многопоточность (Multithreading)

Многопоточность позволяет выполнять несколько потоков в рамках одного процесса, с общей памятью:

#### Пример на Python с использованием модуля `threading`:

```python
import threading
import time

def worker(name, delay):
    """Функция, которая будет выполняться в отдельном потоке."""
    print(f"Worker {name} started")
    time.sleep(delay)
    print(f"Worker {name} finished")

# Создаем и запускаем несколько потоков
threads = []
for i in range(5):
    t = threading.Thread(target=worker, args=(i, i))
    threads.append(t)
    t.start()

# Ожидаем завершения всех потоков
for t in threads:
    t.join()

print("All workers finished")
```

#### Синхронизация потоков с помощью блокировок:

```python
import threading
import time
import random

# Общий ресурс
counter = 0
# Блокировка для защиты общего ресурса
counter_lock = threading.Lock()

def increment_counter(iterations):
    """Увеличивает счетчик указанное количество раз."""
    global counter
    
    for _ in range(iterations):
        # Захватываем блокировку перед доступом к общему ресурсу
        with counter_lock:
            counter += 1
        
        # Имитируем некоторую работу после изменения счетчика
        time.sleep(random.uniform(0.001, 0.005))

# Создаем несколько потоков, которые будут конкурировать за один ресурс
threads = []
for i in range(5):
    t = threading.Thread(target=increment_counter, args=(1000,))
    threads.append(t)
    t.start()

# Ожидаем завершения всех потоков
for t in threads:
    t.join()

print(f"Final counter value: {counter}")
```

### 2. Многопроцессность (Multiprocessing)

Многопроцессность позволяет запускать несколько отдельных процессов, каждый с собственным адресным пространством:

#### Пример на Python с использованием модуля `multiprocessing`:

```python
import multiprocessing
import time

def worker(name, delay, return_dict):
    """Функция, выполняемая в отдельном процессе."""
    print(f"Worker {name} started")
    time.sleep(delay)
    return_dict[name] = name * 10  # Сохраняем результат в общем словаре
    print(f"Worker {name} finished")

if __name__ == "__main__":
    # Общий словарь для хранения результатов
    manager = multiprocessing.Manager()
    return_dict = manager.dict()
    
    # Создаем и запускаем несколько процессов
    processes = []
    for i in range(5):
        p = multiprocessing.Process(target=worker, args=(i, i, return_dict))
        processes.append(p)
        p.start()
    
    # Ожидаем завершения всех процессов
    for p in processes:
        p.join()
    
    print("All workers finished")
    print(f"Results: {dict(return_dict)}")
```

#### Параллельная обработка данных с помощью пула процессов:

```python
import multiprocessing
import time

def process_item(item):
    """Обрабатывает один элемент данных."""
    # Имитируем сложные вычисления
    time.sleep(0.1)
    return item * item

if __name__ == "__main__":
    # Создаем данные для обработки
    data = list(range(100))
    
    start_time = time.time()
    
    # Последовательная обработка
    sequential_result = [process_item(item) for item in data]
    sequential_time = time.time() - start_time
    
    # Параллельная обработка с использованием пула процессов
    start_time = time.time()
    
    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:
        parallel_result = pool.map(process_item, data)
    
    parallel_time = time.time() - start_time
    
    # Проверяем результаты
    assert sequential_result == parallel_result
    
    print(f"Sequential processing time: {sequential_time:.2f} seconds")
    print(f"Parallel processing time: {parallel_time:.2f} seconds")
    print(f"Speedup: {sequential_time / parallel_time:.2f}x")
```

### 3. Асинхронное программирование

Асинхронное программирование позволяет выполнять неблокирующие операции в рамках одного потока:

#### Пример на Python с использованием `asyncio`:

```python
import asyncio
import time

async def async_task(name, delay):
    """Асинхронная задача, которая выполняет неблокирующее ожидание."""
    print(f"Task {name} started at {time.strftime('%H:%M:%S')}")
    await asyncio.sleep(delay)  # Неблокирующее ожидание
    print(f"Task {name} finished at {time.strftime('%H:%M:%S')}")
    return name * 10

async def main():
    """Основная корутина, запускающая несколько задач."""
    # Создаем список задач
    tasks = [
        async_task(i, i) for i in range(1, 6)
    ]
    
    # Запускаем все задачи параллельно и ожидаем результаты
    results = await asyncio.gather(*tasks)
    print(f"Results: {results}")

# Запускаем асинхронное выполнение
if __name__ == "__main__":
    start_time = time.time()
    asyncio.run(main())
    total_time = time.time() - start_time
    
    print(f"Total execution time: {total_time:.2f} seconds")
    # Заметьте, что общее время будет примерно 5 секунд, хотя
    # суммарное время выполнения всех задач составляет 15 секунд
```

#### Асинхронные запросы к веб-серверам:

```python
import asyncio
import aiohttp
import time

async def fetch_url(session, url):
    """Асинхронно получает содержимое URL."""
    try:
        async with session.get(url) as response:
            return {
                'url': url,
                'status': response.status,
                'content_length': len(await response.text())
            }
    except Exception as e:
        return {'url': url, 'error': str(e)}

async def fetch_all(urls):
    """Получает содержимое всех URL параллельно."""
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url(session, url) for url in urls]
        return await asyncio.gather(*tasks)

async def main():
    # Список URL для запроса
    urls = [
        'https://www.python.org',
        'https://www.google.com',
        'https://www.github.com',
        'https://www.stackoverflow.com',
        'https://www.wikipedia.org'
    ]
    
    start_time = time.time()
    results = await fetch_all(urls)
    elapsed = time.time() - start_time
    
    for result in results:
        if 'error' in result:
            print(f"Error fetching {result['url']}: {result['error']}")
        else:
            print(f"Fetched {result['url']} - Status: {result['status']}, Length: {result['content_length']} chars")
    
    print(f"Fetched {len(urls)} URLs in {elapsed:.2f} seconds")

if __name__ == "__main__":
    asyncio.run(main())
```

### 4. Модель акторов (Actor Model)

Модель акторов — концепция параллельных вычислений, где "акторы" являются универсальными примитивами параллелизма. Каждый актор обрабатывает сообщения асинхронно и может:
- Отправлять сообщения другим акторам
- Создавать новых акторов
- Определять поведение для обработки следующего сообщения

#### Пример с использованием библиотеки `pykka` для Python:

```python
import pykka
import time
import random

class WorkerActor(pykka.ThreadingActor):
    """Актор-исполнитель, который обрабатывает задачи."""
    
    def on_receive(self, message):
        """Обрабатывает входящее сообщение."""
        if message.get('command') == 'process':
            task_id = message.get('task_id')
            print(f"Worker processing task {task_id}")
            
            # Имитируем выполнение работы
            time.sleep(random.uniform(0.1, 0.5))
            
            # Отправляем результат обратно координатору
            return {'task_id': task_id, 'status': 'completed', 'result': task_id * 10}

class CoordinatorActor(pykka.ThreadingActor):
    """Актор-координатор, который распределяет задачи между рабочими акторами."""
    
    def __init__(self, num_workers):
        super().__init__()
        self.workers = [WorkerActor.start() for _ in range(num_workers)]
        self.results = {}
        self.pending_tasks = set()
    
    def on_receive(self, message):
        """Обрабатывает входящие сообщения."""
        if message.get('command') == 'submit':
            # Получаем новую задачу для обработки
            task_id = message.get('task_id')
            worker = random.choice(self.workers)
            print(f"Coordinator assigning task {task_id} to worker")
            
            # Запоминаем, что у нас есть ожидающая задача
            self.pending_tasks.add(task_id)
            
            # Отправляем задачу рабочему и настраиваем обработку результата
            future = worker.ask({'command': 'process', 'task_id': task_id})
            future.add_callback(self.handle_result)
            
            return {'status': 'submitted', 'task_id': task_id}
            
        elif message.get('command') == 'get_results':
            # Возвращаем текущие результаты
            return {
                'results': self.results,
                'pending': list(self.pending_tasks)
            }
    
    def handle_result(self, result):
        """Обрабатывает результат, полученный от рабочего актора."""
        task_id = result['task_id']
        print(f"Coordinator received result for task {task_id}")
        
        # Сохраняем результат
        self.results[task_id] = result
        self.pending_tasks.remove(task_id)

if __name__ == "__main__":
    # Создаем координатора с 5 рабочими
    coordinator = CoordinatorActor.start(5)
    
    # Отправляем 10 задач на обработку
    for i in range(10):
        response = coordinator.ask({'command': 'submit', 'task_id': i})
        print(f"Submitted task {i}, response: {response}")
    
    # Периодически проверяем статус задач
    while True:
        time.sleep(0.5)
        status = coordinator.ask({'command': 'get_results'})
        print(f"Results: {len(status['results'])}, Pending: {len(status['pending'])}")
        
        # Если все задачи завершены, выходим из цикла
        if not status['pending']:
            print(f"All tasks completed! Results: {status['results']}")
            break
    
    # Останавливаем акторов
    pykka.ActorRegistry.stop_all()
```

### 5. Параллелизм на основе задач (Task-Based Parallelism)

В этой модели программа разбивается на независимые задачи, которые могут выполняться параллельно:

#### Пример с использованием `concurrent.futures` в Python:

```python
import concurrent.futures
import requests
import time

def download_image(url):
    """Загружает изображение по URL."""
    response = requests.get(url)
    if response.status_code == 200:
        return {
            'url': url,
            'size': len(response.content),
            'status': 'success'
        }
    else:
        return {
            'url': url,
            'status': 'error',
            'code': response.status_code
        }

def process_images(image_urls, max_workers=5):
    """Параллельно загружает изображения с использованием пула потоков."""
    results = []
    
    # Используем ThreadPoolExecutor для параллельной загрузки
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Отправляем задачи на выполнение
        future_to_url = {
            executor.submit(download_image, url): url 
            for url in image_urls
        }
        
        # Обрабатываем результаты по мере их завершения
        for future in concurrent.futures.as_completed(future_to_url):
            url = future_to_url[future]
            try:
                result = future.result()
                results.append(result)
                print(f"Downloaded {url} - Size: {result.get('size', 'N/A')} bytes")
            except Exception as e:
                results.append({
                    'url': url,
                    'status': 'exception',
                    'error': str(e)
                })
                print(f"Error downloading {url}: {e}")
    
    return results

if __name__ == "__main__":
    # Список URL с изображениями
    image_urls = [
        'https://www.python.org/static/img/python-logo.png',
        'https://www.python.org/static/img/python-logo-only.png',
        'https://www.python.org/static/img/psf-logo.png',
        'https://www.python.org/static/img/python-powered.png',
        'https://www.python.org/static/img/pypy-logo.png',
        'https://www.python.org/static/img/powered-by-django.png',
    ]
    
    start_time = time.time()
    
    # Параллельная загрузка
    results = process_images(image_urls)
    
    elapsed = time.time() - start_time
    print(f"Downloaded {len(results)} images in {elapsed:.2f} seconds")
    
    # Выводим статистику
    success_count = sum(1 for r in results if r['status'] == 'success')
    total_size = sum(r.get('size', 0) for r in results if r['status'] == 'success')
    
    print(f"Successfully downloaded: {success_count}/{len(results)}")
    print(f"Total size: {total_size} bytes")
```

## Параллельные алгоритмы и структуры данных

### 1. Параллельное сведение (Parallel Reduction)

Параллельное сведение — алгоритм для вычисления агрегатных операций (сумма, произведение, минимум, максимум) на массиве данных с использованием параллелизма.

#### Пример: Параллельное вычисление суммы элементов массива

```python
import numpy as np
import multiprocessing
import time

def sum_chunk(chunk):
    """Вычисляет сумму элементов в части массива."""
    return np.sum(chunk)

def parallel_sum(arr, num_processes=None):
    """
    Параллельно вычисляет сумму элементов массива.
    
    Args:
        arr: Исходный массив
        num_processes: Количество процессов (по умолчанию — число ядер CPU)
        
    Returns:
        Сумма элементов массива
    """
    if num_processes is None:
        num_processes = multiprocessing.cpu_count()
    
    # Разбиваем массив на части
    arr_chunks = np.array_split(arr, num_processes)
    
    # Создаем пул процессов и вычисляем сумму для каждой части
    with multiprocessing.Pool(processes=num_processes) as pool:
        chunk_sums = pool.map(sum_chunk, arr_chunks)
    
    # Суммируем результаты частей
    return sum(chunk_sums)

if __name__ == "__main__":
    # Создаем большой массив для тестирования
    size = 100_000_000
    arr = np.random.rand(size)
    
    # Вычисляем сумму последовательно
    start_time = time.time()
    seq_sum = np.sum(arr)
    seq_time = time.time() - start_time
    print(f"Sequential sum: {seq_sum:.6f} (Time: {seq_time:.4f} s)")
    
    # Вычисляем сумму параллельно
    start_time = time.time()
    par_sum = parallel_sum(arr)
    par_time = time.time() - start_time
    print(f"Parallel sum: {par_sum:.6f} (Time: {par_time:.4f} s)")
    
    # Проверяем результаты и выводим ускорение
    assert np.isclose(seq_sum, par_sum)
    print(f"Speedup: {seq_time / par_time:.2f}x")
```

### 2. Параллельное сортировки

Многие алгоритмы сортировки можно эффективно распараллелить.

#### Пример: Параллельная сортировка слиянием

```python
import multiprocessing
import time
import random

def merge(left, right):
    """Слияние двух отсортированных массивов."""
    result = []
    i = j = 0
    
    # Объединяем массивы, сохраняя порядок
    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    
    # Добавляем оставшиеся элементы
    result.extend(left[i:])
    result.extend(right[j:])
    return result

def sequential_merge_sort(arr):
    """Последовательная сортировка слиянием."""
    if len(arr) <= 1:
        return arr
    
    # Разделяем массив на две части
    mid = len(arr) // 2
    left = sequential_merge_sort(arr[:mid])
    right = sequential_merge_sort(arr[mid:])
    
    # Сливаем отсортированные части
    return merge(left, right)

def parallel_merge_sort(arr, depth=0, max_depth=None):
    """
    Параллельная сортировка слиянием.
    
    Args:
        arr: Исходный массив
        depth: Текущая глубина рекурсии
        max_depth: Максимальная глубина для распараллеливания
        
    Returns:
        Отсортированный массив
    """
    # Если максимальная глубина не задана, устанавливаем ее в зависимости от числа ядер
    if max_depth is None:
        max_depth = multiprocessing.cpu_count().bit_length() - 1
    
    # Базовый случай
    if len(arr) <= 1:
        return arr
    
    # Разделяем массив на две части
    mid = len(arr) // 2
    
    # Если текущая глубина меньше максимальной, используем параллельную обработку
    if depth < max_depth:
        # Создаем пул из двух процессов для сортировки левой и правой частей
        with multiprocessing.Pool(processes=2) as pool:
            left_future = pool.apply_async(parallel_merge_sort, (arr[:mid], depth + 1, max_depth))
            right_future = pool.apply_async(parallel_merge_sort, (arr[mid:], depth + 1, max_depth))
            
            # Получаем результаты
            left = left_future.get()
            right = right_future.get()
    else:
        # На большой глубине переключаемся на последовательную сортировку
        left = sequential_merge_sort(arr[:mid])
        right = sequential_merge_sort(arr[mid:])
    
    # Сливаем отсортированные части
    return merge(left, right)

if __name__ == "__main__":
    # Генерируем случайный массив для сортировки
    size = 10_000_000
    arr = [random.randint(0, 1000000) for _ in range(size)]
    
    # Создаем копии для разных алгоритмов
    arr_seq = arr.copy()
    arr_par = arr.copy()
    
    # Сортируем последовательно
    print(f"Sorting _1.arrays of size {size} sequentially...")
    start_time = time.time()
    arr_seq_sorted = sequential_merge_sort(arr_seq)
    seq_time = time.time() - start_time
    print(f"Sequential merge sort time: {seq_time:.4f} s")
    
    # Сортируем параллельно
    print(f"Sorting _1.arrays of size {size} in parallel...")
    start_time = time.time()
    arr_par_sorted = parallel_merge_sort(arr_par)
    par_time = time.time() - start_time
    print(f"Parallel merge sort time: {par_time:.4f} s")
    
    # Проверяем результаты и выводим ускорение
    assert arr_seq_sorted == arr_par_sorted
    print(f"Results match! Speedup: {seq_time / par_time:.2f}x")
```

### 3. Параллельные поиск и фильтрация

Поиск и фильтрация данных также хорошо распараллеливаются.

#### Пример: Параллельная фильтрация элементов

```python
import multiprocessing
import time
import random

def is_prime(n):
    """Проверяет, является ли число простым (наивная реализация)."""
    if n <= 1:
        return False
    if n <= 3:
        return True
    if n % 2 == 0 or n % 3 == 0:
        return False
    
    i = 5
    while i * i <= n:
        if n % i == 0 or n % (i + 2) == 0:
            return False
        i += 6
    
    return True

def filter_chunk(chunk):
    """Фильтрует простые числа из части массива."""
    return [num for num in chunk if is_prime(num)]

def parallel_filter_primes(numbers, num_processes=None):
    """
    Параллельно фильтрует простые числа из массива.
    
    Args:
        numbers: Исходный массив чисел
        num_processes: Количество процессов (по умолчанию — число ядер CPU)
        
    Returns:
        Список простых чисел
    """
    if num_processes is None:
        num_processes = multiprocessing.cpu_count()
    
    # Разбиваем массив на части
    chunk_size = len(numbers) // num_processes
    chunks = [numbers[i:i + chunk_size] for i in range(0, len(numbers), chunk_size)]
    
    # Создаем пул процессов и фильтруем каждую часть
    with multiprocessing.Pool(processes=num_processes) as pool:
        results = pool.map(filter_chunk, chunks)
    
    # Объединяем результаты
    return [prime for chunk_result in results for prime in chunk_result]

def sequential_filter_primes(numbers):
    """Последовательно фильтрует простые числа из массива."""
    return [num for num in numbers if is_prime(num)]

if __name__ == "__main__":
    # Генерируем случайные числа для тестирования
    size = 100_000
    max_value = 1_000_000
    numbers = [random.randint(2, max_value) for _ in range(size)]
    
    # Фильтруем последовательно
    print(f"Filtering primes from {size} numbers sequentially...")
    start_time = time.time()
    seq_primes = sequential_filter_primes(numbers)
    seq_time = time.time() - start_time
    print(f"Sequential filtering time: {seq_time:.4f} s")
    print(f"Found {len(seq_primes)} primes")
    
    # Фильтруем параллельно
    print(f"Filtering primes from {size} numbers in parallel...")
    start_time = time.time()
    par_primes = parallel_filter_primes(numbers)
    par_time = time.time() - start_time
    print(f"Parallel filtering time: {par_time:.4f} s")
    print(f"Found {len(par_primes)} primes")
    
    # Проверяем результаты и выводим ускорение
    assert sorted(seq_primes) == sorted(par_primes)
    print(f"Results match! Speedup: {seq_time / par_time:.2f}x")
```

## Общие паттерны параллельного программирования

### 1. Модель "мастер-рабочий" (Master-Worker)

В этой модели "мастер" разделяет задачу на более мелкие части и распределяет их между "рабочими", а затем собирает результаты.

#### Пример: Распределение задач с использованием очереди

```python
import multiprocessing
import time
import random

def worker(task_queue, result_queue, worker_id):
    """
    Рабочий процесс, который обрабатывает задачи из очереди.
    
    Args:
        task_queue: Очередь задач
        result_queue: Очередь результатов
        worker_id: Идентификатор рабочего
    """
    print(f"Worker {worker_id} started")
    
    while True:
        # Получаем задачу из очереди
        task = task_queue.get()
        
        # Проверяем, не является ли это сигналом завершения
        if task is None:
            print(f"Worker {worker_id} shutting down")
            break
        
        # Распаковываем данные задачи
        task_id, data = task
        
        # Имитируем обработку задачи
        print(f"Worker {worker_id} processing task {task_id}")
        time.sleep(random.uniform(0.1, 0.5))
        result = data * data  # Пример обработки - возводим в квадрат
        
        # Помещаем результат в очередь результатов
        result_queue.put((task_id, result, worker_id))
    
    # Сигнализируем о завершении
    result_queue.put((None, None, worker_id))

def master(tasks, num_workers):
    """
    Мастер-процесс, который распределяет задачи и собирает результаты.
    
    Args:
        tasks: Список задач для обработки
        num_workers: Количество рабочих процессов
        
    Returns:
        Словарь с результатами
    """
    # Создаем очереди для задач и результатов
    task_queue = multiprocessing.Queue()
    result_queue = multiprocessing.Queue()
    
    # Запускаем рабочие процессы
    workers = []
    for i in range(num_workers):
        p = multiprocessing.Process(
            target=worker, 
            args=(task_queue, result_queue, i)
        )
        workers.append(p)
        p.start()
    
    # Отправляем задачи в очередь
    for task_id, task_data in enumerate(tasks):
        task_queue.put((task_id, task_data))
    
    # Отправляем сигналы завершения для всех рабочих
    for _ in range(num_workers):
        task_queue.put(None)
    
    # Собираем результаты
    results = {}
    workers_done = 0
    while workers_done < num_workers:
        task_id, result, worker_id = result_queue.get()
        
        if task_id is None:
            # Рабочий процесс завершился
            workers_done += 1
        else:
            # Сохраняем результат
            results[task_id] = result
            print(f"Master received result for task {task_id} from worker {worker_id}: {result}")
    
    # Ожидаем завершения всех рабочих процессов
    for p in workers:
        p.join()
    
    return results

if __name__ == "__main__":
    # Создаем список задач
    num_tasks = 20
    tasks = [random.randint(1, 100) for _ in range(num_tasks)]
    
    # Запускаем обработку
    start_time = time.time()
    results = master(tasks, num_workers=4)
    elapsed = time.time() - start_time
    
    # Проверяем результаты
    assert len(results) == num_tasks
    for task_id, task_data in enumerate(tasks):
        assert results[task_id] == task_data * task_data
    
    print(f"Processed {num_tasks} tasks in {elapsed:.2f} seconds")
    print(f"All results correct!")
```

### 2. Конвейер (Pipeline)

В этой модели задача разбивается на последовательные этапы, причем каждый этап может обрабатывать данные параллельно с другими этапами.

#### Пример: Конвейерная обработка данных

```python
import multiprocessing
import time
import random
import string

def generate_data(output_queue, num_items):
    """
    Первый этап конвейера: генерирует случайные строки.
    
    Args:
        output_queue: Очередь для вывода сгенерированных данных
        num_items: Количество элементов для генерации
    """
    for i in range(num_items):
        # Генерируем случайную строку
        length = random.randint(5, 15)
        data = ''.join(random.choices(string.ascii_letters, k=length))
        
        # Отправляем в следующий этап
        output_queue.put((i, data))
        print(f"Generator: Produced item {i}: {data}")
        time.sleep(random.uniform(0.05, 0.2))  # Имитируем время обработки
    
    # Сигнализируем о завершении
    output_queue.put(None)
    print("Generator: Done")

def process_data(input_queue, output_queue):
    """
    Второй этап конвейера: обрабатывает строки (преобразует в верхний регистр).
    
    Args:
        input_queue: Очередь для ввода данных
        output_queue: Очередь для вывода обработанных данных
    """
    while True:
        # Получаем элемент из предыдущего этапа
        item = input_queue.get()
        
        # Проверяем, не является ли это сигналом завершения
        if item is None:
            # Передаем сигнал следующему этапу
            output_queue.put(None)
            print("Processor: Done")
            break
        
        # Распаковываем данные
        item_id, data = item
        
        # Обрабатываем данные
        processed_data = data.upper()
        print(f"Processor: Processed item {item_id}: {data} -> {processed_data}")
        time.sleep(random.uniform(0.1, 0.3))  # Имитируем время обработки
        
        # Отправляем в следующий этап
        output_queue.put((item_id, processed_data))

def analyze_data(input_queue, output_queue):
    """
    Третий этап конвейера: анализирует обработанные строки.
    
    Args:
        input_queue: Очередь для ввода данных
        output_queue: Очередь для вывода результатов анализа
    """
    while True:
        # Получаем элемент из предыдущего этапа
        item = input_queue.get()
        
        # Проверяем, не является ли это сигналом завершения
        if item is None:
            # Передаем сигнал следующему этапу
            output_queue.put(None)
            print("Analyzer: Done")
            break
        
        # Распаковываем данные
        item_id, data = item
        
        # Анализируем данные
        analysis = {
            'length': len(data),
            'vowels': sum(1 for char in data if char in 'AEIOU'),
            'consonants': sum(1 for char in data if char in 'BCDFGHJKLMNPQRSTVWXYZ')
        }
        
        print(f"Analyzer: Analyzed item {item_id}: Length={analysis['length']}, "
              f"Vowels={analysis['vowels']}, Consonants={analysis['consonants']}")
        time.sleep(random.uniform(0.1, 0.2))  # Имитируем время обработки
        
        # Отправляем в следующий этап
        output_queue.put((item_id, data, analysis))

def store_results(input_queue, results):
    """
    Последний этап конвейера: сохраняет результаты.
    
    Args:
        input_queue: Очередь для ввода данных
        results: Список для хранения результатов
    """
    while True:
        # Получаем элемент из предыдущего этапа
        item = input_queue.get()
        
        # Проверяем, не является ли это сигналом завершения
        if item is None:
            print("Storage: Done")
            break
        
        # Распаковываем данные
        item_id, data, analysis = item
        
        # Сохраняем результат
        results.append({
            'id': item_id,
            'data': data,
            'analysis': analysis
        })
        
        print(f"Storage: Stored result for item {item_id}")
        time.sleep(random.uniform(0.05, 0.15))  # Имитируем время обработки

def run_pipeline(num_items):
    """
    Запускает весь конвейер обработки данных.
    
    Args:
        num_items: Количество элементов для обработки
        
    Returns:
        Список с результатами обработки
    """
    # Создаем очереди для передачи данных между этапами
    queue1 = multiprocessing.Queue()  # Генератор -> Процессор
    queue2 = multiprocessing.Queue()  # Процессор -> Анализатор
    queue3 = multiprocessing.Queue()  # Анализатор -> Хранилище
    
    # Список для хранения результатов
    manager = multiprocessing.Manager()
    results = manager.list()
    
    # Создаем и запускаем процессы для каждого этапа
    p1 = multiprocessing.Process(target=generate_data, args=(queue1, num_items))
    p2 = multiprocessing.Process(target=process_data, args=(queue1, queue2))
    p3 = multiprocessing.Process(target=analyze_data, args=(queue2, queue3))
    p4 = multiprocessing.Process(target=store_results, args=(queue3, results))
    
    # Запускаем все процессы
    p1.start()
    p2.start()
    p3.start()
    p4.start()
    
    # Ожидаем завершения всех процессов
    p1.join()
    p2.join()
    p3.join()
    p4.join()
    
    # Возвращаем результаты
    return list(results)

if __name__ == "__main__":
    # Запускаем конвейер
    start_time = time.time()
    results = run_pipeline(num_items=10)
    elapsed = time.time() - start_time
    
    # Выводим итоговые результаты
    print("\nFinal Results:")
    for result in sorted(results, key=lambda x: x['id']):
        print(f"Item {result['id']}: {result['data']} - "
              f"Length: {result['analysis']['length']}, "
              f"Vowels: {result['analysis']['vowels']}, "
              f"Consonants: {result['analysis']['consonants']}")
    
    print(f"\nProcessed {len(results)} items in {elapsed:.2f} seconds")
```

### 3. Разделение пространства (Divide and Conquer)

В этой модели задача разбивается на независимые подзадачи, которые могут быть решены параллельно, а затем результаты объединяются.

#### Пример: Параллельное интегрирование методом Монте-Карло

```python
import multiprocessing
import time
import random
import math

def estimate_pi_chunk(num_points):
    """
    Оценивает число π методом Монте-Карло на основе заданного количества точек.
    
    Args:
        num_points: Количество случайных точек для генерации
        
    Returns:
        Оценка π на основе пропорции точек внутри круга
    """
    inside_circle = 0
    
    for _ in range(num_points):
        # Генерируем случайную точку в квадрате [-1, 1] x [-1, 1]
        x = random.uniform(-1, 1)
        y = random.uniform(-1, 1)
        
        # Проверяем, находится ли точка внутри круга единичного радиуса
        if x**2 + y**2 <= 1:
            inside_circle += 1
    
    # Вычисляем оценку π
    # Площадь круга = π*r^2, площадь квадрата = (2r)^2
    # Отношение площадей = π/4, откуда π = 4 * отношение
    return 4 * inside_circle / num_points

def parallel_monte_carlo_pi(total_points, num_processes=None):
    """
    Параллельно оценивает число π методом Монте-Карло.
    
    Args:
        total_points: Общее количество точек для генерации
        num_processes: Количество процессов (по умолчанию — число ядер CPU)
        
    Returns:
        Оценка числа π
    """
    if num_processes is None:
        num_processes = multiprocessing.cpu_count()
    
    # Разделяем точки между процессами
    points_per_process = total_points // num_processes
    
    # Создаем аргументы для каждого процесса
    args = [points_per_process] * num_processes
    
    # Если деление не целое, добавляем остаток к последнему процессу
    if total_points % num_processes != 0:
        args[-1] += total_points % num_processes
    
    # Создаем пул процессов и запускаем вычисления
    with multiprocessing.Pool(processes=num_processes) as pool:
        results = pool.map(estimate_pi_chunk, args)
    
    # Вычисляем среднее значение оценок
    return sum(results) / len(results)

if __name__ == "__main__":
    # Количество точек для генерации
    total_points = 100_000_000
    
    # Последовательная оценка
    print(f"Estimating π using {total_points:,} points sequentially...")
    start_time = time.time()
    seq_pi = estimate_pi_chunk(total_points)
    seq_time = time.time() - start_time
    print(f"Sequential estimate: π ≈ {seq_pi:.10f} (Error: {abs(seq_pi - math.pi):.10f})")
    print(f"Sequential time: {seq_time:.4f} s")
    
    # Параллельная оценка
    print(f"\nEstimating π using {total_points:,} points in parallel...")
    start_time = time.time()
    par_pi = parallel_monte_carlo_pi(total_points)
    par_time = time.time() - start_time
    print(f"Parallel estimate: π ≈ {par_pi:.10f} (Error: {abs(par_pi - math.pi):.10f})")
    print(f"Parallel time: {par_time:.4f} s")
    
    # Выводим ускорение
    print(f"\nSpeedup: {seq_time / par_time:.2f}x")
    print(f"Actual π value: {math.pi:.10f}")
```

## Проблемы параллельного программирования

### 1. Гонки данных (Race Conditions)

Гонки данных возникают, когда несколько потоков или процессов пытаются одновременно изменить общие данные, и результат зависит от порядка их выполнения.

#### Пример гонки данных:

```python
import threading
import time

# Общая переменная
counter = 0

def increment_counter(iterations):
    """Увеличивает счетчик указанное количество раз."""
    global counter
    for _ in range(iterations):
        # Считываем текущее значение
        current = counter
        # Имитируем задержку для усиления эффекта гонки
        time.sleep(0.00001)
        # Увеличиваем на 1 и записываем обратно
        counter = current + 1

# Создаем и запускаем несколько потоков
threads = []
num_threads = 5
iterations_per_thread = 1000

start_time = time.time()

for _ in range(num_threads):
    t = threading.Thread(target=increment_counter, args=(iterations_per_thread,))
    threads.append(t)
    t.start()

# Ожидаем завершения всех потоков
for t in threads:
    t.join()

elapsed = time.time() - start_time

# Проверяем результат
expected = num_threads * iterations_per_thread
print(f"Expected counter value: {expected}")
print(f"Actual counter value: {counter}")
print(f"Missing increments: {expected - counter}")
print(f"Elapsed time: {elapsed:.4f} s")
```

#### Решение с использованием блокировки:

```python
import threading
import time

# Общая переменная и блокировка
counter = 0
counter_lock = threading.Lock()

def increment_counter_safe(iterations):
    """Увеличивает счетчик указанное количество раз с блокировкой."""
    global counter
    for _ in range(iterations):
        # Захватываем блокировку перед изменением общей переменной
        with counter_lock:
            counter += 1

# Создаем и запускаем несколько потоков
threads = []
num_threads = 5
iterations_per_thread = 1000

start_time = time.time()

for _ in range(num_threads):
    t = threading.Thread(target=increment_counter_safe, args=(iterations_per_thread,))
    threads.append(t)
    t.start()

# Ожидаем завершения всех потоков
for t in threads:
    t.join()

elapsed = time.time() - start_time

# Проверяем результат
expected = num_threads * iterations_per_thread
print(f"Expected counter value: {expected}")
print(f"Actual counter value: {counter}")
print(f"Missing increments: {expected - counter}")
print(f"Elapsed time: {elapsed:.4f} s")
```

### 2. Взаимоблокировки (Deadlocks)

Взаимоблокировка возникает, когда два или более потоков блокируют друг друга, ожидая ресурсы, удерживаемые другими потоками.

#### Пример взаимоблокировки:

```python
import threading
import time

# Две блокировки
lock_a = threading.Lock()
lock_b = threading.Lock()

def thread_1():
    """Первый поток, который сначала захватывает lock_a, затем lock_b."""
    print("Thread 1: Trying to acquire lock A")
    with lock_a:
        print("Thread 1: Acquired lock A")
        
        # Имитируем некоторую работу
        time.sleep(0.1)
        
        print("Thread 1: Trying to acquire lock B")
        with lock_b:
            print("Thread 1: Acquired lock B")
            print("Thread 1: Both locks acquired")

def thread_2():
    """Второй поток, который сначала захватывает lock_b, затем lock_a."""
    print("Thread 2: Trying to acquire lock B")
    with lock_b:
        print("Thread 2: Acquired lock B")
        
        # Имитируем некоторую работу
        time.sleep(0.1)
        
        print("Thread 2: Trying to acquire lock A")
        with lock_a:
            print("Thread 2: Acquired lock A")
            print("Thread 2: Both locks acquired")

# Создаем и запускаем два потока
t1 = threading.Thread(target=thread_1)
t2 = threading.Thread(target=thread_2)

t1.start()
t2.start()

# Ожидаем завершения потоков с таймаутом
t1.join(timeout=2)
t2.join(timeout=2)

# Проверяем, не застряли ли потоки
if t1.is_alive() or t2.is_alive():
    print("Deadlock detected!")
else:
    print("No deadlock, both threads completed.")
```

#### Решение с использованием упорядоченных блокировок:

```python
import threading
import time

# Две блокировки
lock_a = threading.Lock()
lock_b = threading.Lock()

def thread_1_safe():
    """Первый поток, который всегда захватывает блокировки в одинаковом порядке."""
    print("Thread 1: Trying to acquire locks in order")
    
    # Всегда сначала захватываем lock_a, затем lock_b
    with lock_a:
        print("Thread 1: Acquired lock A")
        
        # Имитируем некоторую работу
        time.sleep(0.1)
        
        print("Thread 1: Trying to acquire lock B")
        with lock_b:
            print("Thread 1: Acquired lock B")
            print("Thread 1: Both locks acquired")

def thread_2_safe():
    """Второй поток, который всегда захватывает блокировки в том же порядке, что и первый."""
    print("Thread 2: Trying to acquire locks in order")
    
    # Тоже сначала захватываем lock_a, затем lock_b
    with lock_a:
        print("Thread 2: Acquired lock A")
        
        # Имитируем некоторую работу
        time.sleep(0.1)
        
        print("Thread 2: Trying to acquire lock B")
        with lock_b:
            print("Thread 2: Acquired lock B")
            print("Thread 2: Both locks acquired")

# Создаем и запускаем два потока
t1 = threading.Thread(target=thread_1_safe)
t2 = threading.Thread(target=thread_2_safe)

t1.start()
t2.start()

# Ожидаем завершения потоков
t1.join()
t2.join()

print("Both threads completed successfully.")
```

### 3. Состояние гонки (Race Condition)

Состояние гонки — это ситуация, когда результат выполнения зависит от относительного порядка или времени выполнения нескольких потоков.

#### Пример с исправлением с помощью атомарных операций:

```python
import threading
import time
import ctypes

# Атомарный счетчик
class AtomicCounter:
    def __init__(self, initial=0):
        self._value = ctypes.c_long(initial)
        
    def increment(self, num=1):
        """Атомарно увеличивает счетчик на заданное число."""
        while True:
            current = self._value.value
            new = current + num
            # Сравниваем и обмениваем атомарно
            if ctypes.pythonapi.PyLong_FromLong(current).value == self._value.value:
                self._value = ctypes.c_long(new)
                break
    
    @property
    def value(self):
        return self._value.value

# Обычный счетчик
normal_counter = 0
# Атомарный счетчик
atomic_counter = AtomicCounter()

# Блокировка для обычного счетчика
counter_lock = threading.Lock()

def increment_normal(iterations):
    """Увеличивает обычный счетчик без синхронизации."""
    global normal_counter
    for _ in range(iterations):
        normal_counter += 1

def increment_normal_with_lock(iterations):
    """Увеличивает обычный счетчик с синхронизацией."""
    global normal_counter
    for _ in range(iterations):
        with counter_lock:
            normal_counter += 1

def increment_atomic(iterations):
    """Увеличивает атомарный счетчик."""
    for _ in range(iterations):
        atomic_counter.increment()

# Тестируем разные варианты
def test_counter(increment_func, counter_name):
    global normal_counter
    normal_counter = 0
    if counter_name == "Atomic":
        atomic_counter._value = ctypes.c_long(0)
    
    threads = []
    num_threads = 5
    iterations_per_thread = 10000
    
    start_time = time.time()
    
    for _ in range(num_threads):
        t = threading.Thread(target=increment_func, args=(iterations_per_thread,))
        threads.append(t)
        t.start()
    
    for t in threads:
        t.join()
    
    elapsed = time.time() - start_time
    
    expected = num_threads * iterations_per_thread
    actual = atomic_counter.value if counter_name == "Atomic" else normal_counter
    
    print(f"{counter_name} Counter:")
    print(f"  Expected value: {expected}")
    print(f"  Actual value: {actual}")
    print(f"  Missing increments: {expected - actual}")
    print(f"  Elapsed time: {elapsed:.4f} s")
    print()

# Запускаем тесты
test_counter(increment_normal, "Unsafe")
test_counter(increment_normal_with_lock, "Locked")
test_counter(increment_atomic, "Atomic")
```

## Масштабирование в параллельных вычислениях

### Сильное масштабирование (Strong Scaling)

Сильное масштабирование фокусируется на сокращении времени выполнения для задачи фиксированного размера путем увеличения количества процессоров.

#### Пример измерения сильного масштабирования:

```python
import multiprocessing
import time
import numpy as np
import matplotlib.pyplot as plt

def matrix_multiply_chunk(args):
    """
    Умножает часть матрицы на другую матрицу.
    
    Args:
        args: Кортеж (start_row, end_row, A, B)
        
    Returns:
        Часть результирующей матрицы
    """
    start_row, end_row, A, B = args
    n = B.shape[1]
    result = np.zeros((end_row - start_row, n))
    
    for i in range(end_row - start_row):
        for j in range(n):
            for k in range(A.shape[1]):
                result[i, j] += A[start_row + i, k] * B[k, j]
    
    return start_row, end_row, result

def parallel_matrix_multiply(A, B, num_processes):
    """
    Параллельно умножает матрицы A и B.
    
    Args:
        A: Первая матрица
        B: Вторая матрица
        num_processes: Количество процессов
        
    Returns:
        Результат умножения A * B
    """
    m, k1 = A.shape
    k2, n = B.shape
    
    if k1 != k2:
        raise ValueError(f"Несовместимые размеры матриц: {A.shape} и {B.shape}")
    
    # Разбиваем первую матрицу на части по строкам
    chunk_size = max(1, m // num_processes)
    chunks = []
    
    for i in range(0, m, chunk_size):
        end_row = min(i + chunk_size, m)
        chunks.append((i, end_row, A, B))
    
    # Выполняем умножение параллельно
    with multiprocessing.Pool(processes=num_processes) as pool:
        results = pool.map(matrix_multiply_chunk, chunks)
    
    # Собираем результат
    C = np.zeros((m, n))
    for start_row, end_row, chunk_result in results:
        C[start_row:end_row, :] = chunk_result
    
    return C

def measure_strong_scaling(matrix_size, max_processes):
    """
    Измеряет сильное масштабирование для умножения матриц.
    
    Args:
        matrix_size: Размер матриц (matrix_size x matrix_size)
        max_processes: Максимальное количество процессов для тестирования
        
    Returns:
        Кортеж (processes, times, speedups, efficiencies)
    """
    # Создаем случайные матрицы
    A = np.random.rand(matrix_size, matrix_size)
    B = np.random.rand(matrix_size, matrix_size)
    
    # Умножаем матрицы последовательно для проверки и измерения базового времени
    start_time = time.time()
    C_sequential = np.matmul(A, B)
    sequential_time = time.time() - start_time
    
    print(f"Sequential multiplication time: {sequential_time:.4f} s")
    
    # Измеряем время для разного количества процессов
    processes = list(range(1, max_processes + 1))
    times = []
    
    for num_processes in processes:
        print(f"Testing with {num_processes} processes...")
        start_time = time.time()
        C_parallel = parallel_matrix_multiply(A, B, num_processes)
        elapsed = time.time() - start_time
        times.append(elapsed)
        
        # Проверяем правильность результата
        if not np.allclose(C_sequential, C_parallel, rtol=1e-5, atol=1e-5):
            print(f"Warning: Parallel result with {num_processes} processes doesn't match sequential result!")
        
        print(f"  Time: {elapsed:.4f} s, Speedup: {sequential_time / elapsed:.2f}x")
    
    # Вычисляем ускорения и эффективность
    speedups = [sequential_time / t for t in times]
    efficiencies = [s / p for s, p in zip(speedups, processes)]
    
    return processes, times, speedups, efficiencies

def plot_scaling_results(processes, times, speedups, efficiencies):
    """Визуализирует результаты масштабирования."""
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))
    
    # График времени выполнения
    ax1.plot(processes, times, 'o-')
    ax1.set_xlabel('Number of Processes')
    ax1.set_ylabel('Execution Time (s)')
    ax1.set_title('Execution Time vs. Number of Processes')
    ax1.grid(True)
    
    # График ускорения
    ax2.plot(processes, speedups, 'o-')
    ax2.plot(processes, processes, 'r--', label='Ideal Speedup')
    ax2.set_xlabel('Number of Processes')
    ax2.set_ylabel('Speedup')
    ax2.set_title('Speedup vs. Number of Processes')
    ax2.legend()
    ax2.grid(True)
    
    # График эффективности
    ax3.plot(processes, efficiencies, 'o-')
    ax3.axhline(y=1.0, color='r', linestyle='--', label='Ideal Efficiency')
    ax3.set_xlabel('Number of Processes')
    ax3.set_ylabel('Efficiency')
    ax3.set_title('Efficiency vs. Number of Processes')
    ax3.legend()
    ax3.grid(True)
    
    plt.tight_layout()
    plt.savefig('strong_scaling_results.png')
    print("Results saved to 'strong_scaling_results.png'")

if __name__ == "__main__":
    # Измеряем сильное масштабирование для умножения матриц
    matrix_size = 500
    max_processes = min(8, multiprocessing.cpu_count())
    
    processes, times, speedups, efficiencies = measure_strong_scaling(matrix_size, max_processes)
    
    # Выводим результаты
    print("\nScaling Results:")
    print("Processes | Time (s) | Speedup | Efficiency")
    print("-" * 45)
    for p, t, s, e in zip(processes, times, speedups, efficiencies):
        print(f"{p:9d} | {t:7.4f} | {s:7.2f} | {e:9.2f}")
    
    # Визуализируем результаты (если установлен matplotlib)
    try:
        plot_scaling_results(processes, times, speedups, efficiencies)
    except ImportError:
        print("Matplotlib not installed. Skipping visualization.")
```

### Слабое масштабирование (Weak Scaling)

Слабое масштабирование фокусируется на поддержании постоянного времени выполнения путем увеличения размера задачи пропорционально количеству процессоров.

#### Пример измерения слабого масштабирования:

```python
import multiprocessing
import time
import numpy as np
import matplotlib.pyplot as plt

def matrix_vector_multiply_chunk(args):
    """
    Умножает часть матрицы на вектор.
    
    Args:
        args: Кортеж (start_row, end_row, chunk_A, x)
        
    Returns:
        Часть результирующего вектора
    """
    start_row, end_row, chunk_A, x = args
    result = np.zeros(end_row - start_row)
    
    for i in range(end_row - start_row):
        for j in range(len(x)):
            result[i] += chunk_A[i, j] * x[j]
    
    return start_row, end_row, result

def parallel_matrix_vector_multiply(A, x, num_processes):
    """
    Параллельно умножает матрицу A на вектор x.
    
    Args:
        A: Матрица
        x: Вектор
        num_processes: Количество процессов
        
    Returns:
        Результат умножения A * x
    """
    m, n = A.shape
    
    if n != len(x):
        raise ValueError(f"Несовместимые размеры: {A.shape} и {len(x)}")
    
    # Разбиваем матрицу на части по строкам
    chunk_size = max(1, m // num_processes)
    chunks = []
    
    for i in range(0, m, chunk_size):
        end_row = min(i + chunk_size, m)
        chunks.append((i, end_row, A[i:end_row, :], x))
    
    # Выполняем умножение параллельно
    with multiprocessing.Pool(processes=num_processes) as pool:
        results = pool.map(matrix_vector_multiply_chunk, chunks)
    
    # Собираем результат
    y = np.zeros(m)
    for start_row, end_row, chunk_result in results:
        y[start_row:end_row] = chunk_result
    
    return y

def measure_weak_scaling(base_size, max_processes):
    """
    Измеряет слабое масштабирование для умножения матрицы на вектор.
    
    Args:
        base_size: Базовый размер для одного процесса
        max_processes: Максимальное количество процессов для тестирования
        
    Returns:
        Кортеж (processes, sizes, times, efficiencies)
    """
    processes = list(range(1, max_processes + 1))
    sizes = [p * base_size for p in processes]
    times = []
    
    # Выполняем тесты для разного количества процессов
    for p, size in zip(processes, sizes):
        print(f"Testing with {p} processes, problem size = {size}...")
        
        # Создаем матрицу и вектор соответствующего размера
        A = np.random.rand(size, base_size)
        x = np.random.rand(base_size)
        
        # Измеряем время выполнения
        start_time = time.time()
        y = parallel_matrix_vector_multiply(A, x, p)
        elapsed = time.time() - start_time
        times.append(elapsed)
        
        # Проверяем правильность результата
        y_check = np.dot(A, x)
        if not np.allclose(y, y_check, rtol=1e-5, atol=1e-5):
            print(f"Warning: Parallel result with {p} processes doesn't match sequential result!")
        
        print(f"  Time: {elapsed:.4f} s")
    
    # Вычисляем эффективность (относительно времени выполнения на 1 процессе)
    base_time = times[0]
    efficiencies = [base_time / t for t in times]
    
    return processes, sizes, times, efficiencies

def plot_weak_scaling_results(processes, sizes, times, efficiencies):
    """Визуализирует результаты слабого масштабирования."""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # График времени выполнения
    ax1.plot(processes, times, 'o-')
    ax1.set_xlabel('Number of Processes')
    ax1.set_ylabel('Execution Time (s)')
    ax1.set_title('Weak Scaling: Execution Time')
    ax1.grid(True)
    
    # График эффективности
    ax2.plot(processes, efficiencies, 'o-')
    ax2.axhline(y=1.0, color='r', linestyle='--', label='Ideal Efficiency')
    ax2.set_xlabel('Number of Processes')
    ax2.set_ylabel('Efficiency')
    ax2.set_title('Weak Scaling: Efficiency')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.savefig('weak_scaling_results.png')
    print("Results saved to 'weak_scaling_results.png'")

if __name__ == "__main__":
    # Измеряем слабое масштабирование для умножения матрицы на вектор
    base_size = 2000  # Размер для одного процесса
    max_processes = min(8, multiprocessing.cpu_count())
    
    processes, sizes, times, efficiencies = measure_weak_scaling(base_size, max_processes)
    
    # Выводим результаты
    print("\nWeak Scaling Results:")
    print("Processes | Problem Size | Time (s) | Efficiency")
    print("-" * 50)
    for p, s, t, e in zip(processes, sizes, times, efficiencies):
        print(f"{p:9d} | {s:12d} | {t:7.4f} | {e:9.2f}")
    
    # Визуализируем результаты (если установлен matplotlib)
    try:
        plot_weak_scaling_results(processes, sizes, times, efficiencies)
    except ImportError:
        print("Matplotlib not installed. Skipping visualization.")
```

## Заключение

Параллельные вычисления стали неотъемлемой частью современной разработки программного обеспечения. С увеличением числа ядер в процессорах и развитием распределенных систем, способность эффективно использовать параллелизм становится всё более важным навыком.

Ключевые моменты:
1. Параллельные вычисления позволяют значительно ускорить обработку данных, используя несколько вычислительных ресурсов одновременно.
2. Существуют разные уровни и модели параллелизма, каждая со своими преимуществами и областями применения.
3. Закон Амдала определяет теоретические пределы ускорения, подчеркивая важность минимизации последовательных частей программы.
4. Основные проблемы параллельного программирования включают гонки данных, взаимоблокировки и состояния гонки.
5. Правильная синхронизация и проектирование параллельных алгоритмов критически важны для создания эффективных и правильных параллельных программ.

При разработке параллельных алгоритмов важно учитывать особенности конкретной задачи, архитектуры системы и требования к производительности. Не всякая задача одинаково хорошо распараллеливается, и дополнительные затраты на синхронизацию могут иногда перевесить преимущества параллельного выполнения для небольших или неподходящих задач.
