# Кэширование: механизмы кэширования, Redis

## Введение в кэширование

Кэширование — это техника временного хранения копий данных в быстродоступном месте для уменьшения времени доступа к информации. Кэширование значительно увеличивает производительность приложения, снижает нагрузку на базы данных и внешние сервисы.

### Ключевые концепции кэширования

- **Время жизни (TTL)** — период, в течение которого кэшированные данные считаются актуальными
- **Стратегии вытеснения** — правила, определяющие, какие данные удаляются из кэша при его заполнении
- **Ключи кэша** — уникальные идентификаторы для доступа к кэшированным данным
- **Hit и Miss** — успешное и неуспешное обращение к кэшу
- **Инвалидация кэша** — процесс принудительной очистки кэша при изменении данных

### Уровни кэширования

1. **Клиентский кэш** (браузеры, клиентские приложения)
2. **CDN** (Content Delivery Networks)
3. **API Gateway кэш**
4. **Кэш приложения** (In-memory, Redis, Memcached)
5. **Кэш базы данных** (буферы и кэш СУБД)

## Встроенные механизмы кэширования в Python

### Декоратор functools.lru_cache

```python
import time
import functools

# Кэширование результатов функции с использованием LRU кэша
@functools.lru_cache(maxsize=128)
def fibonacci(n):
    """Вычисляет n-ое число Фибоначчи (рекурсивно)."""
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)

# Демонстрация эффекта кэширования
def measure_time(func, *args, **kwargs):
    start = time.time()
    result = func(*args, **kwargs)
    end = time.time()
    return result, end - start

# Без кэширования
def fibonacci_no_cache(n):
    if n <= 1:
        return n
    return fibonacci_no_cache(n-1) + fibonacci_no_cache(n-2)

# Сравнение производительности
n = 35
result1, time1 = measure_time(fibonacci_no_cache, n)
result2, time2 = measure_time(fibonacci, n)

print(f"Fibonacci({n}) без кэширования: {result1}, время: {time1:.6f} сек")
print(f"Fibonacci({n}) с кэшированием: {result2}, время: {time2:.6f} сек")
print(f"Ускорение: {time1/time2:.1f}x")

# Информация о состоянии кэша
print(f"\nИнформация о кэше:")
print(f"Размер кэша: {fibonacci.cache_info().currsize}")
print(f"Максимальный размер: {fibonacci.cache_info().maxsize}")
print(f"Количество попаданий (hits): {fibonacci.cache_info().hits}")
print(f"Количество промахов (misses): {fibonacci.cache_info().misses}")

# Очистка кэша
fibonacci.cache_clear()
print(f"Кэш очищен: {fibonacci.cache_info()}")
```

### Настраиваемый кэш с TTL

```python
import time
import functools
from datetime import datetime, timedelta

class TTLCache:
    """Простой кэш с контролем времени жизни записей."""
    
    def __init__(self, ttl_seconds=300):
        self.cache = {}
        self.ttl = ttl_seconds
    
    def get(self, key):
        """Получает значение из кэша, если оно существует и не истекло."""
        if key not in self.cache:
            return None
        
        value, timestamp = self.cache[key]
        if datetime.now() - timestamp > timedelta(seconds=self.ttl):
            # Значение истекло
            del self.cache[key]
            return None
        
        return value
    
    def set(self, key, value):
        """Сохраняет значение в кэш с текущей временной меткой."""
        self.cache[key] = (value, datetime.now())
    
    def clear(self):
        """Очищает весь кэш."""
        self.cache.clear()
    
    def remove_expired(self):
        """Удаляет истекшие записи из кэша."""
        now = datetime.now()
        expired_keys = [
            key for key, (_, timestamp) in self.cache.items()
            if now - timestamp > timedelta(seconds=self.ttl)
        ]
        
        for key in expired_keys:
            del self.cache[key]
        
        return len(expired_keys)

# Использование TTLCache для кэширования функции
def ttl_cache(ttl_seconds=300, maxsize=128):
    """Декоратор для кэширования функции с TTL."""
    cache = TTLCache(ttl_seconds=ttl_seconds)
    cache_info_data = {"hits": 0, "misses": 0}
    
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # Создаем ключ кэша на основе аргументов
            key = str((args, frozenset(kwargs.items())))
            
            # Проверяем кэш
            cached_value = cache.get(key)
            if cached_value is not None:
                cache_info_data["hits"] += 1
                return cached_value
            
            # Вычисляем результат
            cache_info_data["misses"] += 1
            result = func(*args, **kwargs)
            
            # Сохраняем в кэш
            cache.set(key, result)
            return result
        
        # Добавляем методы для управления кэшем
        def cache_info():
            return (f"CacheInfo(hits={cache_info_data['hits']}, "
                    f"misses={cache_info_data['misses']}, "
                    f"ttl={cache.ttl}, size={len(cache.cache)})")
        
        def cache_clear():
            cache.clear()
            cache_info_data["hits"] = 0
            cache_info_data["misses"] = 0
        
        def remove_expired():
            return cache.remove_expired()
        
        wrapper.cache_info = cache_info
        wrapper.cache_clear = cache_clear
        wrapper.remove_expired = remove_expired
        
        return wrapper
    
    return decorator

# Пример использования
@ttl_cache(ttl_seconds=10)
def get_weather(city):
    """Имитация запроса к API погоды."""
    print(f"Получение данных о погоде для {city} (дорогая операция)")
    time.sleep(1)  # Имитация задержки сети
    return f"Солнечно, 25°C в {city} на {datetime.now().strftime('%H:%M:%S')}"

# Демонстрация работы
for _ in range(3):
    print(get_weather("Москва"))  # Первый запрос - miss, остальные - hit
    print(get_weather("Санкт-Петербург"))  # То же самое

print(f"Информация о кэше: {get_weather.cache_info()}")

print("\nЖдем истечения TTL...")
time.sleep(11)  # Ждем, пока истечет TTL

print("\nПосле истечения TTL:")
print(get_weather("Москва"))  # Miss - TTL истек
print(get_weather.cache_info())
```

### Кэширование на диске с diskcache

```python
import diskcache as dc
import time
import functools

# Создание кэша на диске
cache = dc.Cache('./cache_dir')

# Декоратор для кэширования с использованием diskcache
def disk_cache(expire=300, tag=None):
    """
    Декоратор для кэширования функции с хранением данных на диске.
    
    Args:
        expire: Время жизни в секундах (0 = бесконечно)
        tag: Тег для группировки записей кэша
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # Создаем ключ кэша
            key = f"{func.__module__}.{func.__name__}:{str(args)}:{str(kwargs)}"
            
            # Проверяем кэш
            result = cache.get(key)
            if result is not None:
                print(f"Cache HIT for {key}")
                return result
            
            # Вычисляем результат
            print(f"Cache MISS for {key}")
            result = func(*args, **kwargs)
            
            # Сохраняем в кэш
            cache.set(key, result, expire=expire, tag=tag)
            return result
        
        # Добавляем метод для очистки кэша
        def clear_cache(pattern=None):
            if pattern:
                # Удаляем записи по шаблону
                count = 0
                for key in cache.iterkeys():
                    if pattern in key:
                        del cache[key]
                        count += 1
                return count
            else:
                # Удаляем все записи, связанные с этой функцией
                prefix = f"{func.__module__}.{func.__name__}:"
                count = 0
                for key in cache.iterkeys():
                    if key.startswith(prefix):
                        del cache[key]
                        count += 1
                return count
        
        wrapper.clear_cache = clear_cache
        return wrapper
    
    return decorator

# Пример использования
@disk_cache(expire=30, tag="database")
def get_user_data(user_id):
    """Имитация запроса к базе данных."""
    print(f"Выполняется запрос к БД для пользователя {user_id}")
    time.sleep(1)  # Имитация задержки БД
    return {
        'id': user_id,
        'name': f'User {user_id}',
        'created_at': time.time(),
        'data': [1, 2, 3, 4, 5]
    }

# Демонстрация работы кэша на диске
for _ in range(3):
    print(get_user_data(123))
    print(get_user_data(456))

# Статистика кэша
print(f"\nСтатистика кэша:")
print(f"Размер кэша: {len(cache)} записей")
print(f"Размер на диске: {cache.volume()} байт")
print(f"Директория кэша: {cache.directory}")

# Очистка кэша для конкретной функции
cleared = get_user_data.clear_cache()
print(f"\nОчищено записей кэша: {cleared}")

# Очистка всего кэша
cache.clear()
print(f"Весь кэш очищен")
```

## Кэширование запросов к внешним API

```python
import requests
import hashlib
import pickle
import os
import time
from datetime import datetime, timedelta

class APICache:
    """Класс для кэширования запросов к внешним API."""
    
    def __init__(self, cache_dir='./api_cache', default_ttl=3600):
        """
        Инициализация кэша.
        
        Args:
            cache_dir: Директория для хранения кэша
            default_ttl: Время жизни кэша по умолчанию в секундах
        """
        self.cache_dir = cache_dir
        self.default_ttl = default_ttl
        
        # Создаем директорию для кэша, если ее нет
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
    
    def _get_cache_key(self, url, params=None, headers=None):
        """Генерирует ключ кэша на основе URL и параметров."""
        # Создаем строку для хеширования
        key_parts = [url]
        if params:
            key_parts.append(str(sorted(params.items())))
        if headers:
            # Используем только важные для кэша заголовки
            cache_headers = {k: v for k, v in headers.items() 
                           if k.lower() in ('accept', 'content-type')}
            if cache_headers:
                key_parts.append(str(sorted(cache_headers.items())))
        
        key_string = ''.join(key_parts)
        
        # Создаем MD5 хеш
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def _get_cache_path(self, cache_key):
        """Возвращает путь к файлу кэша."""
        return os.path.join(self.cache_dir, f"{cache_key}.cache")
    
    def get(self, url, params=None, headers=None, ttl=None):
        """
        Получает данные из кэша или выполняет запрос к API.
        
        Args:
            url: URL для запроса
            params: Параметры запроса
            headers: Заголовки запроса
            ttl: Время жизни кэша для этого запроса (переопределяет default_ttl)
        
        Returns:
            Ответ от API (из кэша или свежий)
        """
        cache_key = self._get_cache_key(url, params, headers)
        cache_path = self._get_cache_path(cache_key)
        
        # Проверяем наличие кэша
        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'rb') as f:
                    cached_data = pickle.load(f)
                
                # Проверяем, не истек ли срок действия кэша
                if cached_data['expires_at'] > datetime.now():
                    print(f"Cache HIT for {url}")
                    return cached_data['response']
            except (pickle.PickleError, KeyError, EOFError):
                # Если с кэшем что-то не так, игнорируем его
                pass
        
        # Кэш отсутствует или устарел - выполняем запрос
        print(f"Cache MISS for {url}")
        response = requests.get(url, params=params, headers=headers)
        
        # Сохраняем ответ в кэш
        ttl = ttl or self.default_ttl
        cache_data = {
            'response': response,
            'created_at': datetime.now(),
            'expires_at': datetime.now() + timedelta(seconds=ttl),
            'url': url,
            'params': params,
            'headers': {k: v for k, v in (headers or {}).items() 
                      if k.lower() in ('accept', 'content-type')}
        }
        
        with open(cache_path, 'wb') as f:
            pickle.dump(cache_data, f)
        
        return response
    
    def clear(self, url=None, params=None, headers=None):
        """
        Очищает кэш для конкретного запроса или весь кэш.
        
        Args:
            url: URL запроса (None для очистки всего кэша)
            params: Параметры запроса
            headers: Заголовки запроса
        
        Returns:
            Количество удаленных файлов кэша
        """
        if url:
            # Очищаем кэш для конкретного запроса
            cache_key = self._get_cache_key(url, params, headers)
            cache_path = self._get_cache_path(cache_key)
            
            if os.path.exists(cache_path):
                os.remove(cache_path)
                return 1
            return 0
        else:
            # Очищаем весь кэш
            count = 0
            for filename in os.listdir(self.cache_dir):
                if filename.endswith(".cache"):
                    os.remove(os.path.join(self.cache_dir, filename))
                    count += 1
            return count
    
    def get_stats(self):
        """Возвращает статистику кэша."""
        files = [f for f in os.listdir(self.cache_dir) if f.endswith('.cache')]
        
        total_size = sum(os.path.getsize(os.path.join(self.cache_dir, f)) for f in files)
        
        # Анализируем содержимое кэша
        expired = 0
        valid = 0
        now = datetime.now()
        
        for filename in files:
            try:
                with open(os.path.join(self.cache_dir, filename), 'rb') as f:
                    data = pickle.load(f)
                    if data['expires_at'] < now:
                        expired += 1
                    else:
                        valid += 1
            except (pickle.PickleError, KeyError, EOFError):
                expired += 1
        
        return {
            'total_entries': len(files),
            'valid_entries': valid,
            'expired_entries': expired,
            'total_size_bytes': total_size,
            'total_size_kb': total_size / 1024,
            'cache_dir': self.cache_dir
        }

# Пример использования
def demo_api_cache():
    # Создаем объект кэша
    api_cache = APICache(cache_dir='./api_cache', default_ttl=60)
    
    # Выполняем запросы к публичному API с кэшированием
    for _ in range(3):
        # Этот запрос будет кэшироваться
        response = api_cache.get(
            'https://jsonplaceholder.typicode.com/todos/1',
            params={'_': int(time.time())}  # Добавляем случайный параметр для демонстрации
        )
        print(f"Status code: {response.status_code}")
        print(f"Response: {response.json()}")
        print()
    
    # Статистика кэша
    stats = api_cache.get_stats()
    print("Cache Statistics:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # Очистка всего кэша
    cleared = api_cache.clear()
    print(f"\nОчищено {cleared} записей кэша")

# Запускаем демонстрацию
demo_api_cache()
```

## Кэширование запросов к базе данных

```python
import sqlite3
import hashlib
import pickle
import functools
import time
from datetime import datetime, timedelta

class DBCache:
    """Класс для кэширования запросов к базе данных."""
    
    def __init__(self, db_path, cache_table='query_cache', default_ttl=300):
        """
        Инициализация кэша.
        
        Args:
            db_path: Путь к базе данных SQLite
            cache_table: Имя таблицы для хранения кэша
            default_ttl: Время жизни кэша по умолчанию в секундах
        """
        self.db_path = db_path
        self.cache_table = cache_table
        self.default_ttl = default_ttl
        
        # Инициализируем таблицу кэша
        self._init_cache_table()
    
    def _init_cache_table(self):
        """Создает таблицу кэша, если она не существует."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute(f'''
        CREATE TABLE IF NOT EXISTS {self.cache_table} (
            key TEXT PRIMARY KEY,
            value BLOB,
            created_at TIMESTAMP,
            expires_at TIMESTAMP
        )
        ''')
        
        # Индекс для быстрого поиска по времени истечения
        cursor.execute(f'''
        CREATE INDEX IF NOT EXISTS idx_{self.cache_table}_expires
        ON {self.cache_table} (expires_at)
        ''')
        
        conn.commit()
        conn.close()
    
    def _get_cache_key(self, query, params=None):
        """Генерирует ключ кэша на основе запроса и параметров."""
        key_parts = [query]
        if params:
            key_parts.append(str(params))
        
        key_string = ''.join(key_parts)
        
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def get(self, query, params=None, ttl=None):
        """
        Получает результаты запроса из кэша или выполняет запрос.
        
        Args:
            query: SQL-запрос
            params: Параметры запроса
            ttl: Время жизни кэша для этого запроса (переопределяет default_ttl)
        
        Returns:
            Кортеж (is_cached, results), где is_cached указывает, были ли данные взяты из кэша
        """
        cache_key = self._get_cache_key(query, params)
        
        # Пытаемся получить данные из кэша
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute(f'''
        SELECT value, expires_at FROM {self.cache_table}
        WHERE key = ? AND expires_at > ?
        ''', (cache_key, datetime.now()))
        
        row = cursor.fetchone()
        
        if row:
            # Данные найдены в кэше и не истекли
            value_blob, expires_at = row
            results = pickle.loads(value_blob)
            conn.close()
            return True, results
        
        # Данных нет в кэше или они устарели - выполняем запрос
        db_conn = sqlite3.connect(self.db_path)
        db_cursor = db_conn.cursor()
        
        start_time = time.time()
        db_cursor.execute(query, params or ())
        results = db_cursor.fetchall()
        execution_time = time.time() - start_time
        
        db_conn.close()
        
        # Сохраняем результаты в кэш
        ttl = ttl or self.default_ttl
        expires_at = datetime.now() + timedelta(seconds=ttl)
        
        value_blob = pickle.dumps(results)
        
        cursor.execute(f'''
        INSERT OR REPLACE INTO {self.cache_table}
        (key, value, created_at, expires_at)
        VALUES (?, ?, ?, ?)
        ''', (cache_key, value_blob, datetime.now(), expires_at))
        
        conn.commit()
        conn.close()
        
        return False, results
    
    def invalidate(self, query=None, params=None):
        """
        Инвалидирует кэш для конкретного запроса или очищает весь кэш.
        
        Args:
            query: SQL-запрос (None для очистки всего кэша)
            params: Параметры запроса
        
        Returns:
            Количество удаленных записей кэша
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if query:
            # Инвалидируем кэш для конкретного запроса
            cache_key = self._get_cache_key(query, params)
            cursor.execute(f'''
            DELETE FROM {self.cache_table}
            WHERE key = ?
            ''', (cache_key,))
        else:
            # Инвалидируем весь кэш
            cursor.execute(f'''
            DELETE FROM {self.cache_table}
            ''')
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        return deleted_count
    
    def clear_expired(self):
        """
        Удаляет истекшие записи кэша.
        
        Returns:
            Количество удаленных записей
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute(f'''
        DELETE FROM {self.cache_table}
        WHERE expires_at < ?
        ''', (datetime.now(),))
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        return deleted_count
    
    def get_stats(self):
        """Возвращает статистику кэша."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Общее количество записей
        cursor.execute(f'''
        SELECT COUNT(*) FROM {self.cache_table}
        ''')
        total_entries = cursor.fetchone()[0]
        
        # Количество истекших записей
        cursor.execute(f'''
        SELECT COUNT(*) FROM {self.cache_table}
        WHERE expires_at < ?
        ''', (datetime.now(),))
        expired_entries = cursor.fetchone()[0]
        
        # Размер таблицы кэша (приблизительно)
        cursor.execute(f'''
        SELECT SUM(length(value)) FROM {self.cache_table}
        ''')
        total_size = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return {
            'total_entries': total_entries,
            'valid_entries': total_entries - expired_entries,
            'expired_entries': expired_entries,
            'total_size_bytes': total_size,
            'total_size_kb': total_size / 1024,
            'db_path': self.db_path,
            'cache_table': self.cache_table
        }

# Декоратор для кэширования запросов к БД
def db_cache(ttl=300):
    """
    Декоратор для кэширования функций, выполняющих запросы к базе данных.
    
    Args:
        ttl: Время жизни кэша в секундах
    """
    cache = DBCache('cache.db', default_ttl=ttl)
    
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # Создаем ключ кэша на основе функции и аргументов
            query = f"{func.__module__}.{func.__name__}"
            params = args + tuple(sorted(kwargs.items()))
            
            # Проверяем кэш
            is_cached, result = cache.get(query, params, ttl)
            
            if is_cached:
                print(f"Cache HIT for {func.__name__}{args}")
            else:
                print(f"Cache MISS for {func.__name__}{args}")
                # Если не в кэше, выполняем функцию
                result = func(*args, **kwargs)
                
                # Обновляем кэш вручную (так как функция уже была выполнена)
                cache_key = cache._get_cache_key(query, params)
                conn = sqlite3.connect(cache.db_path)
                cursor = conn.cursor()
                
                value_blob = pickle.dumps(result)
                expires_at = datetime.now() + timedelta(seconds=ttl)
                
                cursor.execute(f'''
                INSERT OR REPLACE INTO {cache.cache_table}
                (key, value, created_at, expires_at)
                VALUES (?, ?, ?, ?)
                ''', (cache_key, value_blob, datetime.now(), expires_at))
                
                conn.commit()
                conn.close()
            
            return result
        
        # Добавляем методы для управления кэшем
        wrapper.invalidate_cache = lambda: cache.invalidate(f"{func.__module__}.{func.__name__}")
        wrapper.clear_all_cache = lambda: cache.invalidate()
        wrapper.get_cache_stats = lambda: cache.get_stats()
        
        return wrapper
    
    return decorator

# Пример использования кэша БД
def demo_db_cache():
    # Создаем тестовую базу данных
    conn = sqlite3.connect('example.db')
    cursor = conn.cursor()
    
    # Создаем таблицу для тестовых данных
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS users (
        id INTEGER PRIMARY KEY,
        name TEXT,
        email TEXT,
        created_at TIMESTAMP
    )
    ''')
    
    # Добавляем тестовые данные
    users_data = [
        (1, 'Alice', 'alice@example.com', datetime.now()),
        (2, 'Bob', 'bob@example.com', datetime.now()),
        (3, 'Charlie', 'charlie@example.com', datetime.now())
    ]
    
    cursor.executemany('''
    INSERT OR REPLACE INTO users (id, name, email, created_at)
    VALUES (?, ?, ?, ?)
    ''', users_data)
    
    conn.commit()
    conn.close()
    
    # Создаем объект кэша
    db_cache = DBCache('cache.db', default_ttl=60)
    
    # Выполняем запросы с кэшированием
    for _ in range(3):
        # Первый запрос: miss, следующие: hit
        is_cached, users = db_cache.get(
            "SELECT * FROM users WHERE id > ?",
            params=(0,)
        )
        
        status = "HIT" if is_cached else "MISS"
        print(f"Cache {status}: Got {len(users)} users")
        for user in users:
            print(f"  {user}")
        print()
    
    # Инвалидация кэша
    invalidated = db_cache.invalidate(
        "SELECT * FROM users WHERE id > ?",
        params=(0,)
    )
    print(f"Инвалидировано {invalidated} записей кэша")
    
    # Еще один запрос после инвалидации (miss)
    is_cached, users = db_cache.get(
        "SELECT * FROM users WHERE id > ?",
        params=(0,)
    )
    
    status = "HIT" if is_cached else "MISS"
    print(f"Cache {status} после инвалидации")
    
    # Статистика кэша
    stats = db_cache.get_stats()
    print("\nСтатистика кэша:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # Очистка истекших записей
    cleared = db_cache.clear_expired()
    print(f"\nУдалено {cleared} истекших записей кэша")

# Запускаем демонстрацию
demo_db_cache()
```

## Кэширование с использованием Redis

Redis — высокопроизводительное хранилище данных в памяти, которое поддерживает различные структуры данных и имеет встроенную поддержку TTL.

### Основы работы с Redis в Python

```python
import redis
import time
import json

# Подключение к Redis
r = redis.Redis(
    host='localhost',
    port=6379,
    db=0,
    decode_responses=True  # Автоматическое декодирование байтов в строки
)

# Проверка соединения
try:
    r.ping()
    print("Подключение к Redis успешно!")
except redis.exceptions.ConnectionError:
    print("Ошибка подключения к Redis. Убедитесь, что сервер запущен.")
    exit(1)

# Базовые операции с ключами-значениями
r.set('my_key', 'Hello, Redis!')
value = r.get('my_key')
print(f"Значение: {value}")

# Установка TTL (время жизни)
r.setex('temp_key', 10, 'Значение с таймаутом')  # истекает через 10 секунд
print(f"Значение с TTL: {r.get('temp_key')}")
print(f"TTL: {r.ttl('temp_key')} секунд")

# Проверка наличия ключа
if r.exists('my_key'):
    print("Ключ 'my_key' существует")

# Хранение структурированных данных
user_data = {
    'id': 123,
    'name': 'John Doe',
    'email': 'john@example.com',
    'is_active': True
}

# Сериализация в JSON и сохранение
r.set('user:123', json.dumps(user_data))

# Получение и десериализация
user_json = r.get('user:123')
if user_json:
    user = json.loads(user_json)
    print(f"Пользователь: {user['name']} ({user['email']})")

# Список операций
r.rpush('my_list', 'item1', 'item2', 'item3')
list_length = r.llen('my_list')
list_items = r.lrange('my_list', 0, -1)  # Все элементы
print(f"Список ({list_length} элементов): {list_items}")

# Хеш-таблицы (словари)
r.hset('user:profile:123', mapping={
    'username': 'johndoe',
    'first_name': 'John',
    'last_name': 'Doe',
    'visits': 10
})

# Получение всего хеша
profile = r.hgetall('user:profile:123')
print(f"Профиль: {profile}")

# Инкремент числового поля
r.hincrby('user:profile:123', 'visits', 1)
visits = r.hget('user:profile:123', 'visits')
print(f"Посещения: {visits}")

# Множества
r.sadd('tags', 'python', 'redis', 'caching', 'nosql')
tags = r.smembers('tags')
print(f"Теги: {tags}")

# Проверка наличия в множестве
is_member = r.sismember('tags', 'python')
print(f"'python' в тегах: {is_member}")

# Упорядоченные множества (sorted sets)
r.zadd('leaderboard', {
    'player1': 100,
    'player2': 150,
    'player3': 120,
    'player4': 200
})

# Получение топ-3 игроков (в порядке убывания)
top_players = r.zrevrange('leaderboard', 0, 2, withscores=True)
print("Таблица лидеров:")
for i, (player, score) in enumerate(top_players, 1):
    print(f"  {i}. {player} - {int(score)} баллов")

# Очистка тестовых данных
r.delete('my_key', 'temp_key', 'user:123', 'my_list', 
         'user:profile:123', 'tags', 'leaderboard')
print("\nТестовые данные очищены")
```

### Кэширование функций с Redis

```python
import redis
import json
import time
import hashlib
import functools
from datetime import datetime

# Подключение к Redis
redis_client = redis.Redis(
    host='localhost',
    port=6379,
    db=0,
    decode_responses=True
)

def redis_cache(prefix='cache', ttl=300):
    """
    Декоратор для кэширования функций с использованием Redis.
    
    Args:
        prefix: Префикс для ключей кэша
        ttl: Время жизни кэша в секундах
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # Создаем ключ кэша
            cache_key = f"{prefix}:{func.__module__}:{func.__name__}:"
            
            # Добавляем хеш аргументов к ключу
            arg_hash = hashlib.md5(
                str((args, sorted(kwargs.items()))).encode()
            ).hexdigest()
            cache_key += arg_hash
            
            # Проверяем кэш
            cached_value = redis_client.get(cache_key)
            if cached_value:
                try:
                    # Десериализуем результат
                    result = json.loads(cached_value)
                    print(f"Cache HIT for {func.__name__}")
                    return result
                except json.JSONDecodeError:
                    # Если не удалось десериализовать, удаляем запись
                    redis_client.delete(cache_key)
            
            # Кэш отсутствует или невалиден
            print(f"Cache MISS for {func.__name__}")
            result = func(*args, **kwargs)
            
            # Сериализуем и сохраняем результат в кэш
            try:
                redis_client.setex(
                    cache_key,
                    ttl,
                    json.dumps(result, default=str)  # default=str для сериализации дат
                )
            except (TypeError, json.JSONDecodeError) as e:
                print(f"Warning: Could not cache result: {e}")
            
            return result
        
        # Добавляем метод для инвалидации кэша
        def invalidate_cache(*args, **kwargs):
            if args or kwargs:
                # Инвалидация для конкретных аргументов
                arg_hash = hashlib.md5(
                    str((args, sorted(kwargs.items()))).encode()
                ).hexdigest()
                cache_key = f"{prefix}:{func.__module__}:{func.__name__}:{arg_hash}"
                deleted = redis_client.delete(cache_key)
                return deleted
            else:
                # Инвалидация всех кэшей для данной функции
                pattern = f"{prefix}:{func.__module__}:{func.__name__}:*"
                keys = redis_client.keys(pattern)
                if keys:
                    deleted = redis_client.delete(*keys)
                    return deleted
                return 0
        
        wrapper.invalidate_cache = invalidate_cache
        return wrapper
    
    return decorator

# Пример использования декоратора redis_cache
@redis_cache(ttl=60)
def get_fibonacci(n):
    """Вычисляет n-е число Фибоначчи."""
    print(f"Вычисление fibonacci({n})...")
    if n <= 1:
        return n
    a, b = 0, 1
    for _ in range(2, n + 1):
        a, b = b, a + b
    return b

@redis_cache(prefix='api', ttl=300)
def simulate_api_call(endpoint, params=None):
    """Имитирует вызов API с задержкой."""
    print(f"Calling API {endpoint} with params {params}...")
    time.sleep(1)  # Имитация задержки сети
    
    return {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'endpoint': endpoint,
        'params': params or {},
        'data': [1, 2, 3, 4, 5],
        'status': 'success'
    }

# Демонстрация работы кэширования
def demo_redis_cache():
    # Кэширование вычислений
    print("=== Кэширование вычислений ===")
    for _ in range(3):  # Первый вызов - miss, следующие - hit
        result = get_fibonacci(30)
        print(f"Fibonacci(30) = {result}")
    
    # Кэширование API-вызовов
    print("\n=== Кэширование API-вызовов ===")
    for _ in range(3):
        response = simulate_api_call('/users', {'active': True})
        print(f"API response timestamp: {response['timestamp']}")
    
    # Инвалидация кэша
    print("\n=== Инвалидация кэша ===")
    deleted = get_fibonacci.invalidate_cache(30)
    print(f"Инвалидировано {deleted} записей кэша")
    
    # После инвалидации - miss
    result = get_fibonacci(30)
    print(f"Fibonacci(30) = {result} (after invalidation)")
    
    # Инвалидация всех кэшей функции
    deleted = simulate_api_call.invalidate_cache()
    print(f"Инвалидировано {deleted} записей кэша API")

# Запускаем демонстрацию
demo_redis_cache()
```

### Распределенный кэш с помощью Redis

```python
import redis
import json
import time
import random
import threading
from datetime import datetime

# Создаем пул соединений Redis (для многопоточного использования)
redis_pool = redis.ConnectionPool(
    host='localhost',
    port=6379,
    db=0,
    decode_responses=True
)

class DistributedCache:
    """
    Распределенный кэш с использованием Redis,
    поддерживающий блокировки для предотвращения проблемы Thunder Herd.
    """
    
    def __init__(self, namespace='cache', default_ttl=300, lock_ttl=10):
        """
        Инициализация кэша.
        
        Args:
            namespace: Пространство имен для ключей кэша
            default_ttl: Время жизни кэша по умолчанию (секунды)
            lock_ttl: Время жизни блокировки (секунды)
        """
        self.namespace = namespace
        self.default_ttl = default_ttl
        self.lock_ttl = lock_ttl
        self.redis = redis.Redis(connection_pool=redis_pool)
    
    def _get_cache_key(self, key):
        """Получает полный ключ кэша с учетом пространства имен."""
        return f"{self.namespace}:{key}"
    
    def _get_lock_key(self, key):
        """Получает ключ блокировки для данного ключа кэша."""
        return f"{self.namespace}:lock:{key}"
    
    def _acquire_lock(self, lock_key, lock_value, ttl):
        """
        Пытается получить блокировку.
        
        Args:
            lock_key: Ключ блокировки
            lock_value: Уникальное значение для идентификации владельца блокировки
            ttl: Время жизни блокировки (секунды)
        
        Returns:
            True если блокировка получена, False иначе
        """
        return self.redis.set(lock_key, lock_value, ex=ttl, nx=True)
    
    def _release_lock(self, lock_key, lock_value):
        """
        Освобождает блокировку, если она принадлежит нам.
        
        Args:
            lock_key: Ключ блокировки
            lock_value: Значение блокировки для проверки владения
        
        Returns:
            True если блокировка освобождена, False иначе
        """
        # Используем Lua-скрипт для атомарной проверки и удаления
        script = """
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
        """
        result = self.redis.eval(script, 1, lock_key, lock_value)
        return result == 1
    
    def get(self, key, callback=None, ttl=None, wait_for_lock=True, max_wait=5):
        """
        Получает значение из кэша с поддержкой блокировок.
        
        Args:
            key: Ключ кэша
            callback: Функция для вычисления значения при отсутствии в кэше
            ttl: Время жизни кэша (переопределяет default_ttl)
            wait_for_lock: Ждать ли освобождения блокировки
            max_wait: Максимальное время ожидания блокировки (секунды)
        
        Returns:
            Tuple (value, is_cached) - значение и флаг, указывающий, было ли оно из кэша
        """
        cache_key = self._get_cache_key(key)
        lock_key = self._get_lock_key(key)
        ttl = ttl or self.default_ttl
        
        # Проверяем кэш
        cached_value = self.redis.get(cache_key)
        if cached_value:
            try:
                # Кэш найден
                return json.loads(cached_value), True
            except json.JSONDecodeError:
                # Невалидный кэш, удаляем
                self.redis.delete(cache_key)
        
        # Кэш не найден, нужно вычислить значение
        if callback is None:
            return None, False
        
        # Уникальный идентификатор для блокировки
        lock_value = f"{threading.get_ident()}:{time.time()}"
        
        # Пытаемся получить блокировку
        got_lock = self._acquire_lock(lock_key, lock_value, self.lock_ttl)
        
        if got_lock:
            try:
                # Мы получили блокировку, вычисляем значение
                value = callback()
                
                # Сохраняем в кэш
                self.redis.setex(
                    cache_key,
                    ttl,
                    json.dumps(value, default=str)
                )
                
                return value, False
            finally:
                # Всегда освобождаем блокировку
                self._release_lock(lock_key, lock_value)
        elif wait_for_lock:
            # Ждем освобождения блокировки
            start_time = time.time()
            
            while time.time() - start_time < max_wait:
                # Проверяем, появилось ли значение в кэше
                cached_value = self.redis.get(cache_key)
                if cached_value:
                    try:
                        return json.loads(cached_value), True
                    except json.JSONDecodeError:
                        # Невалидный кэш, продолжаем ждать
                        pass
                
                # Проверяем, освободилась ли блокировка
                if not self.redis.exists(lock_key):
                    # Блокировка освободилась, рекурсивно пробуем снова
                    return self.get(key, callback, ttl, wait_for_lock, 
                                    max_wait - (time.time() - start_time))
                
                # Ждем немного перед следующей попыткой
                time.sleep(0.1)
            
            # Превышено время ожидания, вычисляем значение без блокировки
            value = callback()
            return value, False
        else:
            # Не ждем блокировку, сразу вычисляем значение
            value = callback()
            return value, False
    
    def set(self, key, value, ttl=None):
        """
        Сохраняет значение в кэш.
        
        Args:
            key: Ключ кэша
            value: Значение для сохранения
            ttl: Время жизни (переопределяет default_ttl)
        """
        cache_key = self._get_cache_key(key)
        ttl = ttl or self.default_ttl
        
        self.redis.setex(
            cache_key,
            ttl,
            json.dumps(value, default=str)
        )
    
    def delete(self, key):
        """Удаляет значение из кэша."""
        cache_key = self._get_cache_key(key)
        return self.redis.delete(cache_key)
    
    def exists(self, key):
        """Проверяет наличие ключа в кэше."""
        cache_key = self._get_cache_key(key)
        return self.redis.exists(cache_key)
    
    def clear_namespace(self):
        """Удаляет все ключи в текущем пространстве имен."""
        pattern = f"{self.namespace}:*"
        keys = self.redis.keys(pattern)
        if keys:
            return self.redis.delete(*keys)
        return 0

# Демонстрация распределенного кэша
def slow_database_query(query_id):
    """Имитирует медленный запрос к базе данных."""
    print(f"Выполнение запроса {query_id} к БД...")
    time.sleep(random.uniform(0.5, 2.0))
    return {
        'id': query_id,
        'result': f"Data for query {query_id}",
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')
    }

def worker(cache, query_id, worker_id):
    """Функция для имитации параллельных запросов."""
    print(f"Worker {worker_id}: Запрос данных для {query_id}")
    
    start_time = time.time()
    
    value, is_cached = cache.get(
        f"query:{query_id}",
        callback=lambda: slow_database_query(query_id),
        ttl=30
    )
    
    end_time = time.time()
    elapsed = end_time - start_time
    
    status = "HIT" if is_cached else "MISS"
    print(f"Worker {worker_id}: Cache {status} for {query_id} - "
          f"timestamp: {value['timestamp']}, "
          f"elapsed: {elapsed:.3f}s")

def demo_distributed_cache():
    # Создаем распределенный кэш
    cache = DistributedCache(namespace='demo', default_ttl=60, lock_ttl=10)
    
    # Очищаем предыдущие данные
    cache.clear_namespace()
    
    # Тестируем простые операции
    cache.set('test_key', {'name': 'Test Value', 'created_at': datetime.now()})
    value, is_cached = cache.get('test_key')
    print(f"Test key: {value}, is_cached: {is_cached}")
    
    # Имитируем Thunder Herd проблему (множество одновременных запросов к одному ресурсу)
    print("\n=== Имитация Thunder Herd проблемы ===")
    
    # Создаем потоки для одновременных запросов к одному ресурсу
    query_id = "user:profile:123"
    threads = []
    
    for i in range(5):
        thread = threading.Thread(
            target=worker,
            args=(cache, query_id, i)
        )
        threads.append(thread)
    
    # Запускаем все потоки
    for thread in threads:
        thread.start()
        time.sleep(0.1)  # Небольшая задержка между запусками
    
    # Ждем завершения всех потоков
    for thread in threads:
        thread.join()
    
    # Проверяем повторное использование кэша
    print("\n=== Повторное использование кэша ===")
    for i in range(3):
        value, is_cached = cache.get(
            f"query:{query_id}",
            callback=lambda: slow_database_query(query_id)
        )
        status = "HIT" if is_cached else "MISS"
        print(f"Request {i}: Cache {status}, timestamp: {value['timestamp']}")
    
    # Инвалидация кэша
    print("\n=== Инвалидация кэша ===")
    deleted = cache.delete(f"query:{query_id}")
    print(f"Удалено {deleted} записей кэша")
    
    # После инвалидации - miss
    value, is_cached = cache.get(
        f"query:{query_id}",
        callback=lambda: slow_database_query(query_id)
    )
    status = "HIT" if is_cached else "MISS"
    print(f"После инвалидации: Cache {status}, timestamp: {value['timestamp']}")

# Запускаем демонстрацию
if __name__ == "__main__":
    try:
        demo_distributed_cache()
    except redis.exceptions.ConnectionError:
        print("Ошибка подключения к Redis. Убедитесь, что сервер запущен.")
```

## Паттерны и стратегии кэширования

### Стратегия вытеснения кэша

```python
import redis
import time
import random
import string

# Подключение к Redis
r = redis.Redis(
    host='localhost',
    port=6379,
    db=0,
    decode_responses=True
)

# Очищаем базу перед демонстрацией
r.flushdb()

# Генерация случайной строки заданной длины
def random_string(length=10):
    letters = string.ascii_letters + string.digits
    return ''.join(random.choice(letters) for _ in range(length))

# 1. Стратегия LRU (Least Recently Used)
print("=== Демонстрация LRU (Least Recently Used) ===")

# Настройка Redis для использования LRU (в реальной системе это делается в redis.conf)
# maxmemory 100mb
# maxmemory-policy allkeys-lru

# Имитация LRU в коде
class LRUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = {}
        self.usage_order = []
    
    def get(self, key):
        if key in self.cache:
            # Обновляем порядок использования (ключ становится самым недавно использованным)
            self.usage_order.remove(key)
            self.usage_order.append(key)
            return self.cache[key]
        return None
    
    def put(self, key, value):
        if key in self.cache:
            # Обновляем значение и порядок использования
            self.cache[key] = value
            self.usage_order.remove(key)
            self.usage_order.append(key)
        else:
            # Проверяем, нужно ли вытеснить элемент
            if len(self.cache) >= self.capacity:
                # Удаляем наименее недавно использованный элемент
                oldest_key = self.usage_order.pop(0)
                del self.cache[oldest_key]
                print(f"LRU: Вытеснен ключ {oldest_key}")
            
            # Добавляем новый элемент
            self.cache[key] = value
            self.usage_order.append(key)

# Демонстрация LRU
lru_cache = LRUCache(capacity=5)
for i in range(7):
    key = f"key{i}"
    lru_cache.put(key, f"value{i}")

# Обращаемся к некоторым ключам (обновляем их "недавность")
lru_cache.get("key1")
lru_cache.get("key3")
lru_cache.put("key7", "value7")  # Вытеснит key0, так как key1 и key3 недавно использовались

print(f"LRU Кэш: {lru_cache.cache}")
print(f"Порядок использования: {lru_cache.usage_order}")

# 2. Стратегия LFU (Least Frequently Used)
print("\n=== Демонстрация LFU (Least Frequently Used) ===")

# Настройка Redis для использования LFU (в реальной системе)
# maxmemory-policy allkeys-lfu

class LFUCache:
    def __init__(self, capacity):
        self.capacity = capacity
        self.cache = {}
        self.frequency = {}  # Частота использования для каждого ключа
        self.min_frequency = 0
    
    def get(self, key):
        if key in self.cache:
            # Увеличиваем частоту использования
            self._increase_frequency(key)
            return self.cache[key]
        return None
    
    def put(self, key, value):
        if key in self.cache:
            # Обновляем значение и частоту
            self.cache[key] = value
            self._increase_frequency(key)
        else:
            # Проверяем, нужно ли вытеснить элемент
            if len(self.cache) >= self.capacity:
                # Находим ключи с минимальной частотой
                min_freq_keys = self.frequency.get(self.min_frequency, set())
                if min_freq_keys:
                    # Вытесняем один из наименее часто используемых ключей
                    victim_key = min_freq_keys.pop()
                    if not min_freq_keys:
                        del self.frequency[self.min_frequency]
                    del self.cache[victim_key]
                    print(f"LFU: Вытеснен ключ {victim_key} с частотой {self.min_frequency}")
            
            # Добавляем новый элемент с частотой 1
            self.cache[key] = value
            self.min_frequency = 1
            if 1 not in self.frequency:
                self.frequency[1] = set()
            self.frequency[1].add(key)
    
    def _increase_frequency(self, key):
        # Получаем текущую частоту
        for freq, keys in self.frequency.items():
            if key in keys:
                current_freq = freq
                break
        
        # Удаляем ключ из текущей частоты
        self.frequency[current_freq].remove(key)
        if not self.frequency[current_freq] and current_freq == self.min_frequency:
            self.min_frequency += 1
        
        # Увеличиваем частоту
        new_freq = current_freq + 1
        if new_freq not in self.frequency:
            self.frequency[new_freq] = set()
        self.frequency[new_freq].add(key)

# Демонстрация LFU
lfu_cache = LFUCache(capacity=5)
for i in range(5):
    key = f"key{i}"
    lfu_cache.put(key, f"value{i}")

# Обращаемся к некоторым ключам чаще
for _ in range(3):
    lfu_cache.get("key1")
for _ in range(2):
    lfu_cache.get("key2")
lfu_cache.get("key3")

# Вытеснение произойдет из ключей с наименьшей частотой
lfu_cache.put("key5", "value5")  # Вытеснит key0 или key4

print(f"LFU Кэш: {lfu_cache.cache}")
print(f"Частоты: {lfu_cache.frequency}")

# 3. Time-based Expiration (Срок действия на основе времени)
print("\n=== Демонстрация Time-based Expiration ===")

# В Redis это встроенная функциональность
r.setex("temp_key1", 5, "краткосрочные данные")  # TTL 5 секунд
r.setex("temp_key2", 30, "среднесрочные данные")  # TTL 30 секунд
r.set("perm_key", "постоянные данные")  # Без TTL

print(f"Ключи Redis: {r.keys()}")
print(f"TTL для temp_key1: {r.ttl('temp_key1')} сек")
print(f"TTL для temp_key2: {r.ttl('temp_key2')} сек")
print(f"TTL для perm_key: {r.ttl('perm_key')}")  # -1 = бессрочно

print("Ждем 6 секунд...")
time.sleep(6)
print(f"Ключи Redis после ожидания: {r.keys()}")  # temp_key1 исчез

# 4. Write-Through и Write-Back
print("\n=== Демонстрация Write-Through и Write-Back ===")

class Database:
    """Имитация базы данных."""
    def __init__(self):
        self.data = {}
        self.write_count = 0
    
    def read(self, key):
        print(f"DB: Чтение {key}")
        return self.data.get(key)
    
    def write(self, key, value):
        print(f"DB: Запись {key}={value}")
        self.data[key] = value
        self.write_count += 1
        return True

class WriteThroughCache:
    """Кэш с политикой Write-Through (запись идет сразу в БД)."""
    def __init__(self, database, ttl=None):
        self.cache = {}
        self.db = database
        self.ttl = ttl
        self.expiry = {}
    
    def get(self, key):
        now = time.time()
        
        # Проверяем истечение срока действия
        if key in self.expiry and now > self.expiry[key]:
            del self.cache[key]
            del self.expiry[key]
        
        # Проверяем кэш
        if key in self.cache:
            print(f"WT: Cache HIT для {key}")
            return self.cache[key]
        
        # Читаем из БД
        value = self.db.read(key)
        if value is not None:
            self.cache[key] = value
            if self.ttl:
                self.expiry[key] = now + self.ttl
        return value
    
    def set(self, key, value):
        # Запись в БД
        self.db.write(key, value)
        
        # Обновление кэша
        self.cache[key] = value
        if self.ttl:
            self.expiry[key] = time.time() + self.ttl
        return True

class WriteBackCache:
    """Кэш с политикой Write-Back (запись откладывается)."""
    def __init__(self, database, ttl=None, flush_threshold=3):
        self.cache = {}
        self.db = database
        self.ttl = ttl
        self.expiry = {}
        self.dirty = set()  # Измененные ключи
        self.flush_threshold = flush_threshold
    
    def get(self, key):
        now = time.time()
        
        # Проверяем истечение срока действия
        if key in self.expiry and now > self.expiry[key]:
            # Если ключ в dirty, нужно записать в БД перед удалением
            if key in self.dirty:
                self.db.write(key, self.cache[key])
                self.dirty.remove(key)
            
            del self.cache[key]
            del self.expiry[key]
        
        # Проверяем кэш
        if key in self.cache:
            print(f"WB: Cache HIT для {key}")
            return self.cache[key]
        
        # Читаем из БД
        value = self.db.read(key)
        if value is not None:
            self.cache[key] = value
            if self.ttl:
                self.expiry[key] = now + self.ttl
        return value
    
    def set(self, key, value):
        # Обновление кэша
        self.cache[key] = value
        if self.ttl:
            self.expiry[key] = time.time() + self.ttl
        
        # Отмечаем как "грязный"
        self.dirty.add(key)
        
        # Проверяем, нужно ли сбрасывать данные в БД
        if len(self.dirty) >= self.flush_threshold:
            self.flush()
        
        return True
    
    def flush(self):
        """Сбрасывает все "грязные" данные в БД."""
        print(f"WB: Сброс {len(self.dirty)} записей в БД")
        for key in list(self.dirty):
            if key in self.cache:  # Проверяем, не истек ли срок действия
                self.db.write(key, self.cache[key])
            self.dirty.remove(key)

# Демонстрация Write-Through
db1 = Database()
wt_cache = WriteThroughCache(db1, ttl=10)

print("Write-Through демонстрация:")
wt_cache.set("user:1", {"name": "Alice", "age": 30})
wt_cache.set("user:2", {"name": "Bob", "age": 25})
print(f"Данные из кэша: {wt_cache.get('user:1')}")
print(f"Количество записей в БД: {db1.write_count}")

# Демонстрация Write-Back
db2 = Database()
wb_cache = WriteBackCache(db2, ttl=10, flush_threshold=3)

print("\nWrite-Back демонстрация:")
wb_cache.set("user:1", {"name": "Alice", "age": 30})
wb_cache.set("user:2", {"name": "Bob", "age": 25})
print(f"Данные из кэша: {wb_cache.get('user:1')}")
print(f"Количество записей в БД до flush: {db2.write_count}")

# Добавляем еще один элемент, чтобы вызвать flush
wb_cache.set("user:3", {"name": "Charlie", "age": 35})
print(f"Количество записей в БД после flush: {db2.write_count}")

# Принудительный сброс
wb_cache.flush()
print(f"Количество записей в БД после принудительного flush: {db2.write_count}")
```

## Заключение

Кэширование — важный инструмент оптимизации производительности приложений. В Python доступно множество механизмов для кэширования: от встроенных декораторов `lru_cache` до распределенных решений на базе Redis. Ключевые принципы эффективного кэширования:

1. **Выбирайте правильный уровень кэширования** в зависимости от природы данных и требований к производительности
2. **Используйте соответствующую стратегию вытеснения** (LRU, LFU, TTL)
3. **Управляйте инвалидацией кэша** для обеспечения согласованности данных
4. **Учитывайте распределенность** в многосерверных средах
5. **Мониторьте эффективность кэша** (соотношение hit/miss, использование памяти)

Правильно реализованный кэш может значительно повысить производительность приложения и снизить нагрузку на системы хранения данных.