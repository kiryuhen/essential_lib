# Алгоритмы и их сложность

## Содержание
- [Big O Notation](#big-o-notation)
- [Алгоритмы сортировки](#алгоритмы-сортировки)
- [Алгоритмы поиска](#алгоритмы-поиска)
- [Динамическое программирование](#динамическое-программирование)
- [Жадные алгоритмы](#жадные-алгоритмы)
- [Рекурсия и её применение](#рекурсия-и-её-применение)

## Big O Notation

### Общий обзор

Big O Notation (O-нотация) — математическая запись, используемая для описания асимптотического поведения функций, особенно для анализа временной и пространственной сложности алгоритмов. Она позволяет оценить, как рост объема входных данных влияет на время выполнения и использование памяти в наихудшем случае.

Основная идея Big O заключается в том, чтобы описать скорость роста сложности алгоритма, игнорируя константы и младшие члены, когда размер входных данных стремится к бесконечности.

### Основные классы сложности

![Big O Complexity Chart](https://i.imgur.com/OSlMr5H.png)

Вот основные классы сложности в порядке возрастания (от быстрых к медленным):

1. **O(1)** — Константное время
   - Сложность не зависит от размера входных данных
   - Примеры: доступ к элементу массива по индексу, push/pop в стеке

2. **O(log n)** — Логарифмическое время
   - Время растет логарифмически с увеличением размера входных данных
   - Примеры: бинарный поиск, сбалансированные деревья поиска

3. **O(n)** — Линейное время
   - Время растет линейно с увеличением размера входных данных
   - Примеры: линейный поиск, обход массива

4. **O(n log n)** — Линеарифметическое время
   - Примеры: эффективные алгоритмы сортировки (быстрая сортировка, сортировка слиянием)

5. **O(n²)** — Квадратичное время
   - Примеры: вложенные циклы, простые алгоритмы сортировки (пузырьковая, вставками)

6. **O(n³)** — Кубическое время
   - Примеры: некоторые алгоритмы умножения матриц

7. **O(2ⁿ)** — Экспоненциальное время
   - Примеры: рекурсивное вычисление чисел Фибоначчи без мемоизации, задача о рюкзаке перебором

8. **O(n!)** — Факториальное время
   - Примеры: задача коммивояжера перебором, генерация всех перестановок

### Правила асимптотической нотации

1. **Правило суммы**: O(f(n) + g(n)) = O(max(f(n), g(n)))
   ```python
   # O(n) + O(n^2) = O(n^2)
   def example_sum(arr):
       sum_arr = 0
       for i in arr:  # O(n)
           sum_arr += i
       
       for i in arr:  # O(n^2)
           for j in arr:
               print(i, j)
       
       return sum_arr
   ```

2. **Правило произведения**: O(f(n) * g(n)) = O(f(n) * g(n))
   ```python
   # O(n) * O(n) = O(n^2)
   def example_product(arr):
       for i in arr:  # O(n)
           for j in arr:  # O(n)
               print(i, j)
   ```

3. **Константы отбрасываются**: O(c * f(n)) = O(f(n))
   ```python
   # O(3n) = O(n)
   def example_constants(arr):
       # Это выполняется 3 раза, но всё равно O(n)
       for i in arr:  
           print(i)
       for i in arr:
           print(i)
       for i in arr:
           print(i)
   ```

4. **Младшие члены отбрасываются**: O(f(n) + g(n)) = O(f(n)), если f(n) растет быстрее g(n)
   ```python
   # O(n^2 + n) = O(n^2)
   def example_lower_terms(arr):
       for i in arr:  # O(n^2)
           for j in arr:
               print(i, j)
       
       for i in arr:  # O(n)
           print(i)
   ```

### Другие асимптотические нотации

- **Ω (Omega)** — нижняя граница (лучший случай)
- **Θ (Theta)** — точная граница (когда верхняя и нижняя границы совпадают)
- **o (little-o)** — верхняя граница, которая не является точной

### Анализ алгоритмов на Python

Язык Python имеет ряд особенностей, влияющих на производительность:

1. **Сложность операций со встроенными типами**:

| Операция | Список (List) | Множество (Set) | Словарь (Dict) | Кортеж (Tuple) |
|----------|---------------|----------------|----------------|----------------|
| Доступ по индексу | O(1) | N/A | O(1) | O(1) |
| Поиск элемента | O(n) | O(1) в среднем | O(1) в среднем | O(n) |
| Вставка/удаление в конце | O(1)* | N/A | N/A | N/A |
| Вставка/удаление в середине | O(n) | N/A | N/A | N/A |
| Добавление элемента | O(1)* | O(1) в среднем | O(1) в среднем | N/A |

2. **Измерение времени выполнения**:

```python
import time

def measure_time(func, *args, **kwargs):
    start_time = time.time()
    result = func(*args, **kwargs)
    end_time = time.time()
    print(f"Время выполнения: {end_time - start_time:.6f} секунд")
    return result

# Пример использования
def linear_search(arr, target):
    for i, val in enumerate(arr):
        if val == target:
            return i
    return -1

# Измерение для разных размеров входных данных
for size in [1000, 10000, 100000]:
    arr = list(range(size))
    measure_time(linear_search, arr, size - 1)
```

3. **Профилирование кода**:

```python
import cProfile

def profile_function(func, *args, **kwargs):
    return cProfile.runctx('func(*args, **kwargs)', globals(), locals())

# Пример использования
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        for j in range(0, n - i - 1):
            if arr[j] > arr[j + 1]:
                arr[j], arr[j + 1] = arr[j + 1], arr[j]
    return arr

profile_function(bubble_sort, [5, 3, 8, 4, 2])
```

### Практические рекомендации

1. **Выбор структуры данных**:
   - Для быстрого поиска используйте множества и словари, а не списки
   - Для частых вставок/удалений в середине используйте `collections.deque`

2. **Оптимизация циклов**:
   - Избегайте вложенных циклов, когда это возможно
   - Используйте генераторы выражений вместо списков, если не нужен весь список сразу

3. **Преждевременная оптимизация**:
   - "Преждевременная оптимизация — корень всех зол" (Дональд Кнут)
   - Сначала сделайте код корректным, затем измерьте производительность, потом оптимизируйте

4. **Использование встроенных функций**:
   - Встроенные функции и методы Python обычно оптимизированы и написаны на C
   - Например, используйте `min()`, `max()`, `sum()` вместо собственных реализаций

### Дополнительные ресурсы
- [Python Time Complexity](https://wiki.python.org/moin/TimeComplexity)
- [Big-O Cheat Sheet](https://www.bigocheatsheet.com/)
- [MIT OpenCourseWare: Introduction to Algorithms](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/)
- [Визуализация алгоритмов и их сложности](https://www.toptal.com/developers/sorting-algorithms)

## Алгоритмы сортировки

### Общий обзор

Алгоритмы сортировки — фундаментальные алгоритмы для упорядочивания элементов в последовательности по определенному критерию. Они используются повсеместно: от простых пользовательских задач до сложной обработки данных и являются основой многих более сложных алгоритмов.

Выбор подходящего алгоритма сортировки зависит от:
- Размера набора данных
- Степени упорядоченности исходных данных
- Ограничений по памяти
- Стабильности сортировки (сохранение порядка равных элементов)
- Требований к производительности

### Пузырьковая сортировка (Bubble Sort)

Один из самых простых алгоритмов сортировки, который многократно проходит через список, сравнивая соседние элементы и меняя их местами, если они расположены в неправильном порядке.

#### Принцип работы:
1. Сравниваем каждую пару соседних элементов
2. Если они в неправильном порядке, меняем их местами
3. Повторяем, пока список не будет полностью отсортирован

#### Реализация:

```python
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):
        # Флаг для оптимизации: если за проход не было обменов, значит массив уже отсортирован
        swapped = False
        
        # Последние i элементов уже на своих местах
        for j in range(0, n - i - 1):
            if arr[j] > arr[j + 1]:
                arr[j], arr[j + 1] = arr[j + 1], arr[j]
                swapped = True
        
        # Если за проход не было обменов, выходим
        if not swapped:
            break
    
    return arr

# Пример использования
arr = [64, 34, 25, 12, 22, 11, 90]
bubble_sort(arr)
print(arr)  # [11, 12, 22, 25, 34, 64, 90]
```

#### Сложность:
- Временная сложность: O(n²) в среднем и худшем случае, O(n) в лучшем случае (для уже отсортированного массива с оптимизацией)
- Пространственная сложность: O(1)
- Стабильность: Стабильный

#### Применение:
- Образовательные цели (понимание сортировки)
- Очень маленькие наборы данных
- Когда данные почти отсортированы

### Сортировка вставками (Insertion Sort)

Этот алгоритм строит отсортированный массив по одному элементу за раз, вставляя каждый новый элемент в правильную позицию.

#### Принцип работы:
1. Начинаем с первого элемента (считаем его уже отсортированным)
2. Берем следующий элемент и вставляем его в правильную позицию среди уже отсортированных
3. Повторяем шаг 2 для всех остальных элементов

#### Реализация:

```python
def insertion_sort(arr):
    for i in range(1, len(arr)):
        key = arr[i]
        j = i - 1
        
        # Перемещаем элементы больше key на одну позицию вперед
        while j >= 0 and arr[j] > key:
            arr[j + 1] = arr[j]
            j -= 1
        
        arr[j + 1] = key
    
    return arr

# Пример использования
arr = [12, 11, 13, 5, 6]
insertion_sort(arr)
print(arr)  # [5, 6, 11, 12, 13]
```

#### Сложность:
- Временная сложность: O(n²) в среднем и худшем случае, O(n) в лучшем случае (для почти отсортированного массива)
- Пространственная сложность: O(1)
- Стабильность: Стабильный

#### Применение:
- Небольшие наборы данных
- Онлайн-алгоритм (обрабатывает данные по мере поступления)
- Когда данные почти отсортированы
- Как часть более сложных алгоритмов (например, быстрой сортировки)

### Сортировка выбором (Selection Sort)

Алгоритм многократно находит минимальный элемент из неотсортированной части и помещает его в начало.

#### Принцип работы:
1. Находим минимальный элемент в неотсортированной части массива
2. Меняем его местами с первым элементом неотсортированной части
3. Перемещаем границу отсортированной/неотсортированной части на один элемент вправо
4. Повторяем, пока весь массив не будет отсортирован

#### Реализация:

```python
def selection_sort(arr):
    n = len(arr)
    for i in range(n):
        # Находим минимальный элемент в оставшейся части
        min_idx = i
        for j in range(i + 1, n):
            if arr[j] < arr[min_idx]:
                min_idx = j
        
        # Меняем местами найденный минимальный элемент с первым элементом
        arr[i], arr[min_idx] = arr[min_idx], arr[i]
    
    return arr

# Пример использования
arr = [64, 25, 12, 22, 11]
selection_sort(arr)
print(arr)  # [11, 12, 22, 25, 64]
```

#### Сложность:
- Временная сложность: O(n²) во всех случаях
- Пространственная сложность: O(1)
- Стабильность: Нестабильный

#### Применение:
- Когда количество обменов нужно минимизировать (выполняет только O(n) обменов)
- Простые встроенные системы с ограниченной памятью

### Быстрая сортировка (Quick Sort)

Один из наиболее эффективных алгоритмов сортировки, основанный на стратегии "разделяй и властвуй".

#### Принцип работы:
1. Выбираем опорный элемент (pivot)
2. Разделяем массив на два подмассива: элементы меньше опорного и элементы больше опорного
3. Рекурсивно сортируем оба подмассива
4. Объединяем результаты (это происходит автоматически из-за особенностей разделения)

#### Реализация:

```python
def quick_sort(arr):
    if len(arr) <= 1:
        return arr
    
    pivot = arr[len(arr) // 2]  # Выбираем опорный элемент (средний)
    
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    
    return quick_sort(left) + middle + quick_sort(right)

# Пример использования
arr = [10, 7, 8, 9, 1, 5]
sorted_arr = quick_sort(arr)
print(sorted_arr)  # [1, 5, 7, 8, 9, 10]
```

Более оптимизированная версия без создания новых подмассивов:

```python
def quick_sort_in_place(arr, low, high):
    if low < high:
        pivot_index = partition(arr, low, high)
        quick_sort_in_place(arr, low, pivot_index - 1)
        quick_sort_in_place(arr, pivot_index + 1, high)
    return arr

def partition(arr, low, high):
    pivot = arr[high]  # Выбираем последний элемент как опорный
    i = low - 1  # Индекс меньшего элемента
    
    for j in range(low, high):
        # Если текущий элемент меньше или равен опорному
        if arr[j] <= pivot:
            i += 1
            arr[i], arr[j] = arr[j], arr[i]
    
    arr[i + 1], arr[high] = arr[high], arr[i + 1]
    return i + 1

# Пример использования
arr = [10, 7, 8, 9, 1, 5]
quick_sort_in_place(arr, 0, len(arr) - 1)
print(arr)  # [1, 5, 7, 8, 9, 10]
```

#### Сложность:
- Временная сложность: O(n log n) в среднем случае, O(n²) в худшем случае (при плохом выборе опорного элемента)
- Пространственная сложность: O(log n) для стека рекурсивных вызовов
- Стабильность: Нестабильный

#### Применение:
- Общая сортировка больших наборов данных
- Встроенная функция `sorted()` и метод `.sort()` в Python используют Timsort (гибрид сортировки вставками и сортировки слиянием)
- Когда средняя производительность важнее гарантий худшего случая

### Сортировка слиянием (Merge Sort)

Алгоритм "разделяй и властвуй", который разбивает массив на две половины, сортирует их отдельно, а затем объединяет.

#### Принцип работы:
1. Разделяем массив пополам
2. Рекурсивно сортируем обе половины
3. Объединяем (сливаем) отсортированные половины

#### Реализация:

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    
    # Разделяем массив пополам
    mid = len(arr) // 2
    left = arr[:mid]
    right = arr[mid:]
    
    # Рекурсивно сортируем обе половины
    left = merge_sort(left)
    right = merge_sort(right)
    
    # Объединяем отсортированные половины
    return merge(left, right)

def merge(left, right):
    result = []
    i = j = 0
    
    # Сравниваем элементы из обоих массивов и добавляем меньший
    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    
    # Добавляем оставшиеся элементы
    result.extend(left[i:])
    result.extend(right[j:])
    
    return result

# Пример использования
arr = [38, 27, 43, 3, 9, 82, 10]
sorted_arr = merge_sort(arr)
print(sorted_arr)  # [3, 9, 10, 27, 38, 43, 82]
```

#### Сложность:
- Временная сложность: O(n log n) во всех случаях
- Пространственная сложность: O(n)
- Стабильность: Стабильный

#### Применение:
- Когда требуются гарантии производительности (всегда O(n log n))
- Когда стабильность сортировки имеет значение
- Внешняя сортировка больших объемов данных, не помещающихся в памяти
- Параллельные и распределенные вычисления (легко распараллеливается)

### Сортировка кучей (Heap Sort)

Использует структуру данных "куча" (бинарная куча) для сортировки элементов.

#### Принцип работы:
1. Строим максимальную кучу из массива
2. Корень кучи (максимальный элемент) перемещаем в конец массива
3. Уменьшаем размер кучи и восстанавливаем её свойства
4. Повторяем шаги 2-3, пока куча не опустеет

#### Реализация:

```python
def heapify(arr, n, i):
    largest = i  # Инициализируем наибольший элемент как корень
    left = 2 * i + 1
    right = 2 * i + 2
    
    # Проверяем, существует ли левый потомок и больше ли он корня
    if left < n and arr[left] > arr[largest]:
        largest = left
    
    # Проверяем, существует ли правый потомок и больше ли он текущего наибольшего
    if right < n and arr[right] > arr[largest]:
        largest = right
    
    # Если наибольший элемент не корень
    if largest != i:
        arr[i], arr[largest] = arr[largest], arr[i]
        
        # Рекурсивно восстанавливаем свойства кучи для поддерева
        heapify(arr, n, largest)

def heap_sort(arr):
    n = len(arr)
    
    # Построение максимальной кучи
    for i in range(n // 2 - 1, -1, -1):
        heapify(arr, n, i)
    
    # Извлекаем элементы из кучи по одному
    for i in range(n - 1, 0, -1):
        arr[0], arr[i] = arr[i], arr[0]  # Перемещаем корень в конец
        heapify(arr, i, 0)  # Восстанавливаем свойства кучи для уменьшенной кучи
    
    return arr

# Пример использования
arr = [12, 11, 13, 5, 6, 7]
heap_sort(arr)
print(arr)  # [5, 6, 7, 11, 12, 13]
```

#### Сложность:
- Временная сложность: O(n log n) во всех случаях
- Пространственная сложность: O(1)
- Стабильность: Нестабильный

#### Применение:
- Когда требуется гарантированная производительность O(n log n)
- Когда пространственная сложность критична (in-place сортировка)
- Приоритетные очереди

### Сравнение алгоритмов сортировки

| Алгоритм | Лучший случай | Средний случай | Худший случай | Память | Стабильность |
|----------|---------------|----------------|---------------|--------|--------------|
| Пузырьковая | O(n) | O(n²) | O(n²) | O(1) | Да |
| Вставками | O(n) | O(n²) | O(n²) | O(1) | Да |
| Выбором | O(n²) | O(n²) | O(n²) | O(1) | Нет |
| Быстрая | O(n log n) | O(n log n) | O(n²) | O(log n) | Нет |
| Слиянием | O(n log n) | O(n log n) | O(n log n) | O(n) | Да |
| Кучей | O(n log n) | O(n log n) | O(n log n) | O(1) | Нет |
| Timsort (Python) | O(n) | O(n log n) | O(n log n) | O(n) | Да |

### Встроенные средства сортировки в Python

1. **Функция `sorted()`**:
   ```python
   arr = [3, 1, 4, 1, 5, 9, 2]
   sorted_arr = sorted(arr)  # Возвращает новый отсортированный список
   print(sorted_arr)  # [1, 1, 2, 3, 4, 5, 9]
   
   # Сортировка по ключу
   words = ["banana", "apple", "cherry"]
   sorted_words = sorted(words, key=len)  # Сортировка по длине
   print(sorted_words)  # ['apple', 'banana', 'cherry']
   
   # Сортировка в обратном порядке
   reverse_sorted = sorted(arr, reverse=True)
   print(reverse_sorted)  # [9, 5, 4, 3, 2, 1, 1]
   ```

2. **Метод `.sort()`**:
   ```python
   arr = [3, 1, 4, 1, 5, 9, 2]
   arr.sort()  # Сортирует исходный список на месте
   print(arr)  # [1, 1, 2, 3, 4, 5, 9]
   
   # Сортировка по ключу
   people = [{"name": "Alice", "age": 25}, {"name": "Bob", "age": 20}]
   people.sort(key=lambda x: x["age"])
   print(people)  # [{'name': 'Bob', 'age': 20}, {'name': 'Alice', 'age': 25}]
   ```

### Дополнительные ресурсы
- [Визуализация алгоритмов сортировки](https://visualgo.net/en/sorting)
- [Сортировки в Python](https://docs.python.org/3/howto/sorting.html)
- [The Sound of Sorting (визуализация и озвучивание)](https://www.youtube.com/watch?v=kPRA0W1kECg)
- [Timsort - алгоритм сортировки, используемый в Python](https://en.wikipedia.org/wiki/Timsort)

## Алгоритмы поиска

### Общий обзор

Алгоритмы поиска используются для нахождения элемента или группы элементов с определенными свойствами среди множества других элементов. Они являются фундаментальными алгоритмами в информатике и используются во многих приложениях, от поиска элемента в массиве до поиска информации в базе данных или Интернете.

### Линейный поиск (Linear Search)

Самый простой алгоритм поиска, который последовательно проверяет каждый элемент коллекции.

#### Принцип работы:
1. Проходим по каждому элементу последовательности один за другим
2. Сравниваем текущий элемент с искомым значением
3. Если найдено совпадение, возвращаем индекс или элемент
4. Если достигнут конец последовательности без совпадений, возвращаем указание на отсутствие элемента

#### Реализация:

```python
def linear_search(arr, target):
    for i, value in enumerate(arr):
        if value == target:
            return i  # Возвращаем индекс найденного элемента
    return -1  # Элемент не найден

# Пример использования
arr = [5, 8, 2, 10, 3, 1, 7]
target = 3
result = linear_search(arr, target)
print(f"Элемент {target} найден на позиции {result}" if result != -1 else f"Элемент {target} не найден")
# Элемент 3 найден на позиции 4
```

#### Сложность:
- Временная сложность: O(n) - худший и средний случай
- Пространственная сложность: O(1)

#### Применение:
- Маленькие массивы или списки
- Когда нет возможности использовать индексацию или структуру данных
- Несортированные данные
- Поиск по условию, не только по равенству

### Бинарный поиск (Binary Search)

Эффективный алгоритм поиска, работающий с отсортированными данными, используя стратегию "разделяй и властвуй".

#### Принцип работы:
1. Сравниваем целевое значение со средним элементом последовательности
2. Если равны, поиск завершен
3. Если целевое значение меньше, повторяем поиск в левой половине
4. Если целевое значение больше, повторяем поиск в правой половине
5. Продолжаем, пока не найдем элемент или пока диапазон поиска не станет пустым

#### Рекурсивная реализация:

```python
def binary_search_recursive(arr, target, low, high):
    if high < low:
        return -1  # Элемент не найден
    
    mid = (low + high) // 2
    
    if arr[mid] == target:
        return mid  # Элемент найден
    elif arr[mid] > target:
        return binary_search_recursive(arr, target, low, mid - 1)  # Поиск в левой половине
    else:
        return binary_search_recursive(arr, target, mid + 1, high)  # Поиск в правой половине

# Пример использования
arr = [1, 2, 3, 5, 7, 8, 10]  # Отсортированный массив!
target = 7
result = binary_search_recursive(arr, target, 0, len(arr) - 1)
print(f"Элемент {target} найден на позиции {result}" if result != -1 else f"Элемент {target} не найден")
# Элемент 7 найден на позиции 4
```

#### Итеративная реализация:

```python
def binary_search_iterative(arr, target):
    low, high = 0, len(arr) - 1
    
    while low <= high:
        mid = (low + high) // 2
        
        if arr[mid] == target:
            return mid  # Элемент найден
        elif arr[mid] > target:
            high = mid - 1  # Поиск в левой половине
        else:
            low = mid + 1  # Поиск в правой половине
    
    return -1  # Элемент не найден

# Пример использования
arr = [1, 2, 3, 5, 7, 8, 10]  # Отсортированный массив!
target = 7
result = binary_search_iterative(arr, target)
print(f"Элемент {target} найден на позиции {result}" if result != -1 else f"Элемент {target} не найден")
# Элемент 7 найден на позиции 4
```

#### Использование встроенной функции:

```python
import bisect

def binary_search_builtin(arr, target):
    index = bisect.bisect_left(arr, target)
    if index < len(arr) and arr[index] == target:
        return index
    return -1

# Пример использования
arr = [1, 2, 3, 5, 7, 8, 10]
target = 7
result = binary_search_builtin(arr, target)
print(f"Элемент {target} найден на позиции {result}" if result != -1 else f"Элемент {target} не найден")
# Элемент 7 найден на позиции 4
```

#### Сложность:
- Временная сложность: O(log n) - худший и средний случай
- Пространственная сложность: O(log n) для рекурсивной версии (из-за стека вызовов), O(1) для итеративной

#### Применение:
- Отсортированные массивы или списки
- Поиск в больших наборах данных
- Поиск в словарях и индексах баз данных
- Нахождение элемента, ближайшего к заданному

### Интерполяционный поиск (Interpolation Search)

Улучшенная версия бинарного поиска, которая использует интерполяцию для более эффективного поиска в равномерно распределенных данных.

#### Принцип работы:
Вместо деления диапазона пополам, интерполяционный поиск оценивает вероятное положение искомого элемента на основе его значения и значений крайних элементов диапазона.

#### Реализация:

```python
def interpolation_search(arr, target):
    low, high = 0, len(arr) - 1
    
    while low <= high and arr[low] <= target <= arr[high]:
        # Формула интерполяции для оценки позиции
        pos = low + ((target - arr[low]) * (high - low)) // (arr[high] - arr[low])
        
        if arr[pos] == target:
            return pos  # Элемент найден
        elif arr[pos] < target:
            low = pos + 1  # Поиск в правой части
        else:
            high = pos - 1  # Поиск в левой части
    
    return -1  # Элемент не найден

# Пример использования
arr = [1, 2, 3, 5, 7, 8, 10, 12, 15, 18, 20]  # Отсортированный массив!
target = 15
result = interpolation_search(arr, target)
print(f"Элемент {target} найден на позиции {result}" if result != -1 else f"Элемент {target} не найден")
# Элемент 15 найден на позиции 8
```

#### Сложность:
- Временная сложность: O(log log n) в среднем для равномерно распределенных данных, O(n) в худшем случае
- Пространственная сложность: O(1)

#### Применение:
- Равномерно распределенные отсортированные данные
- Когда требуется улучшить производительность бинарного поиска

### Поиск по хешу (Hash-based Search)

Используется для очень быстрого поиска элементов с использованием хеш-таблиц.

#### Принцип работы:
1. Вычисляем хеш-значение искомого ключа
2. Используем хеш для определения местоположения элемента в хеш-таблице
3. Проверяем наличие элемента в этой позиции

#### Реализация с использованием словарей Python:

```python
def hash_search(hash_table, key):
    return key in hash_table

# Пример использования
hash_table = {
    "apple": 5,
    "banana": 7,
    "orange": 10,
    "grape": 3
}

key = "orange"
result = hash_search(hash_table, key)
print(f"Ключ '{key}' найден" if result else f"Ключ '{key}' не найден")
# Ключ 'orange' найден

# Быстрое извлечение значения
value = hash_table.get(key, "Не найдено")
print(f"Значение для ключа '{key}': {value}")
# Значение для ключа 'orange': 10
```

#### Сложность:
- Временная сложность: O(1) в среднем случае, O(n) в худшем случае (при большом количестве коллизий)
- Пространственная сложность: O(n)

#### Применение:
- Словари и множества
- Базы данных (индексы)
- Кэширование
- Проверка дубликатов

### Дерево поиска (Tree-based Search)

Алгоритмы поиска, использующие древовидные структуры данных, такие как двоичные деревья поиска, B-деревья и т.д.

#### Пример поиска в двоичном дереве поиска:

```python
class TreeNode:
    def __init__(self, key):
        self.key = key
        self.left = None
        self.right = None

def search_in_bst(root, key):
    # Базовый случай: корень пуст или ключ находится в корне
    if root is None or root.key == key:
        return root
    
    # Ключ больше, чем ключ корня
    if root.key < key:
        return search_in_bst(root.right, key)
    
    # Ключ меньше, чем ключ корня
    return search_in_bst(root.left, key)

# Пример использования
#       8
#      / \
#     3   10
#    / \    \
#   1   6    14
#      / \   /
#     4   7 13
root = TreeNode(8)
root.left = TreeNode(3)
root.right = TreeNode(10)
root.left.left = TreeNode(1)
root.left.right = TreeNode(6)
root.left.right.left = TreeNode(4)
root.left.right.right = TreeNode(7)
root.right.right = TreeNode(14)
root.right.right.left = TreeNode(13)

key = 6
result = search_in_bst(root, key)
print(f"Ключ {key} найден" if result else f"Ключ {key} не найден")
# Ключ 6 найден
```

#### Сложность:
- Временная сложность: O(log n) в среднем для сбалансированных деревьев, O(n) в худшем случае
- Пространственная сложность: O(log n) для рекурсивной версии

#### Применение:
- Словари и множества (реализация)
- Базы данных (индексы)
- Система файлов
- Карты и графы

### Сравнение алгоритмов поиска

| Алгоритм | Требования | Лучший случай | Средний случай | Худший случай | Пространственная сложность |
|----------|------------|---------------|----------------|---------------|----------------------------|
| Линейный | Нет | O(1) | O(n) | O(n) | O(1) |
| Бинарный | Отсортированный массив | O(1) | O(log n) | O(log n) | O(1) (итер.) / O(log n) (рек.) |
| Интерполяционный | Отсортированный массив | O(1) | O(log log n) | O(n) | O(1) |
| Хеш-поиск | Хеш-таблица | O(1) | O(1) | O(n) | O(n) |
| Поиск в BST | Дерево поиска | O(1) | O(log n) | O(n) | O(log n) |

### Практические рекомендации

1. **Выбор алгоритма поиска**:
   - Используйте линейный поиск для небольших наборов данных или несортированных данных
   - Используйте бинарный поиск для отсортированных данных
   - Используйте хеш-таблицы для очень быстрого доступа к данным по ключу
   - Используйте деревья для сложных структур данных и операций

2. **Оптимизация поиска**:
   - Предварительная сортировка может значительно ускорить поиск
   - Кэширование результатов поиска для часто запрашиваемых данных
   - Использование индексов в базах данных

3. **Встроенные функции Python для поиска**:
   ```python
   # Поиск в списке
   arr = [1, 2, 3, 4, 5]
   
   # Проверка наличия элемента
   if 3 in arr:
       print("Элемент найден")
   
   # Нахождение индекса
   try:
       index = arr.index(3)
       print(f"Элемент найден на позиции {index}")
   except ValueError:
       print("Элемент не найден")
   
   # Поиск в словаре
   d = {"a": 1, "b": 2}
   
   # Проверка наличия ключа
   if "a" in d:
       print("Ключ найден")
   
   # Безопасное получение значения
   value = d.get("c", "Не найдено")
   print(value)  # "Не найдено"
   ```

### Дополнительные ресурсы
- [Визуализация алгоритмов поиска](https://www.cs.usfca.edu/~galles/visualization/Search.html)
- [Бинарный поиск в Python](https://docs.python.org/3/library/bisect.html)
- [Алгоритмы поиска на GeeksforGeeks](https://www.geeksforgeeks.org/searching-algorithms/)
- [Задачи на бинарный поиск на LeetCode](https://leetcode.com/tag/binary-search/)

## Динамическое программирование

### Общий обзор

Динамическое программирование (DP) — это метод оптимизации, который решает сложные задачи, разбивая их на более простые подзадачи и сохраняя результаты этих подзадач для избежания повторных вычислений. Ключевые характеристики задач, где применимо DP:

1. **Оптимальная подструктура**: оптимальное решение задачи содержит оптимальные решения подзадач
2. **Перекрывающиеся подзадачи**: подзадачи решаются многократно при рекурсивном подходе

Динамическое программирование особенно эффективно, когда прямой рекурсивный подход приводит к экспоненциальной сложности из-за повторного решения одних и тех же подзадач.

### Подходы к динамическому программированию

#### 1. Мемоизация (Top-Down):
- Начинаем с основной задачи и решаем её рекурсивно
- Сохраняем результаты вычислений для подзадач в кэше (обычно словаре)
- Перед решением подзадачи проверяем кэш

#### 2. Табуляция (Bottom-Up):
- Начинаем с базовых случаев
- Итеративно строим таблицу результатов для всех возможных подзадач
- Используем эти результаты для решения более крупных подзадач

### Классические задачи динамического программирования

#### 1. Числа Фибоначчи

**Задача**: Найти n-ое число Фибоначчи (F(0)=0, F(1)=1, F(n)=F(n-1)+F(n-2) для n > 1)

**Наивный рекурсивный подход** (экспоненциальная сложность):

```python
def fibonacci_recursive(n):
    if n <= 1:
        return n
    return fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2)

# Этот код очень неэффективен для больших n
# print(fibonacci_recursive(35))  # Займет много времени
```

**Мемоизация (Top-Down)**:

```python
def fibonacci_memo(n, memo={}):
    if n in memo:
        return memo[n]
    
    if n <= 1:
        result = n
    else:
        result = fibonacci_memo(n - 1, memo) + fibonacci_memo(n - 2, memo)
    
    memo[n] = result
    return result

print(fibonacci_memo(100))  # Быстрое вычисление благодаря мемоизации
```

**Табуляция (Bottom-Up)**:

```python
def fibonacci_tabulation(n):
    if n <= 1:
        return n
    
    dp = [0] * (n + 1)
    dp[1] = 1
    
    for i in range(2, n + 1):
        dp[i] = dp[i - 1] + dp[i - 2]
    
    return dp[n]

print(fibonacci_tabulation(100))  # Быстрое вычисление
```

**Оптимизация пространства**:

```python
def fibonacci_optimized(n):
    if n <= 1:
        return n
    
    a, b = 0, 1
    for _ in range(2, n + 1):
        a, b = b, a + b
    
    return b

print(fibonacci_optimized(100))  # Максимально эффективное решение
```

#### 2. Задача о рюкзаке (Knapsack Problem)

**Задача**: Дан набор предметов, каждый с весом и стоимостью, и рюкзак с максимальной вместимостью. Найти набор предметов максимальной суммарной стоимости, которые можно положить в рюкзак.

**Мемоизация (Top-Down)**:

```python
def knapsack_memo(weights, values, capacity, n, memo={}):
    # Создаем ключ для мемоизации
    key = (n, capacity)
    
    # Проверяем, решали ли мы уже эту подзадачу
    if key in memo:
        return memo[key]
    
    # Базовый случай: нет предметов или нет места
    if n == 0 or capacity == 0:
        return 0
    
    # Если текущий предмет весит больше, чем вместимость рюкзака, 
    # его нельзя положить
    if weights[n - 1] > capacity:
        memo[key] = knapsack_memo(weights, values, capacity, n - 1, memo)
        return memo[key]
    
    # Максимум из двух случаев:
    # 1) n-й предмет не входит в решение
    # 2) n-й предмет входит в решение
    memo[key] = max(
        values[n - 1] + knapsack_memo(weights, values, capacity - weights[n - 1], n - 1, memo),
        knapsack_memo(weights, values, capacity, n - 1, memo)
    )
    
    return memo[key]

# Пример использования
weights = [1, 3, 4, 5]
values = [1, 4, 5, 7]
capacity = 7
n = len(weights)

print(knapsack_memo(weights, values, capacity, n))  # 9 (предметы с весами 3 и 4)
```

**Табуляция (Bottom-Up)**:

```python
def knapsack_tabulation(weights, values, capacity):
    n = len(weights)
    dp = [[0 for _ in range(capacity + 1)] for _ in range(n + 1)]
    
    for i in range(1, n + 1):
        for w in range(1, capacity + 1):
            if weights[i - 1] <= w:
                dp[i][w] = max(
                    values[i - 1] + dp[i - 1][w - weights[i - 1]],
                    dp[i - 1][w]
                )
            else:
                dp[i][w] = dp[i - 1][w]
    
    return dp[n][capacity]

# Пример использования
weights = [1, 3, 4, 5]
values = [1, 4, 5, 7]
capacity = 7

print(knapsack_tabulation(weights, values, capacity))  # 9
```

#### 3. Наибольшая общая подпоследовательность (LCS)

**Задача**: Найти длину наибольшей подпоследовательности, общей для двух строк.

```python
def longest_common_subsequence(text1, text2):
    m, n = len(text1), len(text2)
    
    # Создаем таблицу для динамического программирования
    dp = [[0 for _ in range(n + 1)] for _ in range(m + 1)]
    
    # Заполняем таблицу
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if text1[i - 1] == text2[j - 1]:
                dp[i][j] = dp[i - 1][j - 1] + 1
            else:
                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])
    
    return dp[m][n]

# Пример использования
text1 = "abcde"
text2 = "ace"
print(longest_common_subsequence(text1, text2))  # 3 ("ace")
```

#### 4. Задача о редакционном расстоянии (Edit Distance)

**Задача**: Найти минимальное количество операций (вставка, удаление, замена), необходимых для преобразования одной строки в другую.

```python
def edit_distance(word1, word2):
    m, n = len(word1), len(word2)
    
    # Создаем таблицу для динамического программирования
    dp = [[0 for _ in range(n + 1)] for _ in range(m + 1)]
    
    # Инициализация первой строки и первого столбца
    for i in range(m + 1):
        dp[i][0] = i
    for j in range(n + 1):
        dp[0][j] = j
    
    # Заполняем таблицу
    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if word1[i - 1] == word2[j - 1]:
                dp[i][j] = dp[i - 1][j - 1]
            else:
                dp[i][j] = 1 + min(
                    dp[i - 1][j],      # Удаление
                    dp[i][j - 1],      # Вставка
                    dp[i - 1][j - 1]   # Замена
                )
    
    return dp[m][n]

# Пример использования
word1 = "horse"
word2 = "ros"
print(edit_distance(word1, word2))  # 3 (удалить 'h', заменить 'r' на 'o', удалить 'e')
```

### Реконструкция решения

Часто требуется не просто значение оптимального решения, но и само решение (например, какие предметы выбрать в задаче о рюкзаке). В таких случаях DP-таблица должна сохранять не только значения, но и информацию о принятых решениях.

**Пример**: Восстановление пути в задаче о рюкзаке:

```python
def knapsack_with_items(weights, values, capacity):
    n = len(weights)
    dp = [[0 for _ in range(capacity + 1)] for _ in range(n + 1)]
    
    # Заполняем DP-таблицу
    for i in range(1, n + 1):
        for w in range(1, capacity + 1):
            if weights[i - 1] <= w:
                dp[i][w] = max(
                    values[i - 1] + dp[i - 1][w - weights[i - 1]],
                    dp[i - 1][w]
                )
            else:
                dp[i][w] = dp[i - 1][w]
    
    # Восстанавливаем выбранные предметы
    selected_items = []
    w = capacity
    for i in range(n, 0, -1):
        if dp[i][w] != dp[i - 1][w]:
            selected_items.append(i - 1)
            w -= weights[i - 1]
    
    return dp[n][capacity], selected_items[::-1]  # Максимальная стоимость и список выбранных предметов

# Пример использования
weights = [1, 3, 4, 5]
values = [1, 4, 5, 7]
capacity = 7

max_value, selected_items = knapsack_with_items(weights, values, capacity)
print(f"Максимальная стоимость: {max_value}")  # 9
print(f"Выбранные предметы (индексы): {selected_items}")  # [1, 2] (предметы с индексами 1 и 2)
print(f"Веса выбранных предметов: {[weights[i] for i in selected_items]}")  # [3, 4]
print(f"Стоимости выбранных предметов: {[values[i] for i in selected_items]}")  # [4, 5]
```

### Практические рекомендации

1. **Когда использовать DP**:
   - Когда задача требует оптимизации (максимизации или минимизации)
   - Когда прямая рекурсия приводит к экспоненциальной сложности
   - Когда задача обладает оптимальной подструктурой и перекрывающимися подзадачами

2. **Процесс решения**:
   - Определите подзадачи и структуру рекурсии
   - Напишите рекурсивное решение
   - Добавьте мемоизацию или переделайте в табуляцию
   - При необходимости оптимизируйте пространство

3. **Выбор подхода**:
   - Мемоизация (Top-Down): проще реализовать, если уже есть рекурсивное решение; не вычисляет ненужные подзадачи
   - Табуляция (Bottom-Up): более эффективно по памяти; проще оптимизировать

4. **Оптимизация памяти**:
   - Если решение зависит только от предыдущего шага, можно хранить только текущий и предыдущий шаги

### Дополнительные ресурсы
- [Dynamic Programming — From Novice to Advanced](https://www.topcoder.com/community/competitive-programming/tutorials/dynamic-programming-from-novice-to-advanced/)
- [Визуализация динамического программирования](https://people.cs.clemson.edu/~bcdean/dp_practice/)
- [Курс динамического программирования на Coursera](https://www.coursera.org/learn/algorithmic-toolbox)
- [Задачи на динамическое программирование на LeetCode](https://leetcode.com/tag/dynamic-programming/)

## Жадные алгоритмы

### Общий обзор

Жадные алгоритмы (Greedy Algorithms) — это алгоритмы, которые принимают оптимальное локальное решение на каждом шаге с надеждой, что это приведет к глобальному оптимальному решению. В отличие от динамического программирования, жадные алгоритмы не рассматривают все возможные решения, а выбирают лучшее решение в текущий момент без учета будущих последствий.

Жадные алгоритмы работают, но только для определенного класса задач, где локальный оптимум приводит к глобальному оптимуму. Такие задачи обладают свойством **жадного выбора** (greedy choice property).

### Когда применять жадные алгоритмы

Жадные алгоритмы подходят для задач, обладающих следующими свойствами:

1. **Свойство жадного выбора**: оптимальное решение можно построить, сделав локально оптимальный выбор на каждом шаге
2. **Оптимальная подструктура**: оптимальное решение задачи содержит оптимальные решения подзадач

### Примеры классических задач для жадных алгоритмов

#### 1. Задача о размене монет (Coin Change)

**Задача**: Дан набор монет различных достоинств и сумма денег. Найти минимальное количество монет, которыми можно разменять данную сумму.

```python
def coin_change_greedy(coins, amount):
    # Сортируем монеты по убыванию
    coins.sort(reverse=True)
    
    count = 0
    remaining = amount
    coin_counts = {}  # Для хранения количества монет каждого номинала
    
    for coin in coins:
        # Используем максимально возможное количество текущей монеты
        num_coins = remaining // coin
        if num_coins > 0:
            remaining -= num_coins * coin
            count += num_coins
            coin_counts[coin] = num_coins
    
    if remaining == 0:
        print("Размен:")
        for coin, num in coin_counts.items():
            print(f"{num} монет номиналом {coin}")
        return count
    else:
        return -1  # Размен невозможен

# Пример использования
coins = [25, 10, 5, 1]  # Стандартные американские монеты
amount = 63
print(f"Минимальное количество монет: {coin_change_greedy(coins, amount)}")
# Минимальное количество монет: 6
# Размен:
# 2 монет номиналом 25
# 1 монет номиналом 10
# 0 монет номиналом 5
# 3 монет номиналом 1
```

**Примечание**: Жадный алгоритм не всегда дает оптимальное решение для произвольного набора монет. Например, для монет [1, 3, 4] и суммы 6, жадный алгоритм выдаст 3 монеты (4 + 1 + 1), в то время как оптимальное решение — 2 монеты (3 + 3).

#### 2. Задача о расписании (Interval Scheduling)

**Задача**: Дан набор задач с временем начала и окончания. Выбрать максимальное количество задач, которые можно выполнить без пересечений.

```python
def interval_scheduling(jobs):
    # Сортируем задачи по времени окончания
    jobs.sort(key=lambda x: x[1])
    
    selected_jobs = []
    last_finish_time = 0
    
    for start, finish in jobs:
        # Если время начала не раньше времени окончания предыдущей выбранной задачи
        if start >= last_finish_time:
            selected_jobs.append((start, finish))
            last_finish_time = finish
    
    return selected_jobs

# Пример использования
jobs = [(1, 3), (2, 5), (3, 9), (6, 8), (7, 10)]  # (время_начала, время_окончания)
result = interval_scheduling(jobs)
print(f"Максимальное количество непересекающихся задач: {len(result)}")  # 3
print(f"Выбранные задачи: {result}")  # [(1, 3), (6, 8), (7, 10)]
```

**Примечание**: Сортировка по времени окончания гарантирует оптимальное решение для этой задачи.

#### 3. Алгоритм Хаффмана (Huffman Coding)

**Задача**: Построить оптимальный префиксный код для сжатия данных, где символы с большей частотой получают более короткие коды.

```python
import heapq
from collections import Counter

class Node:
    def __init__(self, char, freq):
        self.char = char
        self.freq = freq
        self.left = None
        self.right = None
    
    # Для сравнения узлов в очереди с приоритетом
    def __lt__(self, other):
        return self.freq < other.freq

def huffman_coding(text):
    # Подсчет частоты символов
    frequency = Counter(text)
    
    # Создание листьев дерева Хаффмана
    priority_queue = [Node(char, freq) for char, freq in frequency.items()]
    heapq.heapify(priority_queue)
    
    # Построение дерева Хаффмана
    while len(priority_queue) > 1:
        # Извлекаем два узла с наименьшей частотой
        left = heapq.heappop(priority_queue)
        right = heapq.heappop(priority_queue)
        
        # Создаем новый внутренний узел с этими двумя узлами как потомками
        # и с частотой, равной сумме их частот
        merged = Node(None, left.freq + right.freq)
        merged.left = left
        merged.right = right
        
        heapq.heappush(priority_queue, merged)
    
    # Корень дерева Хаффмана
    root = priority_queue[0]
    
    # Таблица кодов Хаффмана
    codes = {}
    
    def generate_codes(node, code):
        if node:
            if node.char:
                codes[node.char] = code
            generate_codes(node.left, code + "0")
            generate_codes(node.right, code + "1")
    
    generate_codes(root, "")
    
    return codes

# Пример использования
text = "abracadabra"
codes = huffman_coding(text)
print("Коды Хаффмана:")
for char, code in codes.items():
    print(f"{char}: {code}")

# Кодирование текста
encoded_text = ''.join([codes[char] for char in text])
print(f"Закодированный текст: {encoded_text}")

# Вычисление сжатия
original_size = len(text) * 8  # Предполагаем 8 бит на символ
compressed_size = len(encoded_text)
print(f"Сжатие: {original_size} бит -> {compressed_size} бит ({100 * compressed_size / original_size:.2f}%)")
```

#### 4. Алгоритм Прима (Prim's Algorithm)

**Задача**: Найти минимальное остовное дерево в графе (см. раздел "Графы и алгоритмы обхода").

#### 5. Алгоритм Крускала (Kruskal's Algorithm)

**Задача**: Найти минимальное остовное дерево в графе (см. раздел "Графы и алгоритмы обхода").

#### 6. Алгоритм Дейкстры (Dijkstra's Algorithm)

**Задача**: Найти кратчайшие пути от одной вершины до всех остальных в графе с неотрицательными весами (см. раздел "Графы и алгоритмы обхода").

### Сравнение жадных алгоритмов и динамического программирования

| Критерий | Жадные алгоритмы | Динамическое программирование |
|----------|------------------|-------------------------------|
| Принцип | Принимает наилучшее решение на каждом шаге | Рассматривает все возможные решения подзадач |
| Оптимальность | Не всегда оптимальны | Всегда оптимальны при правильной формулировке |
| Скорость | Обычно быстрее | Обычно медленнее |
| Сложность реализации | Обычно проще | Обычно сложнее |
| Применимость | Ограниченный класс задач | Широкий класс задач |
| Требуемые свойства | Свойство жадного выбора, оптимальная подструктура | Оптимальная подструктура, перекрывающиеся подзадачи |

### Когда жадные алгоритмы не работают

Жадные алгоритмы не всегда дают оптимальные решения. Примеры задач, где они могут не работать:

1. **Задача о рюкзаке**: Выбор предметов с наибольшим соотношением цена/вес не всегда оптимален
2. **Задача коммивояжера**: Выбор ближайшего города на каждом шаге не гарантирует кратчайший маршрут
3. **Задача о размене монет с произвольными номиналами**: Как показано выше, жадный алгоритм может не дать оптимального решения

### Дополнительные ресурсы
- [Greedy Algorithms](https://www.geeksforgeeks.org/greedy-algorithms/)
- [When Greedy Algorithms Fail](https://www.cs.princeton.edu/~wayne/kleinberg-tardos/pdf/04GreedyAlgorithmsII.pdf)
- [Визуализация жадных алгоритмов](https://www.cs.usfca.edu/~galles/visualization/Dijkstra.html)
- [Задачи на жадные алгоритмы на LeetCode](https://leetcode.com/tag/greedy/)

## Рекурсия и её применение

### Общий обзор

Рекурсия — это метод решения задач, при котором функция вызывает сама себя с меньшими или более простыми аргументами. Рекурсия широко используется в программировании для задач, которые можно разбить на подзадачи того же типа. Это мощный инструмент для разработки элегантных и эффективных решений.

### Основные принципы рекурсии

1. **Базовый случай (База рекурсии)**: условие, при котором рекурсия останавливается
2. **Рекурсивный случай**: шаг, который приближает задачу к базовому случаю
3. **Корректность**: рекурсивные вызовы должны в конечном итоге достичь базового случая

### Простые примеры рекурсии

#### 1. Факториал числа

```python
def factorial(n):
    # Базовый случай
    if n == 0 or n == 1:
        return 1
    # Рекурсивный случай
    else:
        return n * factorial(n - 1)

# Пример использования
n = 5
print(f"{n}! = {factorial(n)}")  # 5! = 120
```

#### 2. Числа Фибоначчи

```python
def fibonacci(n):
    # Базовые случаи
    if n <= 1:
        return n
    # Рекурсивный случай
    else:
        return fibonacci(n - 1) + fibonacci(n - 2)

# Пример использования
n = 10
print(f"Fibonacci({n}) = {fibonacci(n)}")  # Fibonacci(10) = 55
```

**Примечание**: Это наивная реализация, которая имеет экспоненциальную временную сложность из-за повторных вычислений. Для эффективной реализации необходимо использовать динамическое программирование (см. раздел "Динамическое программирование").

### Типы рекурсии

#### 1. Линейная рекурсия
Функция вызывает себя только один раз в каждом рекурсивном случае.

```python
def sum_array(arr, n):
    # Базовый случай
    if n <= 0:
        return 0
    # Рекурсивный случай
    else:
        return arr[n - 1] + sum_array(arr, n - 1)

# Пример использования
arr = [1, 2, 3, 4, 5]
print(f"Сумма элементов массива: {sum_array(arr, len(arr))}")  # 15
```

#### 2. Бинарная рекурсия
Функция вызывает себя дважды в каждом рекурсивном случае.

```python
# Пример бинарной рекурсии — числа Фибоначчи (см. выше)
```

#### 3. Хвостовая рекурсия
Рекурсивный вызов является последней операцией в функции. Такую рекурсию компилятор или интерпретатор может оптимизировать, превратив её в итерацию.

```python
def factorial_tail(n, accumulator=1):
    # Базовый случай
    if n <= 1:
        return accumulator
    # Рекурсивный случай (хвостовой вызов)
    else:
        return factorial_tail(n - 1, n * accumulator)

# Пример использования
n = 5
print(f"{n}! = {factorial_tail(n)}")  # 5! = 120
```

#### 4. Вложенная рекурсия
Аргумент рекурсивного вызова сам по себе является результатом рекурсивного вызова.

```python
def ackermann(m, n):
    # Базовые случаи
    if m == 0:
        return n + 1
    if n == 0:
        return ackermann(m - 1, 1)
    # Рекурсивный случай (вложенная рекурсия)
    return ackermann(m - 1, ackermann(m, n - 1))

# Пример использования
print(f"Ackermann(3, 2) = {ackermann(3, 2)}")  # Значение растет очень быстро
```

#### 5. Взаимная рекурсия
Две или более функций вызывают друг друга.

```python
def is_even(n):
    if n == 0:
        return True
    else:
        return is_odd(n - 1)

def is_odd(n):
    if n == 0:
        return False
    else:
        return is_even(n - 1)

# Пример использования
print(f"is_even(4) = {is_even(4)}")  # True
print(f"is_odd(5) = {is_odd(5)}")    # True
```

### Стек вызовов и пределы рекурсии

При каждом рекурсивном вызове информация о текущем состоянии функции (параметры, локальные переменные, адрес возврата) сохраняется в стеке вызовов. Это может привести к переполнению стека при слишком глубокой рекурсии.

```python
import sys

# Проверка текущего лимита рекурсии
print(f"Текущий лимит рекурсии: {sys.getrecursionlimit()}")

# Изменение лимита (осторожно!)
sys.setrecursionlimit(3000)
print(f"Новый лимит рекурсии: {sys.getrecursionlimit()}")
```

Для избежания переполнения стека:
1. Используйте хвостовую рекурсию (где возможно)
2. Преобразуйте рекурсию в итерацию
3. Используйте мемоизацию для уменьшения глубины рекурсии

### Рекурсия vs Итерация

Преимущества рекурсии:
1. Более понятный и элегантный код для некоторых задач
2. Естественно соответствует рекурсивной структуре задачи
3. Упрощает обход древовидных и рекурсивных структур данных

Недостатки рекурсии:
1. Расход памяти на стек вызовов
2. Риск переполнения стека
3. Дополнительные накладные расходы на вызовы функций

```python
# Рекурсивная версия факториала
def factorial_recursive(n):
    if n <= 1:
        return 1
    return n * factorial_recursive(n - 1)

# Итеративная версия факториала
def factorial_iterative(n):
    result = 1
    for i in range(1, n + 1):
        result *= i
    return result

# Сравнение
n = 5
print(f"Рекурсивно: {n}! = {factorial_recursive(n)}")
print(f"Итеративно: {n}! = {factorial_iterative(n)}")
```

### Рекурсивные алгоритмы обхода структур данных

#### 1. Обход двоичного дерева

```python
class TreeNode:
    def __init__(self, value):
        self.value = value
        self.left = None
        self.right = None

# Обход в глубину (DFS): предварительный порядок (pre-order)
def preorder_traversal(node):
    if node is None:
        return []
    
    result = [node.value]  # Корень
    result.extend(preorder_traversal(node.left))  # Левое поддерево
    result.extend(preorder_traversal(node.right))  # Правое поддерево
    
    return result

# Обход в глубину (DFS): симметричный порядок (in-order)
def inorder_traversal(node):
    if node is None:
        return []
    
    result = []
    result.extend(inorder_traversal(node.left))  # Левое поддерево
    result.append(node.value)  # Корень
    result.extend(inorder_traversal(node.right))  # Правое поддерево
    
    return result

# Обход в глубину (DFS): обратный порядок (post-order)
def postorder_traversal(node):
    if node is None:
        return []
    
    result = []
    result.extend(postorder_traversal(node.left))  # Левое поддерево
    result.extend(postorder_traversal(node.right))  # Правое поддерево
    result.append(node.value)  # Корень
    
    return result

# Пример использования
#       1
#      / \
#     2   3
#    / \
#   4   5
root = TreeNode(1)
root.left = TreeNode(2)
root.right = TreeNode(3)
root.left.left = TreeNode(4)
root.left.right = TreeNode(5)

print(f"Pre-order traversal: {preorder_traversal(root)}")    # [1, 2, 4, 5, 3]
print(f"In-order traversal: {inorder_traversal(root)}")      # [4, 2, 5, 1, 3]
print(f"Post-order traversal: {postorder_traversal(root)}")  # [4, 5, 2, 3, 1]
```

#### 2. Рекурсивный обход директорий

```python
import os

def list_files(directory, indent=""):
    """Рекурсивно выводит все файлы и директории."""
    try:
        with os.scandir(directory) as entries:
            for entry in entries:
                print(f"{indent}{'[DIR] ' if entry.is_dir() else ''}{entry.name}")
                if entry.is_dir():
                    list_files(entry.path, indent + "  ")
    except PermissionError:
        print(f"{indent}[Отказано в доступе]")

# Пример использования
# list_files("/путь/к/директории")  # Раскомментируйте и укажите реальный путь
```

### Рекурсивные алгоритмы сортировки

#### 1. Быстрая сортировка (Quick Sort)

```python
def quick_sort(arr):
    if len(arr) <= 1:
        return arr
    
    pivot = arr[len(arr) // 2]  # Выбираем опорный элемент
    
    left = [x for x in arr if x < pivot]
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x > pivot]
    
    return quick_sort(left) + middle + quick_sort(right)

# Пример использования
arr = [3, 6, 8, 10, 1, 2, 1]
print(f"Отсортированный массив: {quick_sort(arr)}")  # [1, 1, 2, 3, 6, 8, 10]
```

#### 2. Сортировка слиянием (Merge Sort)

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    
    return merge(left, right)

def merge(left, right):
    result = []
    i = j = 0
    
    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    
    result.extend(left[i:])
    result.extend(right[j:])
    
    return result

# Пример использования
arr = [38, 27, 43, 3, 9, 82, 10]
print(f"Отсортированный массив: {merge_sort(arr)}")  # [3, 9, 10, 27, 38, 43, 82]
```

### Примеры сложных рекурсивных алгоритмов

#### 1. Ханойские башни

```python
def hanoi(n, source, auxiliary, target):
    if n == 1:
        print(f"Переместить диск 1 с {source} на {target}")
        return
    
    hanoi(n - 1, source, target, auxiliary)
    print(f"Переместить диск {n} с {source} на {target}")
    hanoi(n - 1, auxiliary, source, target)

# Пример использования
n = 3
print(f"Решение Ханойской башни для {n} дисков:")
hanoi(n, 'A', 'B', 'C')
```

#### 2. Генерация всех перестановок

```python
def permutations(arr):
    if len(arr) <= 1:
        return [arr]
    
    result = []
    for i in range(len(arr)):
        current = arr[i]
        remaining = arr[:i] + arr[i+1:]
        
        for p in permutations(remaining):
            result.append([current] + p)
    
    return result

# Пример использования
arr = [1, 2, 3]
perms = permutations(arr)
print(f"Все перестановки {arr}: {perms}")
print(f"Количество перестановок: {len(perms)}")  # 6 = 3!
```

#### 3. Алгоритм поиска с возвратом (Backtracking): N ферзей

```python
def is_safe(board, row, col, n):
    # Проверка строки слева
    for i in range(col):
        if board[row][i] == 1:
            return False
    
    # Проверка верхней диагонали слева
    for i, j in zip(range(row, -1, -1), range(col, -1, -1)):
        if board[i][j] == 1:
            return False
    
    # Проверка нижней диагонали слева
    for i, j in zip(range(row, n), range(col, -1, -1)):
        if board[i][j] == 1:
            return False
    
    return True

def solve_n_queens_util(board, col, n, solutions):
    # Базовый случай: все ферзи размещены
    if col >= n:
        solution = []
        for row in board:
            solution.append(''.join(['Q' if cell == 1 else '.' for cell in row]))
        solutions.append(solution)
        return True
    
    # Пробуем разместить ферзя в каждой строке текущего столбца
    res = False
    for row in range(n):
        if is_safe(board, row, col, n):
            # Размещаем ферзя
            board[row][col] = 1
            
            # Рекурсивно пробуем разместить остальных ферзей
            res = solve_n_queens_util(board, col + 1, n, solutions) or res
            
            # Если расстановка не приводит к решению, отменяем (backtrack)
            board[row][col] = 0
    
    return res

def solve_n_queens(n):
    board = [[0 for _ in range(n)] for _ in range(n)]
    solutions = []
    
    solve_n_queens_util(board, 0, n, solutions)
    
    return solutions

# Пример использования
n = 4
solutions = solve_n_queens(n)
print(f"Количество решений для {n} ферзей: {len(solutions)}")
for i, solution in enumerate(solutions):
    print(f"Решение {i + 1}:")
    for row in solution:
        print(row)
    print()
```

### Оптимизация рекурсии

#### 1. Мемоизация

```python
# Наивная рекурсивная реализация чисел Фибоначчи
def fib_naive(n):
    if n <= 1:
        return n
    return fib_naive(n - 1) + fib_naive(n - 2)

# Оптимизированная версия с мемоизацией
def fib_memo(n, memo={}):
    if n in memo:
        return memo[n]
    
    if n <= 1:
        return n
    
    memo[n] = fib_memo(n - 1, memo) + fib_memo(n - 2, memo)
    return memo[n]

# Сравнение (для небольших n)
n = 30
# print(f"Fibonacci({n}) naive: {fib_naive(n)}")  # Медленно для больших n
print(f"Fibonacci({n}) with memoization: {fib_memo(n)}")  # Быстро
```

#### 2. Хвостовая рекурсия и оптимизация компилятором

```python
# Обычная рекурсивная функция факториала
def factorial_regular(n):
    if n <= 1:
        return 1
    return n * factorial_regular(n - 1)

# Хвостовая рекурсия
def factorial_tail(n, acc=1):
    if n <= 1:
        return acc
    return factorial_tail(n - 1, n * acc)

# Пример использования
n = 5
print(f"Regular factorial: {factorial_regular(n)}")
print(f"Tail-recursive factorial: {factorial_tail(n)}")
```

**Примечание**: Python не выполняет автоматическую оптимизацию хвостовой рекурсии, но многие другие языки программирования (Scheme, Haskell, некоторые реализации C/C++) выполняют такую оптимизацию.

### Дополнительные ресурсы
- [Рекурсия в Python](https://realpython.com/python-recursion/)
- [Визуализация рекурсивных алгоритмов](https://visualgo.net/en/recursion)
- [Задачи на рекурсию на LeetCode](https://leetcode.com/tag/recursion/)
- [Tail Call Optimization in Python](https://stackoverflow.com/questions/13591970/does-python-optimize-tail-recursion)
