# Балансировка нагрузки

## Введение в балансировку нагрузки

Балансировка нагрузки — это распределение запросов или вычислительных задач между несколькими серверами или вычислительными ресурсами для оптимизации использования ресурсов, максимизации пропускной способности, уменьшения времени отклика и обеспечения отказоустойчивости.

### Зачем нужна балансировка нагрузки

1. **Масштабируемость**: возможность обрабатывать больше запросов с помощью добавления новых серверов
2. **Высокая доступность**: продолжение работы сервиса даже при отказе отдельных компонентов
3. **Производительность**: оптимальное распределение нагрузки для минимизации времени отклика
4. **Эффективность**: максимально полное использование имеющихся ресурсов

## Типы балансировщиков нагрузки

### Аппаратные балансировщики

Физические устройства, специально разработанные для распределения трафика:

- F5 Networks BIG-IP
- Citrix ADC (ранее NetScaler)
- A10 Networks
- Kemp LoadMaster

**Преимущества**:
- Высокая производительность
- Специализированное оборудование
- Поддержка от производителя

**Недостатки**:
- Высокая стоимость
- Ограниченная гибкость
- Требуется физическое размещение

### Программные балансировщики

Программные решения, работающие на стандартном оборудовании:

- NGINX
- HAProxy
- Apache Traffic Server
- Envoy Proxy
- Traefik

**Преимущества**:
- Гибкое конфигурирование
- Более низкая стоимость
- Легкая интеграция в облачные среды

**Недостатки**:
- Может иметь меньшую производительность, чем аппаратное решение
- Требует управления и обслуживания

### Облачные балансировщики

Решения, предоставляемые облачными провайдерами:

- AWS Elastic Load Balancing
- Google Cloud Load Balancing
- Azure Load Balancer
- Cloudflare Load Balancing

**Преимущества**:
- Масштабируемость по требованию
- Интеграция с облачными сервисами
- Управляемый сервис (меньше административной нагрузки)

**Недостатки**:
- Привязка к облачному провайдеру
- Ограниченная настраиваемость (по сравнению с самостоятельно развернутым решением)
- Стоимость может расти с увеличением объема трафика

## Алгоритмы балансировки нагрузки

### Round Robin (Циклический перебор)

Распределение запросов последовательно по всем серверам в цикле.

```python
class RoundRobinBalancer:
    def __init__(self, servers):
        self.servers = servers
        self.current_index = 0
    
    def get_server(self):
        server = self.servers[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.servers)
        return server
```

**Преимущества**:
- Простая реализация
- Равномерное распределение при однородных запросах

**Недостатки**:
- Не учитывает загруженность серверов
- Не оптимален для разнородных серверов или запросов

### Weighted Round Robin (Взвешенный циклический перебор)

Вариация Round Robin, где серверам назначаются весовые коэффициенты в соответствии с их мощностью.

```python
class WeightedRoundRobinBalancer:
    def __init__(self, servers_with_weights):
        # servers_with_weights is a list of (server, weight) tuples
        self.servers_with_weights = servers_with_weights
        self.weights_sum = sum(weight for _, weight in servers_with_weights)
        self.current_position = 0
        
    def get_server(self):
        while True:
            self.current_position = (self.current_position + 1) % self.weights_sum
            for server, weight in self.servers_with_weights:
                if self.current_position <= weight:
                    return server
                self.current_position -= weight
```

**Преимущества**:
- Учитывает разную мощность серверов
- Относительно простая реализация

**Недостатки**:
- Не учитывает текущую загруженность серверов
- Требует знания относительной мощности серверов

### Least Connections (Наименьшее количество соединений)

Выбор сервера с наименьшим количеством активных соединений.

```python
class LeastConnectionsBalancer:
    def __init__(self, servers):
        self.servers = servers
        self.connections = {server: 0 for server in servers}
    
    def get_server(self):
        # Выбираем сервер с наименьшим количеством соединений
        server = min(self.connections.items(), key=lambda x: x[1])[0]
        self.connections[server] += 1
        return server
    
    def release_server(self, server):
        # Вызывается после завершения обработки запроса
        if server in self.connections:
            self.connections[server] -= 1
```

**Преимущества**:
- Учитывает текущую загрузку серверов
- Эффективен для долгоживущих соединений

**Недостатки**:
- Не учитывает разную мощность серверов
- Сложнее реализовать (требуется отслеживание соединений)

### Weighted Least Connections (Взвешенное наименьшее количество соединений)

Комбинация алгоритмов Least Connections и Weighted Round Robin, учитывающая как текущую загрузку, так и мощность серверов.

```python
class WeightedLeastConnectionsBalancer:
    def __init__(self, servers_with_weights):
        # servers_with_weights is a list of (server, weight) tuples
        self.servers = [server for server, _ in servers_with_weights]
        self.weights = {server: weight for server, weight in servers_with_weights}
        self.connections = {server: 0 for server in self.servers}
    
    def get_server(self):
        # Выбираем сервер с лучшим соотношением (активные соединения / вес)
        server = min(self.servers, key=lambda s: self.connections[s] / self.weights[s])
        self.connections[server] += 1
        return server
    
    def release_server(self, server):
        # Вызывается после завершения обработки запроса
        if server in self.connections:
            self.connections[server] -= 1
```

**Преимущества**:
- Учитывает как мощность серверов, так и их текущую загрузку
- Хороший баланс между эффективностью и сложностью

**Недостатки**:
- Сложнее реализовать
- Требует знания относительной мощности серверов

### IP Hash (Хеширование IP)

Выбор сервера на основе хеша IP-адреса клиента, обеспечивающий, что запросы от одного клиента всегда попадают на один и тот же сервер.

```python
import hashlib

class IPHashBalancer:
    def __init__(self, servers):
        self.servers = servers
    
    def get_server(self, client_ip):
        # Вычисляем хеш IP-адреса клиента
        hash_value = int(hashlib.md5(client_ip.encode()).hexdigest(), 16)
        # Выбираем сервер на основе хеша
        server_index = hash_value % len(self.servers)
        return self.servers[server_index]
```

**Преимущества**:
- Обеспечивает привязку сессии (session affinity)
- Не требует сохранения состояния на балансировщике

**Недостатки**:
- Может привести к неравномерному распределению
- Не адаптируется к изменению загрузки серверов

### Least Response Time (Наименьшее время отклика)

Выбор сервера с наименьшим временем отклика.

```python
class LeastResponseTimeBalancer:
    def __init__(self, servers):
        self.servers = servers
        self.response_times = {server: 0 for server in servers}
        self.active_requests = {server: 0 for server in servers}
    
    def get_server(self):
        # Выбираем сервер с наименьшим временем отклика
        # Если несколько серверов имеют одинаковое время отклика,
        # выбираем тот, у которого меньше активных запросов
        server = min(self.servers, key=lambda s: (self.response_times[s], self.active_requests[s]))
        self.active_requests[server] += 1
        return server
    
    def update_response_time(self, server, response_time):
        # Обновляем среднее время отклика (экспоненциальное скользящее среднее)
        alpha = 0.8  # Весовой коэффициент для нового измерения
        if self.response_times[server] == 0:
            self.response_times[server] = response_time
        else:
            self.response_times[server] = alpha * response_time + (1 - alpha) * self.response_times[server]
        self.active_requests[server] -= 1
```

**Преимущества**:
- Учитывает фактическую производительность серверов
- Адаптируется к изменениям в производительности

**Недостатки**:
- Сложно реализовать и настроить
- Требует мониторинга времени отклика

### Consistent Hashing (Консистентное хеширование)

Метод распределения запросов, устойчивый к изменению количества серверов, который минимизирует перераспределение при добавлении или удалении серверов.

```python
import hashlib
import bisect

class ConsistentHashBalancer:
    def __init__(self, servers, replicas=100):
        self.replicas = replicas
        self.ring = {}
        self.keys = []
        
        # Добавляем серверы в кольцо хеширования
        for server in servers:
            self.add_server(server)
    
    def add_server(self, server):
        # Добавляем сервер в кольцо с несколькими виртуальными узлами (репликами)
        for i in range(self.replicas):
            key = self._hash(f"{server}:{i}")
            self.ring[key] = server
            self.keys.append(key)
        
        # Сортируем ключи для быстрого поиска
        self.keys.sort()
    
    def remove_server(self, server):
        # Удаляем сервер из кольца
        for i in range(self.replicas):
            key = self._hash(f"{server}:{i}")
            if key in self.ring:
                del self.ring[key]
                self.keys.remove(key)
    
    def get_server(self, key_to_hash):
        # Если кольцо пусто, возвращаем None
        if not self.keys:
            return None
        
        # Вычисляем хеш для ключа
        key_hash = self._hash(key_to_hash)
        
        # Находим позицию в кольце
        index = bisect.bisect(self.keys, key_hash)
        if index >= len(self.keys):
            index = 0
        
        # Возвращаем соответствующий сервер
        return self.ring[self.keys[index]]
    
    def _hash(self, key):
        return int(hashlib.md5(str(key).encode()).hexdigest(), 16)
```

**Преимущества**:
- Минимизирует перераспределение при изменении количества серверов
- Хорошо подходит для кэширования и распределенных систем

**Недостатки**:
- Сложнее реализовать
- Не учитывает загрузку серверов

## Реализация балансировки нагрузки в Python

### HTTP Load Balancer с использованием aiohttp

```python
import asyncio
import aiohttp
import time
import random
from aiohttp import web

class SimpleLoadBalancer:
    def __init__(self, backends, algorithm='round_robin'):
        self.backends = backends
        self.algorithm = algorithm
        self.current_index = 0
        self.active_connections = {backend: 0 for backend in backends}
        self.response_times = {backend: 0 for backend in backends}
    
    async def handle_request(self, request):
        # Выбираем бэкенд согласно алгоритму
        backend = self.select_backend(request)
        
        if backend is None:
            return web.Response(text="No backend available", status=503)
        
        # Отправляем запрос на выбранный бэкенд
        start_time = time.time()
        self.active_connections[backend] += 1
        
        try:
            # Копируем запрос на бэкенд
            method = request.method
            path = request.path
            headers = {k: v for k, v in request.headers.items() if k.lower() != 'host'}
            data = await request.read()
            
            # Отправляем запрос на бэкенд
            async with aiohttp.ClientSession() as session:
                async with session.request(method, f"{backend}{path}", 
                                          headers=headers, data=data, 
                                          params=request.query) as resp:
                    
                    # Получаем ответ от бэкенда
                    response_data = await resp.read()
                    response = web.Response(
                        body=response_data,
                        status=resp.status,
                        headers=resp.headers
                    )
                    
                    # Обновляем статистику
                    elapsed = time.time() - start_time
                    self.update_stats(backend, elapsed)
                    
                    return response
                    
        except Exception as e:
            # Обработка ошибок
            print(f"Error forwarding to {backend}: {e}")
            return web.Response(text="Backend error", status=502)
        
        finally:
            # Уменьшаем счетчик активных соединений
            self.active_connections[backend] -= 1
    
    def select_backend(self, request):
        if not self.backends:
            return None
        
        # Выбор бэкенда в зависимости от алгоритма
        if self.algorithm == 'round_robin':
            backend = self.backends[self.current_index]
            self.current_index = (self.current_index + 1) % len(self.backends)
            return backend
        
        elif self.algorithm == 'least_connections':
            return min(self.active_connections.items(), key=lambda x: x[1])[0]
        
        elif self.algorithm == 'least_response_time':
            return min(self.response_times.items(), key=lambda x: x[1])[0]
        
        elif self.algorithm == 'ip_hash' and 'remote' in request:
            # Простая реализация IP Hash
            client_ip = request.remote
            hash_value = sum(ord(c) for c in client_ip)
            backend_index = hash_value % len(self.backends)
            return self.backends[backend_index]
        
        # Если алгоритм неизвестен или произошла ошибка, используем Round Robin
        backend = self.backends[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.backends)
        return backend
    
    def update_stats(self, backend, response_time):
        # Обновляем статистику времени отклика
        alpha = 0.8  # Коэффициент для экспоненциального скользящего среднего
        if self.response_times[backend] == 0:
            self.response_times[backend] = response_time
        else:
            self.response_times[backend] = alpha * response_time + (1 - alpha) * self.response_times[backend]
    
    def add_backend(self, backend):
        if backend not in self.backends:
            self.backends.append(backend)
            self.active_connections[backend] = 0
            self.response_times[backend] = 0
    
    def remove_backend(self, backend):
        if backend in self.backends:
            self.backends.remove(backend)
            if backend in self.active_connections:
                del self.active_connections[backend]
            if backend in self.response_times:
                del self.response_times[backend]
    
    def get_status(self):
        # Возвращает информацию о состоянии балансировщика
        return {
            "backends": self.backends,
            "active_connections": self.active_connections,
            "response_times": self.response_times,
            "algorithm": self.algorithm
        }

async def start_balancer(host='0.0.0.0', port=8080):
    # Список бэкендов
    backends = [
        'http://backend1:8081',
        'http://backend2:8082',
        'http://backend3:8083'
    ]
    
    # Создаем балансировщик
    balancer = SimpleLoadBalancer(backends, algorithm='least_connections')
    
    # Создаем веб-приложение
    app = web.Application()
    
    # Маршрут для получения статуса балансировщика
    async def status_handler(request):
        return web.json_response(balancer.get_status())
    
    # Маршрут для динамического добавления/удаления бэкендов
    async def manage_backends(request):
        data = await request.json()
        action = data.get('action')
        backend = data.get('backend')
        
        if not backend:
            return web.json_response({"error": "Backend URL is required"}, status=400)
        
        if action == 'add':
            balancer.add_backend(backend)
            return web.json_response({"message": f"Backend {backend} added"})
        elif action == 'remove':
            balancer.remove_backend(backend)
            return web.json_response({"message": f"Backend {backend} removed"})
        else:
            return web.json_response({"error": "Invalid action"}, status=400)
    
    # Регистрируем маршруты
    app.router.add_get('/status', status_handler)
    app.router.add_post('/manage', manage_backends)
    
    # Все остальные запросы передаем балансировщику
    app.router.add_route('*', '/{path:.*}', balancer.handle_request)
    
    # Запускаем сервер
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, host, port)
    await site.start()
    
    print(f"Load balancer started at http://{host}:{port}")
    
    # Держим сервер запущенным
    while True:
        await asyncio.sleep(3600)

if __name__ == '__main__':
    asyncio.run(start_balancer())
```

### Динамическое масштабирование на основе нагрузки

```python
import asyncio
import time
import random
import statistics
import psutil
import docker
import aiohttp
from aiohttp import web

class AutoScalingLoadBalancer:
    def __init__(self, base_backend_image, min_instances=2, max_instances=10):
        self.backends = []
        self.base_backend_image = base_backend_image
        self.min_instances = min_instances
        self.max_instances = max_instances
        self.active_connections = {}
        self.response_times = {}
        self.current_index = 0
        self.docker_client = docker.from_env()
        
        # Метрики для автоматического масштабирования
        self.recent_response_times = []
        self.target_response_time = 0.5  # 500 мс
        self.scaling_cooldown = False
        self.cooldown_period = 60  # секунды
    
    async def initialize(self):
        # Запускаем минимальное количество бэкендов
        for _ in range(self.min_instances):
            await self.add_backend_instance()
        
        # Запускаем мониторинг и автомасштабирование
        asyncio.create_task(self.monitor_and_scale())
    
    async def add_backend_instance(self):
        # Запускаем новый контейнер с бэкендом
        container = self.docker_client.containers.run(
            self.base_backend_image,
            detach=True,
            network="host",  # Или используйте вашу сеть Docker
            environment={
                "PORT": str(8080 + len(self.backends) + 1)  # Разные порты для каждого бэкенда
            }
        )
        
        # Ждем, пока контейнер запустится
        await asyncio.sleep(2)
        
        # Формируем URL бэкенда
        backend_url = f"http://localhost:{8080 + len(self.backends) + 1}"
        
        # Проверяем доступность бэкенда
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{backend_url}/health") as resp:
                    if resp.status == 200:
                        # Добавляем бэкенд в список
                        self.backends.append({
                            "url": backend_url,
                            "container_id": container.id,
                            "started_at": time.time()
                        })
                        self.active_connections[backend_url] = 0
                        self.response_times[backend_url] = 0
                        print(f"Added backend {backend_url}")
                        return True
        except Exception as e:
            print(f"Failed to start backend: {e}")
            try:
                container.remove(force=True)
            except:
                pass
            return False
    
    async def remove_backend_instance(self):
        if len(self.backends) <= self.min_instances:
            return False
        
        # Выбираем бэкенд для удаления (самый старый или наименее используемый)
        backend_to_remove = sorted(self.backends, key=lambda b: b["started_at"])[0]
        backend_url = backend_to_remove["url"]
        container_id = backend_to_remove["container_id"]
        
        # Удаляем бэкенд из списка
        self.backends = [b for b in self.backends if b["url"] != backend_url]
        if backend_url in self.active_connections:
            del self.active_connections[backend_url]
        if backend_url in self.response_times:
            del self.response_times[backend_url]
        
        # Останавливаем и удаляем контейнер
        try:
            container = self.docker_client.containers.get(container_id)
            container.remove(force=True)
            print(f"Removed backend {backend_url}")
            return True
        except Exception as e:
            print(f"Failed to remove container: {e}")
            return False
    
    async def monitor_and_scale(self):
        while True:
            await asyncio.sleep(5)  # Проверка каждые 5 секунд
            
            # Вычисляем среднее время отклика
            if self.recent_response_times:
                avg_response_time = statistics.mean(self.recent_response_times)
                self.recent_response_times = []  # Сбрасываем для следующего периода
                
                # Проверяем, нужно ли масштабирование
                if not self.scaling_cooldown:
                    if avg_response_time > self.target_response_time * 1.5:
                        # Время отклика слишком большое - увеличиваем количество бэкендов
                        if len(self.backends) < self.max_instances:
                            print(f"Scaling up due to high response time: {avg_response_time:.3f}s")
                            await self.add_backend_instance()
                            # Устанавливаем период охлаждения
                            self.scaling_cooldown = True
                            asyncio.create_task(self.reset_cooldown())
                    
                    elif avg_response_time < self.target_response_time * 0.5:
                        # Время отклика низкое - уменьшаем количество бэкендов
                        if len(self.backends) > self.min_instances:
                            print(f"Scaling down due to low response time: {avg_response_time:.3f}s")
                            await self.remove_backend_instance()
                            # Устанавливаем период охлаждения
                            self.scaling_cooldown = True
                            asyncio.create_task(self.reset_cooldown())
            
            # Также проверяем загрузку процессора
            cpu_usage = psutil.cpu_percent(interval=1)
            if not self.scaling_cooldown:
                if cpu_usage > 80 and len(self.backends) < self.max_instances:
                    print(f"Scaling up due to high CPU usage: {cpu_usage}%")
                    await self.add_backend_instance()
                    self.scaling_cooldown = True
                    asyncio.create_task(self.reset_cooldown())
                elif cpu_usage < 20 and len(self.backends) > self.min_instances:
                    print(f"Scaling down due to low CPU usage: {cpu_usage}%")
                    await self.remove_backend_instance()
                    self.scaling_cooldown = True
                    asyncio.create_task(self.reset_cooldown())
    
    async def reset_cooldown(self):
        await asyncio.sleep(self.cooldown_period)
        self.scaling_cooldown = False
    
    async def handle_request(self, request):
        # Выбираем бэкенд
        backend = self.select_backend()
        
        if not backend:
            return web.Response(text="No backend available", status=503)
        
        backend_url = backend["url"]
        
        # Отправляем запрос на выбранный бэкенд
        start_time = time.time()
        self.active_connections[backend_url] += 1
        
        try:
            # Копируем запрос на бэкенд
            method = request.method
            path = request.path
            headers = {k: v for k, v in request.headers.items() if k.lower() != 'host'}
            data = await request.read()
            
            # Отправляем запрос на бэкенд
            async with aiohttp.ClientSession() as session:
                async with session.request(method, f"{backend_url}{path}", 
                                          headers=headers, data=data, 
                                          params=request.query) as resp:
                    
                    # Получаем ответ от бэкенда
                    response_data = await resp.read()
                    response = web.Response(
                        body=response_data,
                        status=resp.status,
                        headers=resp.headers
                    )
                    
                    # Обновляем статистику
                    elapsed = time.time() - start_time
                    self.update_stats(backend_url, elapsed)
                    self.recent_response_times.append(elapsed)
                    
                    return response
                    
        except Exception as e:
            # Обработка ошибок
            print(f"Error forwarding to {backend_url}: {e}")
            return web.Response(text="Backend error", status=502)
        
        finally:
            # Уменьшаем счетчик активных соединений
            self.active_connections[backend_url] -= 1
    
    def select_backend(self):
        if not self.backends:
            return None
        
        # Используем алгоритм "Наименьшее количество соединений"
        backend_url = min(self.active_connections.items(), key=lambda x: x[1])[0]
        return next(b for b in self.backends if b["url"] == backend_url)
    
    def update_stats(self, backend_url, response_time):
        # Обновляем статистику времени отклика
        alpha = 0.8  # Коэффициент для экспоненциального скользящего среднего
        if self.response_times[backend_url] == 0:
            self.response_times[backend_url] = response_time
        else:
            self.response_times[backend_url] = alpha * response_time + (1 - alpha) * self.response_times[backend_url]
    
    def get_status(self):
        # Возвращает информацию о состоянии балансировщика
        return {
            "backends": [b["url"] for b in self.backends],
            "active_connections": self.active_connections,
            "response_times": self.response_times,
            "current_instances": len(self.backends),
            "min_instances": self.min_instances,
            "max_instances": self.max_instances,
            "scaling_cooldown": self.scaling_cooldown
        }

# Пример запуска
async def start_autoscaling_balancer(host='0.0.0.0', port=8080):
    # Создаем балансировщик с автомасштабированием
    balancer = AutoScalingLoadBalancer(
        base_backend_image="my-backend-app:latest",
        min_instances=2,
        max_instances=10
    )
    
    # Инициализируем балансировщик
    await balancer.initialize()
    
    # Создаем веб-приложение
    app = web.Application()
    
    # Маршрут для получения статуса балансировщика
    async def status_handler(request):
        return web.json_response(balancer.get_status())
    
    # Регистрируем маршруты
    app.router.add_get('/status', status_handler)
    
    # Все остальные запросы передаем балансировщику
    app.router.add_route('*', '/{path:.*}', balancer.handle_request)
    
    # Запускаем сервер
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, host, port)
    await site.start()
    
    print(f"Autoscaling load balancer started at http://{host}:{port}")
    
    # Держим сервер запущенным
    while True:
        await asyncio.sleep(3600)

# Запуск балансировщика
# asyncio.run(start_autoscaling_balancer())
```

## Инструменты для балансировки нагрузки

### NGINX

NGINX — популярный веб-сервер, который также может быть использован как балансировщик нагрузки и обратный прокси.

**Пример конфигурации NGINX для балансировки нагрузки**:

```nginx
http {
    # Определение группы серверов (upstream)
    upstream backend {
        # Различные алгоритмы:
        # - round-robin (по умолчанию)
        # - least_conn - наименьшее количество соединений
        # - ip_hash - хеширование по IP
        # - hash $request_uri - хеширование по URI
        
        least_conn;  # Используем алгоритм "Наименьшее количество соединений"
        
        server backend1.example.com weight=3;  # Больший вес
        server backend2.example.com;
        server backend3.example.com;
        
        # Для проверки работоспособности бэкендов
        server backup.example.com backup;  # Резервный сервер
    }
    
    server {
        listen 80;
        server_name example.com;
        
        location / {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Таймауты
            proxy_connect_timeout 5s;
            proxy_send_timeout 10s;
            proxy_read_timeout 10s;
        }
        
        # Статические файлы напрямую из NGINX
        location ~* \.(jpg|jpeg|png|gif|ico|css|js)$ {
            root /var/www/static;
            expires 30d;
        }
    }
}
```

### HAProxy

HAProxy — свободное программное обеспечение, обеспечивающее высокую доступность, балансировку нагрузки и проксирование для TCP и HTTP-приложений.

**Пример конфигурации HAProxy**:

```
global
    log /dev/log local0
    log /dev/log local1 notice
    maxconn 4096
    user haproxy
    group haproxy
    daemon

defaults
    log     global
    mode    http
    option  httplog
    option  dontlognull
    timeout connect 5000
    timeout client  50000
    timeout server  50000

frontend http-in
    bind *:80
    default_backend webservers

backend webservers
    balance roundrobin  # Можно использовать: roundrobin, leastconn, source, uri
    option httpchk GET /health
    http-check expect status 200
    server web1 web1.example.com:80 check weight 3
    server web2 web2.example.com:80 check
    server web3 web3.example.com:80 check
    
    # Sticky sessions (привязка сессий)
    cookie SERVERID insert indirect nocache
    server web1 web1.example.com:80 check cookie web1
    server web2 web2.example.com:80 check cookie web2
    server web3 web3.example.com:80 check cookie web3

# Statistics
listen stats
    bind *:8404
    stats enable
    stats uri /stats
    stats refresh 10s
    stats auth admin:password
```

### Реализация балансировки нагрузки в Django

Для Python-приложений на Django можно реализовать балансировку нагрузки на уровне БД:

```python
# settings.py
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.mysql',
        'NAME': 'mydatabase',
        'USER': 'myuser',
        'PASSWORD': 'mypassword',
        'HOST': 'db-master.example.com',  # Главный сервер для записи
        'PORT': '3306',
    },
    'replica1': {
        'ENGINE': 'django.db.backends.mysql',
        'NAME': 'mydatabase',
        'USER': 'myuser',
        'PASSWORD': 'mypassword',
        'HOST': 'db-replica1.example.com',  # Реплика для чтения
        'PORT': '3306',
    },
    'replica2': {
        'ENGINE': 'django.db.backends.mysql',
        'NAME': 'mydatabase',
        'USER': 'myuser',
        'PASSWORD': 'mypassword',
        'HOST': 'db-replica2.example.com',  # Ещё одна реплика для чтения
        'PORT': '3306',
    },
}

# Настройка маршрутизации запросов
DATABASE_ROUTERS = ['myproject.routers.ReplicaRouter']
```

```python
# myproject/routers.py
import random

class ReplicaRouter:
    """
    Маршрутизатор для балансировки запросов чтения между репликами,
    и направления запросов записи на главный сервер.
    """
    
    def db_for_read(self, model, **hints):
        """
        Балансировка запросов чтения между репликами.
        """
        # Простая балансировка Round Robin
        replicas = ['replica1', 'replica2']
        return random.choice(replicas)
    
    def db_for_write(self, model, **hints):
        """
        Все запросы записи направляются на главный сервер.
        """
        return 'default'
    
    def allow_relation(self, obj1, obj2, **hints):
        """
        Разрешаем отношения между объектами на любой БД.
        """
        return True
    
    def allow_migrate(self, db, app_label, model_name=None, **hints):
        """
        Миграции применяются только к главному серверу.
        """
        return db == 'default'
```

## Отказоустойчивость и высокая доступность

### Проверки работоспособности (Health Checks)

Балансировщики нагрузки должны регулярно проверять доступность и работоспособность серверов:

```python
async def health_check(backend_url, timeout=5):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{backend_url}/health", timeout=timeout) as resp:
                if resp.status == 200:
                    return True
                else:
                    print(f"Health check failed for {backend_url}: Status {resp.status}")
                    return False
    except Exception as e:
        print(f"Health check failed for {backend_url}: {e}")
        return False

async def monitor_backends(balancer, check_interval=10):
    while True:
        for backend in list(balancer.backends):  # Копируем список для итерации
            is_healthy = await health_check(backend)
            if not is_healthy and backend in balancer.backends:
                print(f"Removing unhealthy backend: {backend}")
                balancer.remove_backend(backend)
            elif is_healthy and backend not in balancer.backends:
                print(f"Re-adding healthy backend: {backend}")
                balancer.add_backend(backend)
        
        await asyncio.sleep(check_interval)
```

### Автоматическое восстановление

В случае отказа сервера, система должна автоматически восстанавливать требуемое количество серверов:

```python
async def ensure_minimum_backends(balancer, min_backends=3, check_interval=30):
    while True:
        await asyncio.sleep(check_interval)
        
        # Проверяем, что у нас достаточно бэкендов
        healthy_backends = len(balancer.backends)
        
        if healthy_backends < min_backends:
            print(f"Only {healthy_backends} healthy backends. Adding more...")
            
            # Запускаем новые бэкенды
            for _ in range(min_backends - healthy_backends):
                success = await balancer.add_backend_instance()
                if not success:
                    print("Failed to add new backend instance")
```

### Горячая замена (Hot Swapping)

Обновление серверов без простоя сервиса:

```python
async def rolling_update(balancer, new_image_version):
    """
    Обновляет бэкенды поочередно, не прерывая обслуживание.
    """
    for i, backend in enumerate(list(balancer.backends)):
        print(f"Updating backend {i+1}/{len(balancer.backends)}: {backend['url']}")
        
        # Запускаем новый бэкенд с обновленной версией
        success = await balancer.add_backend_instance(image_version=new_image_version)
        
        if success:
            # Даем новому бэкенду время на "разогрев"
            await asyncio.sleep(10)
            
            # Удаляем старый бэкенд
            balancer.remove_backend(backend)
            
            # Небольшая пауза между обновлениями
            await asyncio.sleep(5)
        else:
            print(f"Failed to add new backend with version {new_image_version}")
            break
    
    print("Rolling update completed")
```

## Заключение

Балансировка нагрузки — важный аспект построения масштабируемых и отказоустойчивых систем. Выбор правильного подхода к балансировке зависит от конкретных требований проекта, используемой инфраструктуры и характера нагрузки.

### Основные принципы:

1. **Не полагайтесь на один сервер** — всегда проектируйте с учетом масштабирования
2. **Выбирайте подходящий алгоритм балансировки** для вашего приложения
3. **Реализуйте мониторинг и проверки работоспособности**
4. **Автоматизируйте масштабирование**, когда это возможно
5. **Учитывайте особенности своего приложения** (сессии, состояние и т.д.)

### Что выбрать:

- **Для небольших проектов**: NGINX или HAProxy в качестве обратного прокси
- **Для средних проектов**: Kubernetes с внутренним балансировщиком нагрузки
- **Для крупных проектов**: Комбинация облачных балансировщиков нагрузки (AWS ELB, GCP Load Balancer) и внутренних средств балансировки
- **Для особых требований**: Специализированные решения или собственная реализация